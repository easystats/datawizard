[{"path":[]},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement patilindrajeet.science@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to datawizard","title":"Contributing to datawizard","text":"outlines propose change datawizard.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to datawizard","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. want fix typos documentation, please edit related .R file R/ folder. edit .Rd file man/.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"filing-an-issue","dir":"","previous_headings":"","what":"Filing an issue","title":"Contributing to datawizard","text":"easiest way propose change new feature file issue. ’ve found bug, may also create associated issue. possible, try illustrate proposal bug minimal reproducible example.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to datawizard","text":"Please create Git branch pull request (PR). contributed code roughly follow R style guide, particular easystats convention code-style. datawizard uses roxygen2, Markdown syntax, documentation. datawizard uses testthat. Adding tests PR makes easier merge PR code base. PR user-visible change, may add bullet top NEWS.md describing changes made. may optionally add GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to datawizard","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://easystats.github.io/datawizard/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 datawizard authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://easystats.github.io/datawizard/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with {datawizard}","title":"Getting help with {datawizard}","text":"Thanks using datawizard. filing issue, places explore pieces put together make process smooth possible. Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! resource used tidyverse team. Armed reprex, next step figure ask: ’s question: start StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed. Thanks help!","code":""},{"path":"https://easystats.github.io/datawizard/articles/overview_of_vignettes.html","id":"function-overview","dir":"Articles","previous_headings":"","what":"Function Overview","title":"Overview of Vignettes","text":"Function Reference","code":""},{"path":"https://easystats.github.io/datawizard/articles/overview_of_vignettes.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data Preparation","title":"Overview of Vignettes","text":"Coming ‘tidyverse’ quick summary selection syntax {datawizard}","code":""},{"path":"https://easystats.github.io/datawizard/articles/overview_of_vignettes.html","id":"statistical-transformations","dir":"Articles","previous_headings":"","what":"Statistical Transformations","title":"Overview of Vignettes","text":"Data Standardization","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"quoted-names","dir":"Articles","previous_headings":"Selecting variables","what":"Quoted names","title":"A quick summary of selection syntax in `{datawizard}`","text":"simple way select one several variables. Just use character vector containing variables names, like base R.","code":"data_select(iris, c(\"Sepal.Length\", \"Petal.Width\")) #>    Sepal.Length Petal.Width #> 1           4.3         0.1 #> 2           5.0         0.2 #> 3           7.7         2.2 #> 4           4.4         0.2 #> 5           5.9         1.8 #> 6           6.5         2.0 #> 7           5.5         1.3 #> 8           5.5         1.2 #> 9           5.8         1.9 #> 10          6.1         1.4"},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"unquoted-names","dir":"Articles","previous_headings":"Selecting variables","what":"Unquoted names","title":"A quick summary of selection syntax in `{datawizard}`","text":"also possible use unquoted names. useful use tidyverse want consistent way variable names passed.","code":"iris %>%   group_by(Species) %>%   standardise(Petal.Length) %>%   ungroup() #> # A tibble: 10 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species    #>           <dbl>       <dbl>        <dbl>       <dbl> <fct>      #>  1          4.3         3         -1.09          0.1 setosa     #>  2          5           3.3        0.873         0.2 setosa     #>  3          7.7         3.8        1.50          2.2 virginica  #>  4          4.4         3.2        0.218         0.2 setosa     #>  5          5.9         3         -0.542         1.8 virginica  #>  6          6.5         3         -0.414         2   virginica  #>  7          5.5         2.5       -1.09          1.3 versicolor #>  8          5.5         2.6        0.218         1.2 versicolor #>  9          5.8         2.7       -0.542         1.9 virginica  #> 10          6.1         3          0.873         1.4 versicolor"},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"positions","dir":"Articles","previous_headings":"Selecting variables","what":"Positions","title":"A quick summary of selection syntax in `{datawizard}`","text":"addition variable names, select can also take indices variables select dataframe.","code":"data_select(iris, c(1, 2, 5)) #>    Sepal.Length Sepal.Width    Species #> 1           4.3         3.0     setosa #> 2           5.0         3.3     setosa #> 3           7.7         3.8  virginica #> 4           4.4         3.2     setosa #> 5           5.9         3.0  virginica #> 6           6.5         3.0  virginica #> 7           5.5         2.5 versicolor #> 8           5.5         2.6 versicolor #> 9           5.8         2.7  virginica #> 10          6.1         3.0 versicolor"},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"functions","dir":"Articles","previous_headings":"Selecting variables","what":"Functions","title":"A quick summary of selection syntax in `{datawizard}`","text":"can also pass function select argument. function applied columns return TRUE FALSE. example, want keep numeric columns, can use .numeric. Note can provide custom function select, provided returns TRUE FALSE applied column.","code":"data_select(iris, is.numeric) #>    Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1           4.3         3.0          1.1         0.1 #> 2           5.0         3.3          1.4         0.2 #> 3           7.7         3.8          6.7         2.2 #> 4           4.4         3.2          1.3         0.2 #> 5           5.9         3.0          5.1         1.8 #> 6           6.5         3.0          5.2         2.0 #> 7           5.5         2.5          4.0         1.3 #> 8           5.5         2.6          4.4         1.2 #> 9           5.8         2.7          5.1         1.9 #> 10          6.1         3.0          4.6         1.4 my_function <- function(i) {   is.numeric(i) && mean(i, na.rm = TRUE) > 3.5 }  data_select(iris, my_function) #>    Sepal.Length Petal.Length #> 1           4.3          1.1 #> 2           5.0          1.4 #> 3           7.7          6.7 #> 4           4.4          1.3 #> 5           5.9          5.1 #> 6           6.5          5.2 #> 7           5.5          4.0 #> 8           5.5          4.4 #> 9           5.8          5.1 #> 10          6.1          4.6"},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"patterns","dir":"Articles","previous_headings":"Selecting variables","what":"Patterns","title":"A quick summary of selection syntax in `{datawizard}`","text":"larger datasets, tedious write names variables select, fragile rely variable positions may change later. end, can use four select helpers: starts_with(), ends_with(), contains(), regex(). first three can take several patterns, regex() takes single regular expression. Note: functions exported datawizard detected applied internally. means won’t detected autocompletion write . Note #2: functions exported, create conflicts ones come tidyverse name. Therefore, can still use dplyr friends, won’t change anything selection datawizard functions!","code":"data_select(iris, starts_with(\"Sep\", \"Peta\")) #>    Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1           4.3         3.0          1.1         0.1 #> 2           5.0         3.3          1.4         0.2 #> 3           7.7         3.8          6.7         2.2 #> 4           4.4         3.2          1.3         0.2 #> 5           5.9         3.0          5.1         1.8 #> 6           6.5         3.0          5.2         2.0 #> 7           5.5         2.5          4.0         1.3 #> 8           5.5         2.6          4.4         1.2 #> 9           5.8         2.7          5.1         1.9 #> 10          6.1         3.0          4.6         1.4  data_select(iris, ends_with(\"dth\", \"ies\")) #>    Sepal.Width Petal.Width    Species #> 1          3.0         0.1     setosa #> 2          3.3         0.2     setosa #> 3          3.8         2.2  virginica #> 4          3.2         0.2     setosa #> 5          3.0         1.8  virginica #> 6          3.0         2.0  virginica #> 7          2.5         1.3 versicolor #> 8          2.6         1.2 versicolor #> 9          2.7         1.9  virginica #> 10         3.0         1.4 versicolor  data_select(iris, contains(\"pal\", \"ec\")) #>    Sepal.Length Sepal.Width    Species #> 1           4.3         3.0     setosa #> 2           5.0         3.3     setosa #> 3           7.7         3.8  virginica #> 4           4.4         3.2     setosa #> 5           5.9         3.0  virginica #> 6           6.5         3.0  virginica #> 7           5.5         2.5 versicolor #> 8           5.5         2.6 versicolor #> 9           5.8         2.7  virginica #> 10          6.1         3.0 versicolor  data_select(iris, regex(\"^Sep|ies\")) #>    Sepal.Length Sepal.Width    Species #> 1           4.3         3.0     setosa #> 2           5.0         3.3     setosa #> 3           7.7         3.8  virginica #> 4           4.4         3.2     setosa #> 5           5.9         3.0  virginica #> 6           6.5         3.0  virginica #> 7           5.5         2.5 versicolor #> 8           5.5         2.6 versicolor #> 9           5.8         2.7  virginica #> 10          6.1         3.0 versicolor"},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"excluding-variables","dir":"Articles","previous_headings":"","what":"Excluding variables","title":"A quick summary of selection syntax in `{datawizard}`","text":"want keep variables except ones? two ways can invert selection. first way put minus sign \"-\" front select argument. Note use numeric indices, can’t mix negative positive values. means use select = -(1:2) want exclude first two columns; select = -1:2 work: thing variable names: second way use argument exclude. argument possibilities select. Although may required contexts, wanted , use select exclude arguments time.","code":"data_select(iris, -c(\"Sepal.Length\", \"Petal.Width\")) #>    Sepal.Width Petal.Length    Species #> 1          3.0          1.1     setosa #> 2          3.3          1.4     setosa #> 3          3.8          6.7  virginica #> 4          3.2          1.3     setosa #> 5          3.0          5.1  virginica #> 6          3.0          5.2  virginica #> 7          2.5          4.0 versicolor #> 8          2.6          4.4 versicolor #> 9          2.7          5.1  virginica #> 10         3.0          4.6 versicolor  data_select(iris, -starts_with(\"Sep\", \"Peta\")) #>       Species #> 1      setosa #> 2      setosa #> 3   virginica #> 4      setosa #> 5   virginica #> 6   virginica #> 7  versicolor #> 8  versicolor #> 9   virginica #> 10 versicolor  data_select(iris, -is.numeric) #>       Species #> 1      setosa #> 2      setosa #> 3   virginica #> 4      setosa #> 5   virginica #> 6   virginica #> 7  versicolor #> 8  versicolor #> 9   virginica #> 10 versicolor data_select(iris, -(1:2)) #>    Petal.Length Petal.Width    Species #> 1           1.1         0.1     setosa #> 2           1.4         0.2     setosa #> 3           6.7         2.2  virginica #> 4           1.3         0.2     setosa #> 5           5.1         1.8  virginica #> 6           5.2         2.0  virginica #> 7           4.0         1.3 versicolor #> 8           4.4         1.2 versicolor #> 9           5.1         1.9  virginica #> 10          4.6         1.4 versicolor data_select(iris, -(Petal.Length:Species)) #>    Sepal.Length Sepal.Width #> 1           4.3         3.0 #> 2           5.0         3.3 #> 3           7.7         3.8 #> 4           4.4         3.2 #> 5           5.9         3.0 #> 6           6.5         3.0 #> 7           5.5         2.5 #> 8           5.5         2.6 #> 9           5.8         2.7 #> 10          6.1         3.0 data_select(iris, exclude = c(\"Sepal.Length\", \"Petal.Width\")) #>    Sepal.Width Petal.Length    Species #> 1          3.0          1.1     setosa #> 2          3.3          1.4     setosa #> 3          3.8          6.7  virginica #> 4          3.2          1.3     setosa #> 5          3.0          5.1  virginica #> 6          3.0          5.2  virginica #> 7          2.5          4.0 versicolor #> 8          2.6          4.4 versicolor #> 9          2.7          5.1  virginica #> 10         3.0          4.6 versicolor  data_select(iris, exclude = starts_with(\"Sep\", \"Peta\")) #>       Species #> 1      setosa #> 2      setosa #> 3   virginica #> 4      setosa #> 5   virginica #> 6   virginica #> 7  versicolor #> 8  versicolor #> 9   virginica #> 10 versicolor"},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"programming-with-selections","dir":"Articles","previous_headings":"","what":"Programming with selections","title":"A quick summary of selection syntax in `{datawizard}`","text":"Since datawizard 0.6.0, possible pass function arguments loop indices select exclude arguments. makes easier program datawizard. example, want let user decide selection want use: also possible pass values loops, example list patterns want relocate columns based patterns, one one: loop , columns starting \"Sep\" moved end data frame, thing made columns starting \"Pet\".","code":"my_function <- function(data, selection) {   extract_column_names(data, select = selection) } my_function(iris, \"Sepal.Length\") #> [1] \"Sepal.Length\" my_function(iris, starts_with(\"Sep\")) #> [1] \"Sepal.Length\" \"Sepal.Width\"  my_function_2 <- function(data, pattern) {   extract_column_names(data, select = starts_with(pattern)) } my_function_2(iris, \"Sep\") #> [1] \"Sepal.Length\" \"Sepal.Width\" new_iris <- iris for (i in c(\"Sep\", \"Pet\")) {   new_iris <- new_iris %>%     data_relocate(select = starts_with(i), after = -1) } new_iris #>       Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1      setosa          4.3         3.0          1.1         0.1 #> 2      setosa          5.0         3.3          1.4         0.2 #> 3   virginica          7.7         3.8          6.7         2.2 #> 4      setosa          4.4         3.2          1.3         0.2 #> 5   virginica          5.9         3.0          5.1         1.8 #> 6   virginica          6.5         3.0          5.2         2.0 #> 7  versicolor          5.5         2.5          4.0         1.3 #> 8  versicolor          5.5         2.6          4.4         1.2 #> 9   virginica          5.8         2.7          5.1         1.9 #> 10 versicolor          6.1         3.0          4.6         1.4"},{"path":[]},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"ignore-the-case","dir":"Articles","previous_headings":"Useful to know","what":"Ignore the case","title":"A quick summary of selection syntax in `{datawizard}`","text":"every selection uses variable names, can ignore case selection applying ignore_case = TRUE.","code":"data_select(iris, c(\"sepal.length\", \"petal.width\"), ignore_case = TRUE) #>    Sepal.Length Petal.Width #> 1           4.3         0.1 #> 2           5.0         0.2 #> 3           7.7         2.2 #> 4           4.4         0.2 #> 5           5.9         1.8 #> 6           6.5         2.0 #> 7           5.5         1.3 #> 8           5.5         1.2 #> 9           5.8         1.9 #> 10          6.1         1.4  data_select(iris, ~ Sepal.length + petal.Width, ignore_case = TRUE) #>    Sepal.Length Petal.Width #> 1           4.3         0.1 #> 2           5.0         0.2 #> 3           7.7         2.2 #> 4           4.4         0.2 #> 5           5.9         1.8 #> 6           6.5         2.0 #> 7           5.5         1.3 #> 8           5.5         1.2 #> 9           5.8         1.9 #> 10          6.1         1.4  data_select(iris, starts_with(\"sep\", \"peta\"), ignore_case = TRUE) #>    Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1           4.3         3.0          1.1         0.1 #> 2           5.0         3.3          1.4         0.2 #> 3           7.7         3.8          6.7         2.2 #> 4           4.4         3.2          1.3         0.2 #> 5           5.9         3.0          5.1         1.8 #> 6           6.5         3.0          5.2         2.0 #> 7           5.5         2.5          4.0         1.3 #> 8           5.5         2.6          4.4         1.2 #> 9           5.8         2.7          5.1         1.9 #> 10          6.1         3.0          4.6         1.4"},{"path":"https://easystats.github.io/datawizard/articles/selection_syntax.html","id":"formulas","dir":"Articles","previous_headings":"Useful to know","what":"Formulas","title":"A quick summary of selection syntax in `{datawizard}`","text":"also possible use formulas select variables: made easier use selection custom functions datawizard 0.6.0, kept available backward compatibility.","code":"data_select(iris, ~ Sepal.Length + Petal.Width) #>    Sepal.Length Petal.Width #> 1           4.3         0.1 #> 2           5.0         0.2 #> 3           7.7         2.2 #> 4           4.4         0.2 #> 5           5.9         1.8 #> 6           6.5         2.0 #> 7           5.5         1.3 #> 8           5.5         1.2 #> 9           5.8         1.9 #> 10          6.1         1.4"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Data Standardization","text":"make sense data effects, scientists might want standardize (Z-score) variables. makes data unitless, expressed terms deviation index centrality (e.g., mean median). However, aside benefits, standardization also comes challenges issues, scientist aware .","code":""},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"methods-of-standardization","dir":"Articles","previous_headings":"Introduction","what":"Methods of Standardization","title":"Data Standardization","text":"datawizard package offers two methods standardization via standardize() function: Normal standardization: center around mean, SD units (default). Robust standardization: center around median, MAD (median absolute deviation) units (robust = TRUE). Let’s look following example: can see different methods give different central variation values: standardize() can also used standardize full data frame - numeric variable standardized separately: Weighted standardization also supported via weights argument, factors can also standardized (’re kind thing) setting force = TRUE, converts factors treatment-coded dummy variables standardizing.","code":"library(datawizard) library(effectsize) # for data  # let's have a look at what the data look like data(\"hardlyworking\", package = \"effectsize\") head(hardlyworking) #>     salary xtra_hours n_comps age seniority is_senior #> 1 19744.65       4.16       1  32         3     FALSE #> 2 11301.95       1.62       0  34         3     FALSE #> 3 20635.62       1.19       3  33         5      TRUE #> 4 23047.16       7.19       1  35         3     FALSE #> 5 27342.15      11.26       0  33         4     FALSE #> 6 25656.63       3.63       2  30         5      TRUE # let's use both methods of standardization hardlyworking$xtra_hours_z <- standardize(hardlyworking$xtra_hours) hardlyworking$xtra_hours_zr <- standardize(hardlyworking$xtra_hours, robust = TRUE) library(dplyr)  hardlyworking %>%   select(starts_with(\"xtra_hours\")) %>%   data_to_long() %>%   group_by(Name) %>%   summarise(     mean = mean(Value),     sd = sd(Value),     median = median(Value),     mad = mad(Value)   ) hardlyworking_z <- standardize(hardlyworking) hardlyworking_z %>%   select(-xtra_hours_z, -xtra_hours_zr) %>%   data_to_long() %>%   group_by(Name) %>%   summarise(     mean = mean(Value),     sd = sd(Value),     median = median(Value),     mad = mad(Value)   )"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"variable-wise-vs--participant-wise","dir":"Articles","previous_headings":"Introduction","what":"Variable-wise vs. Participant-wise","title":"Data Standardization","text":"Standardization important step extra caution required repeated-measures designs, three ways standardizing data: Variable-wise: common method. simple scaling column. Participant-wise: Variables standardized “within” participant, .e., participant, participant’s mean SD. Full: Participant-wise first re-standardizing variable-wise. Unfortunately, method used often explicitly stated. issue methods can generate important discrepancies (can turn contribute reproducibility crisis). Let’s investigate 3 methods.","code":""},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"the-data","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"The Data","title":"Data Standardization","text":"take emotion dataset participants exposed negative pictures rate emotions (valence) amount memories associated picture (autobiographical link). One make hypothesis young participants context war violence, negative pictures (mutilations) less related memories less negative pictures (involving example car crashes sick people). words, expect positive relationship valence (high values corresponding less negativity) autobiographical link. Let’s look data, averaged participants: can see means SDs, lot variability participants means individual within-participant SD.","code":"# Download the 'emotion' dataset load(url(\"https://raw.githubusercontent.com/neuropsychology/psycho.R/master/data/emotion.rda\"))  # Discard neutral pictures (keep only negative) emotion <- emotion %>% filter(Emotion_Condition == \"Negative\")  # Summary emotion %>%   drop_na(Subjective_Valence, Autobiographical_Link) %>%   group_by(Participant_ID) %>%   summarise(     n_Trials = n(),     Valence_Mean = mean(Subjective_Valence),     Valence_SD = sd(Subjective_Valence)   ) #> # A tibble: 19 × 4 #> # Groups:   Participant_ID [19] #>    Participant_ID n_Trials Valence_Mean Valence_SD #>    <fct>             <int>        <dbl>      <dbl> #>  1 10S                  24       -58.1       42.6  #>  2 11S                  24       -73.2       37.0  #>  3 12S                  24       -57.5       26.6  #>  4 13S                  24       -63.2       23.7  #>  5 14S                  24       -56.6       26.5  #>  6 15S                  24       -60.6       33.7  #>  7 16S                  24       -46.1       24.9  #>  8 17S                  24        -1.54       4.98 #>  9 18S                  24       -67.2       35.0  #> 10 19S                  24       -59.6       33.2  #> 11 1S                   24       -53.0       42.9  #> 12 2S                   23       -43.0       39.2  #> 13 3S                   24       -64.3       34.4  #> 14 4S                   24       -81.6       27.6  #> 15 5S                   24       -58.1       25.3  #> 16 6S                   24       -74.7       29.2  #> 17 7S                   24       -62.3       39.7  #> 18 8S                   24       -56.9       32.7  #> 19 9S                   24       -31.5       52.7"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"effect-of-standardization","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Effect of Standardization","title":"Data Standardization","text":"create three data frames standardized three techniques. Let’s see three standardization techniques affected Valence variable.","code":"Z_VariableWise <- emotion %>%   standardize()  Z_ParticipantWise <- emotion %>%   group_by(Participant_ID) %>%   standardize()  Z_Full <- emotion %>%   group_by(Participant_ID) %>%   standardize() %>%   ungroup() %>%   standardize()"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"across-participants","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Across Participants","title":"Data Standardization","text":"can calculate mean SD Valence across participants: means SD appear fairly similar (0 1)…  marginal distributions…","code":"# Create a convenient function to print summarise_Subjective_Valence <- function(data) {   df_name <- deparse(substitute(data))   data %>%     ungroup() %>%     summarise(       DF = df_name,       Mean = mean(Subjective_Valence),       SD = sd(Subjective_Valence)     ) } # Check the results rbind(   summarise_Subjective_Valence(Z_VariableWise),   summarise_Subjective_Valence(Z_ParticipantWise),   summarise_Subjective_Valence(Z_Full) ) library(see) library(ggplot2)  ggplot() +   geom_density(aes(Z_VariableWise$Subjective_Valence,     color = \"Z_VariableWise\"   ), linewidth = 1) +   geom_density(aes(Z_ParticipantWise$Subjective_Valence,     color = \"Z_ParticipantWise\"   ), linewidth = 1) +   geom_density(aes(Z_Full$Subjective_Valence,     color = \"Z_Full\"   ), linewidth = 1) +   see::theme_modern() +   labs(color = \"\")"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"at-the-participant-level","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"At the Participant Level","title":"Data Standardization","text":"However, can also look happens participant level. Let’s look first 5 participants: Seems like full participant-wise standardization give similar results, different ones variable-wise standardization.","code":"# Create convenient function print_participants <- function(data) {   df_name <- deparse(substitute(data))   data %>%     group_by(Participant_ID) %>%     summarise(       DF = df_name,       Mean = mean(Subjective_Valence),       SD = sd(Subjective_Valence)     ) %>%     head(5) %>%     select(DF, everything()) }  # Check the results rbind(   print_participants(Z_VariableWise),   print_participants(Z_ParticipantWise),   print_participants(Z_Full) )"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"compare","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Compare","title":"Data Standardization","text":"Let’s correlation variable-wise participant-wise methods.  three standardization methods roughly present characteristics general level (mean 0 SD 1) similar distribution, values exactly ! Let’s now answer original question investigating linear relationship valence autobiographical link. can running mixed-effects model participants entered random effects. can extract parameters interest model, find: can see, variable-wise standardization affects coefficient (expected, changes unit), test statistic statistical significance. However, using participant-wise standardization affect coefficient significance. method better justified, choice depends specific case, context, data goal.","code":"r <- cor.test(   Z_VariableWise$Subjective_Valence,   Z_ParticipantWise$Subjective_Valence )  data.frame(   Original = emotion$Subjective_Valence,   VariableWise = Z_VariableWise$Subjective_Valence,   ParticipantWise = Z_ParticipantWise$Subjective_Valence ) %>%   ggplot(aes(x = VariableWise, y = ParticipantWise, colour = Original)) +   geom_point(alpha = 0.75, shape = 16) +   geom_smooth(method = \"lm\", color = \"black\") +   scale_color_distiller(palette = 1) +   ggtitle(paste0(\"r = \", round(r$estimate, 2))) +   see::theme_modern() library(lme4) m_raw <- lmer(   formula = Subjective_Valence ~ Autobiographical_Link + (1 | Participant_ID),   data = emotion ) m_VariableWise <- update(m_raw, data = Z_VariableWise) m_ParticipantWise <- update(m_raw, data = Z_ParticipantWise) m_Full <- update(m_raw, data = Z_Full) # Convenient function get_par <- function(model) {   mod_name <- deparse(substitute(model))   parameters::model_parameters(model) %>%     mutate(Model = mod_name) %>%     select(-Parameter) %>%     select(Model, everything()) %>%     .[-1, ] }  # Run the model on all datasets rbind(   get_par(m_raw),   get_par(m_VariableWise),   get_par(m_ParticipantWise),   get_par(m_Full) ) #> # Fixed Effects #>  #> Model             | Coefficient |   SE |        95% CI | t(451) |     p #> ----------------------------------------------------------------------- #> m_raw             |        0.09 | 0.07 | [-0.04, 0.22] |   1.36 | 0.174 #> m_VariableWise    |        0.07 | 0.05 | [-0.03, 0.17] |   1.36 | 0.174 #> m_ParticipantWise |        0.08 | 0.05 | [-0.01, 0.17] |   1.75 | 0.080 #> m_Full            |        0.08 | 0.05 | [-0.01, 0.17] |   1.75 | 0.080 #>  #> # Random Effects: Participant_ID #>  #> Model             | Coefficient #> ------------------------------- #> m_raw             |       16.49 #> m_VariableWise    |        0.45 #> m_ParticipantWise |        0.00 #> m_Full            |        0.00 #>  #> # Random Effects: Residual #>  #> Model             | Coefficient #> ------------------------------- #> m_raw             |       33.56 #> m_VariableWise    |        0.91 #> m_ParticipantWise |        0.98 #> m_Full            |        1.00"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"conclusion","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Conclusion","title":"Data Standardization","text":"Standardization can useful cases justified. Variable Participant-wise standardization methods appear produce similar data. Variable Participant-wise standardization can lead different results. chosen method can strongly influence results therefore explicitly stated justified enhance reproducibility results. showed yet another way sneakily tweaking data can change results. prevent use bad practice, can highlight importance open data, open analysis/scripts, preregistration.","code":""},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See also","title":"Data Standardization","text":"datawizard::demean(): https://easystats.github.io/datawizard/reference/demean.html standardize_parameters(method = \"pseudo\") mixed-effects models https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Coming from 'tidyverse'","text":"datawizard package aims make basic data wrangling easier base R. data wrangling workflow supports similar one supported tidyverse package combination dplyr tidyr. However, one main features dependencies: {stats} {utils} (included base R) insight, core package easystats ecosystem. package grew organically simultaneously satisfy “0 non-base hard dependency” principle easystats data wrangling needs constituent packages ecosystem. also important note datawizard designed avoid namespace collisions tidyverse packages. article, see go basic data wrangling steps datawizard. also compare tidyverse syntax achieving . way, decide make switch, can easily find translations . vignette largely inspired dplyr’s Getting started vignette. Note: vignette, use native pipe-operator, |>, introduced R 4.1. Users R version 3.6 4.0 replace native pipe magrittr’s one (%>%) examples work.","code":"library(dplyr) library(tidyr) library(datawizard)  data(efc) efc <- head(efc)"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"workhorses","dir":"Articles","previous_headings":"","what":"Workhorses","title":"Coming from 'tidyverse'","text":"look tidyverse equivalents, can first look datawizard’s key functions data wrangling: Note functions datawizard strict equivalent dplyr tidyr (e.g data_rotate()), won’t discuss next section.","code":""},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"equivalence-with-dplyr-tidyr","dir":"Articles","previous_headings":"","what":"Equivalence with {dplyr} / {tidyr}","title":"Coming from 'tidyverse'","text":"look individually, let’s first look summary table equivalence.","code":""},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"filtering","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Filtering","title":"Coming from 'tidyverse'","text":"data_filter() wrapper around subset(). However, want several filtering conditions, can either use & (subset()) , (dplyr::filter()).","code":"# ---------- datawizard ----------- starwars |>   data_filter(     skin_color == \"light\",     eye_color == \"brown\"   )  # or starwars |>   data_filter(     skin_color == \"light\" &       eye_color == \"brown\"   ) # ---------- tidyverse ----------- starwars |>   filter(     skin_color == \"light\",     eye_color == \"brown\"   ) ## # A tibble: 7 × 14 ##   name      height  mass hair_color skin_color eye_color birth_year sex   gender ## * <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr>  ## 1 Leia Org…    150    49 brown      light      brown             19 fema… femin… ## 2 Biggs Da…    183    84 black      light      brown             24 male  mascu… ## 3 Padmé Am…    185    45 brown      light      brown             46 fema… femin… ## 4 Cordé        157    NA brown      light      brown             NA NA    NA     ## 5 Dormé        165    NA brown      light      brown             NA fema… femin… ## 6 Raymus A…    188    79 brown      light      brown             NA male  mascu… ## 7 Poe Dame…     NA    NA brown      light      brown             NA male  mascu… ## # ℹ 5 more variables: homeworld <chr>, species <chr>, films <list>, ## #   vehicles <list>, starships <list> ## # A tibble: 7 × 14 ##   name      height  mass hair_color skin_color eye_color birth_year sex   gender ## * <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr>  ## 1 Leia Org…    150    49 brown      light      brown             19 fema… femin… ## 2 Biggs Da…    183    84 black      light      brown             24 male  mascu… ## 3 Padmé Am…    185    45 brown      light      brown             46 fema… femin… ## 4 Cordé        157    NA brown      light      brown             NA NA    NA     ## 5 Dormé        165    NA brown      light      brown             NA fema… femin… ## 6 Raymus A…    188    79 brown      light      brown             NA male  mascu… ## 7 Poe Dame…     NA    NA brown      light      brown             NA male  mascu… ## # ℹ 5 more variables: homeworld <chr>, species <chr>, films <list>, ## #   vehicles <list>, starships <list>"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"selecting","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Selecting","title":"Coming from 'tidyverse'","text":"data_select() equivalent dplyr::select(). main difference two functions data_select() uses two arguments (select exclude) requires quoted column names want select several variables, dplyr::select() accepts unquoted column names. can find list select helpers ?data_select.","code":"# ---------- datawizard ----------- starwars |>   data_select(select = c(\"hair_color\", \"skin_color\", \"eye_color\")) # ---------- tidyverse ----------- starwars |>   select(hair_color, skin_color, eye_color) ## # A tibble: 6 × 3 ##   hair_color  skin_color  eye_color ##   <chr>       <chr>       <chr>     ## 1 blond       fair        blue      ## 2 NA          gold        yellow    ## 3 NA          white, blue red       ## 4 none        white       yellow    ## 5 brown       light       brown     ## 6 brown, grey light       blue # ---------- datawizard ----------- starwars |>   data_select(select = -ends_with(\"color\")) # ---------- tidyverse ----------- starwars |>   select(-ends_with(\"color\")) ## # A tibble: 6 × 11 ##   name     height  mass birth_year sex   gender homeworld species films vehicles ##   <chr>     <int> <dbl>      <dbl> <chr> <chr>  <chr>     <chr>   <lis> <list>   ## 1 Luke Sk…    172    77       19   male  mascu… Tatooine  Human   <chr> <chr>    ## 2 C-3PO       167    75      112   none  mascu… Tatooine  Droid   <chr> <chr>    ## 3 R2-D2        96    32       33   none  mascu… Naboo     Droid   <chr> <chr>    ## 4 Darth V…    202   136       41.9 male  mascu… Tatooine  Human   <chr> <chr>    ## 5 Leia Or…    150    49       19   fema… femin… Alderaan  Human   <chr> <chr>    ## 6 Owen La…    178   120       52   male  mascu… Tatooine  Human   <chr> <chr>    ## # ℹ 1 more variable: starships <list> # ---------- datawizard ----------- starwars |>   data_select(select = -(hair_color:eye_color)) # ---------- tidyverse ----------- starwars |>   select(!(hair_color:eye_color)) ## # A tibble: 6 × 11 ##   name     height  mass birth_year sex   gender homeworld species films vehicles ##   <chr>     <int> <dbl>      <dbl> <chr> <chr>  <chr>     <chr>   <lis> <list>   ## 1 Luke Sk…    172    77       19   male  mascu… Tatooine  Human   <chr> <chr>    ## 2 C-3PO       167    75      112   none  mascu… Tatooine  Droid   <chr> <chr>    ## 3 R2-D2        96    32       33   none  mascu… Naboo     Droid   <chr> <chr>    ## 4 Darth V…    202   136       41.9 male  mascu… Tatooine  Human   <chr> <chr>    ## 5 Leia Or…    150    49       19   fema… femin… Alderaan  Human   <chr> <chr>    ## 6 Owen La…    178   120       52   male  mascu… Tatooine  Human   <chr> <chr>    ## # ℹ 1 more variable: starships <list> # ---------- datawizard ----------- starwars |>   data_select(exclude = regex(\"color$\")) # ---------- tidyverse ----------- starwars |>   select(-contains(\"color$\")) ## # A tibble: 6 × 11 ##   name     height  mass birth_year sex   gender homeworld species films vehicles ##   <chr>     <int> <dbl>      <dbl> <chr> <chr>  <chr>     <chr>   <lis> <list>   ## 1 Luke Sk…    172    77       19   male  mascu… Tatooine  Human   <chr> <chr>    ## 2 C-3PO       167    75      112   none  mascu… Tatooine  Droid   <chr> <chr>    ## 3 R2-D2        96    32       33   none  mascu… Naboo     Droid   <chr> <chr>    ## 4 Darth V…    202   136       41.9 male  mascu… Tatooine  Human   <chr> <chr>    ## 5 Leia Or…    150    49       19   fema… femin… Alderaan  Human   <chr> <chr>    ## 6 Owen La…    178   120       52   male  mascu… Tatooine  Human   <chr> <chr>    ## # ℹ 1 more variable: starships <list> # ---------- datawizard ----------- starwars |>   data_select(select = is.numeric) # ---------- tidyverse ----------- starwars |>   select(where(is.numeric)) ## # A tibble: 6 × 3 ##   height  mass birth_year ##    <int> <dbl>      <dbl> ## 1    172    77       19   ## 2    167    75      112   ## 3     96    32       33   ## 4    202   136       41.9 ## 5    150    49       19   ## 6    178   120       52"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"modifying","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Modifying","title":"Coming from 'tidyverse'","text":"data_modify() wrapper around base::transform() several additional benefits: allows us use newly created variables following expressions; works grouped data; preserves variable attributes labels; accepts expressions character vectors easy program last point also main difference data_modify() dplyr::mutate(). data_modify() supports expressions strings via as_expr() helper function. makes easy use custom functions:","code":"# ---------- datawizard ----------- efc |>   data_modify(     c12hour_c = center(c12hour),     c12hour_z = c12hour_c / sd(c12hour, na.rm = TRUE),     c12hour_z2 = standardize(c12hour)   ) # ---------- tidyverse ----------- efc |>   mutate(     c12hour_c = center(c12hour),     c12hour_z = c12hour_c / sd(c12hour, na.rm = TRUE),     c12hour_z2 = standardize(c12hour)   ) ##   c12hour e16sex e42dep c172code neg_c_7 c12hour_c  c12hour_z c12hour_z2 ## 1      16      2      3        2      12     -67.6 -0.9420928 -0.9420928 ## 2     148      2      3        2      20      64.4  0.8974967  0.8974967 ## 3      70      2      3        1      11     -13.6 -0.1895335 -0.1895335 ## 4      NA      2   <NA>        2      10        NA         NA         NA ## 5     168      2      4        2      12      84.4  1.1762224  1.1762224 ## 6      16      2      4        2      19     -67.6 -0.9420928 -0.9420928 new_exp <- c(   \"c12hour_c = center(c12hour)\",   \"c12hour_z = c12hour_c / sd(c12hour, na.rm = TRUE)\" ) data_modify(efc, as_expr(new_exp)) ##   c12hour e16sex e42dep c172code neg_c_7 c12hour_c  c12hour_z ## 1      16      2      3        2      12     -67.6 -0.9420928 ## 2     148      2      3        2      20      64.4  0.8974967 ## 3      70      2      3        1      11     -13.6 -0.1895335 ## 4      NA      2   <NA>        2      10        NA         NA ## 5     168      2      4        2      12      84.4  1.1762224 ## 6      16      2      4        2      19     -67.6 -0.9420928 miles_to_km <- function(data, var) {   data_modify(     data,     as_expr(paste0(\"km = \", var, \"* 1.609344\"))   ) }  distance <- data.frame(miles = c(1, 8, 233, 88, 9)) distance ##   miles ## 1     1 ## 2     8 ## 3   233 ## 4    88 ## 5     9 miles_to_km(distance, \"miles\") ##   miles         km ## 1     1   1.609344 ## 2     8  12.874752 ## 3   233 374.977152 ## 4    88 141.622272 ## 5     9  14.484096"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"sorting","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Sorting","title":"Coming from 'tidyverse'","text":"data_arrange() equivalent dplyr::arrange(). takes two arguments: data frame, vector column names used sort rows. Note contrary functions datawizard, possible use select helpers starts_with() data_arrange(). can also sort variables descending order putting \"-\" front name, like :","code":"# ---------- datawizard ----------- starwars |>   data_arrange(c(\"hair_color\", \"height\")) # ---------- tidyverse ----------- starwars |>   arrange(hair_color, height) ##             name height mass  hair_color  skin_color eye_color birth_year ## 1 Luke Skywalker    172   77       blond        fair      blue       19.0 ## 2    Leia Organa    150   49       brown       light     brown       19.0 ## 3      Owen Lars    178  120 brown, grey       light      blue       52.0 ## 4    Darth Vader    202  136        none       white    yellow       41.9 ## 5          R2-D2     96   32        <NA> white, blue       red       33.0 ## 6          C-3PO    167   75        <NA>        gold    yellow      112.0 ##      sex    gender homeworld species ## 1   male masculine  Tatooine   Human ## 2 female  feminine  Alderaan   Human ## 3   male masculine  Tatooine   Human ## 4   male masculine  Tatooine   Human ## 5   none masculine     Naboo   Droid ## 6   none masculine  Tatooine   Droid ##                                                                                                                                       films ## 1                                           A New Hope, The Empire Strikes Back, Return of the Jedi, Revenge of the Sith, The Force Awakens ## 2                                           A New Hope, The Empire Strikes Back, Return of the Jedi, Revenge of the Sith, The Force Awakens ## 3                                                                                     A New Hope, Attack of the Clones, Revenge of the Sith ## 4                                                              A New Hope, The Empire Strikes Back, Return of the Jedi, Revenge of the Sith ## 5 A New Hope, The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, Revenge of the Sith, The Force Awakens ## 6                    A New Hope, The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, Revenge of the Sith ##                             vehicles                starships ## 1 Snowspeeder, Imperial Speeder Bike X-wing, Imperial shuttle ## 2              Imperial Speeder Bike                          ## 3                                                             ## 4                                             TIE Advanced x1 ## 5                                                             ## 6 # ---------- datawizard ----------- starwars |>   data_arrange(c(\"-hair_color\", \"-height\")) # ---------- tidyverse ----------- starwars |>   arrange(desc(hair_color), -height) ##             name height mass  hair_color  skin_color eye_color birth_year ## 1    Darth Vader    202  136        none       white    yellow       41.9 ## 2      Owen Lars    178  120 brown, grey       light      blue       52.0 ## 3    Leia Organa    150   49       brown       light     brown       19.0 ## 4 Luke Skywalker    172   77       blond        fair      blue       19.0 ## 5          C-3PO    167   75        <NA>        gold    yellow      112.0 ## 6          R2-D2     96   32        <NA> white, blue       red       33.0 ##      sex    gender homeworld species ## 1   male masculine  Tatooine   Human ## 2   male masculine  Tatooine   Human ## 3 female  feminine  Alderaan   Human ## 4   male masculine  Tatooine   Human ## 5   none masculine  Tatooine   Droid ## 6   none masculine     Naboo   Droid ##                                                                                                                                       films ## 1                                                              A New Hope, The Empire Strikes Back, Return of the Jedi, Revenge of the Sith ## 2                                                                                     A New Hope, Attack of the Clones, Revenge of the Sith ## 3                                           A New Hope, The Empire Strikes Back, Return of the Jedi, Revenge of the Sith, The Force Awakens ## 4                                           A New Hope, The Empire Strikes Back, Return of the Jedi, Revenge of the Sith, The Force Awakens ## 5                    A New Hope, The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, Revenge of the Sith ## 6 A New Hope, The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, Revenge of the Sith, The Force Awakens ##                             vehicles                starships ## 1                                             TIE Advanced x1 ## 2                                                             ## 3              Imperial Speeder Bike                          ## 4 Snowspeeder, Imperial Speeder Bike X-wing, Imperial shuttle ## 5                                                             ## 6"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"extracting","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Extracting","title":"Coming from 'tidyverse'","text":"Although mostly work data frames, sometimes useful extract single column vector. can done data_extract(), reproduces behavior dplyr::pull(): can also specify several variables select. case, data_extract() equivalent data_select():","code":"# ---------- datawizard ----------- starwars |>   data_extract(gender) # ---------- tidyverse ----------- starwars |>   pull(gender) ## [1] \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"feminine\"  \"masculine\" starwars |>   data_extract(select = contains(\"color\")) ## # A tibble: 6 × 3 ##   hair_color  skin_color  eye_color ##   <chr>       <chr>       <chr>     ## 1 blond       fair        blue      ## 2 NA          gold        yellow    ## 3 NA          white, blue red       ## 4 none        white       yellow    ## 5 brown       light       brown     ## 6 brown, grey light       blue"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"renaming","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Renaming","title":"Coming from 'tidyverse'","text":"data_rename() equivalent dplyr::rename() syntax two different. dplyr::rename() takes new-old pairs column names, data_rename() requires vector column names rename, vector new names columns must length. way data_rename() designed makes easy apply modifications vector column names. example, can remove underscores use TitleCase following code: also possible add prefix suffix subset variables data_addprefix() data_addsuffix(). argument select accepts select helpers saw data_select():","code":"# ---------- datawizard ----------- starwars |>   data_rename(     select = c(\"sex\", \"hair_color\"),     replacement = c(\"Sex\", \"Hair Color\")   ) # ---------- tidyverse ----------- starwars |>   rename(     Sex = sex,     \"Hair Color\" = hair_color   ) ## # A tibble: 6 × 14 ##   name    height  mass `Hair Color` skin_color eye_color birth_year Sex   gender ##   <chr>    <int> <dbl> <chr>        <chr>      <chr>          <dbl> <chr> <chr>  ## 1 Luke S…    172    77 blond        fair       blue            19   male  mascu… ## 2 C-3PO      167    75 NA           gold       yellow         112   none  mascu… ## 3 R2-D2       96    32 NA           white, bl… red             33   none  mascu… ## 4 Darth …    202   136 none         white      yellow          41.9 male  mascu… ## 5 Leia O…    150    49 brown        light      brown           19   fema… femin… ## 6 Owen L…    178   120 brown, grey  light      blue            52   male  mascu… ## # ℹ 5 more variables: homeworld <chr>, species <chr>, films <list>, ## #   vehicles <list>, starships <list> to_rename <- names(starwars)  starwars |>   data_rename(     select = to_rename,     replacement = tools::toTitleCase(gsub(\"_\", \" \", to_rename, fixed = TRUE))   ) ## # A tibble: 6 × 14 ##   Name     Height  Mass `Hair Color` `Skin Color` `Eye Color` `Birth Year` Sex   ##   <chr>     <int> <dbl> <chr>        <chr>        <chr>              <dbl> <chr> ## 1 Luke Sk…    172    77 blond        fair         blue                19   male  ## 2 C-3PO       167    75 NA           gold         yellow             112   none  ## 3 R2-D2        96    32 NA           white, blue  red                 33   none  ## 4 Darth V…    202   136 none         white        yellow              41.9 male  ## 5 Leia Or…    150    49 brown        light        brown               19   fema… ## 6 Owen La…    178   120 brown, grey  light        blue                52   male  ## # ℹ 6 more variables: Gender <chr>, Homeworld <chr>, Species <chr>, ## #   Films <list>, Vehicles <list>, Starships <list> starwars |>   data_addprefix(     pattern = \"OLD.\",     select = contains(\"color\")   ) |>   data_addsuffix(     pattern = \".NEW\",     select = -contains(\"color\")   ) ## # A tibble: 6 × 14 ##   name.NEW       height.NEW mass.NEW OLD.hair_color OLD.skin_color OLD.eye_color ##   <chr>               <int>    <dbl> <chr>          <chr>          <chr>         ## 1 Luke Skywalker        172       77 blond          fair           blue          ## 2 C-3PO                 167       75 NA             gold           yellow        ## 3 R2-D2                  96       32 NA             white, blue    red           ## 4 Darth Vader           202      136 none           white          yellow        ## 5 Leia Organa           150       49 brown          light          brown         ## 6 Owen Lars             178      120 brown, grey    light          blue          ## # ℹ 8 more variables: birth_year.NEW <dbl>, sex.NEW <chr>, gender.NEW <chr>, ## #   homeworld.NEW <chr>, species.NEW <chr>, films.NEW <list>, ## #   vehicles.NEW <list>, starships.NEW <list>"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"relocating","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Relocating","title":"Coming from 'tidyverse'","text":"Sometimes, want relocate one small subset columns dataset. Rather typing many names data_select(), can use data_relocate(), equivalent dplyr::relocate(). Just like data_select(), can specify list variables want relocate select exclude. , arguments after1 specify selected columns relocated: addition column names, accept column indices. Finally, one can use = -1 relocate selected columns just last column, = -1 relocate last column.","code":"# ---------- datawizard ----------- starwars |>   data_relocate(sex:homeworld, before = \"height\") # ---------- tidyverse ----------- starwars |>   relocate(sex:homeworld, .before = height) ## # A tibble: 6 × 14 ##   name       sex   gender homeworld height  mass hair_color skin_color eye_color ##   <chr>      <chr> <chr>  <chr>      <int> <dbl> <chr>      <chr>      <chr>     ## 1 Luke Skyw… male  mascu… Tatooine     172    77 blond      fair       blue      ## 2 C-3PO      none  mascu… Tatooine     167    75 NA         gold       yellow    ## 3 R2-D2      none  mascu… Naboo         96    32 NA         white, bl… red       ## 4 Darth Vad… male  mascu… Tatooine     202   136 none       white      yellow    ## 5 Leia Orga… fema… femin… Alderaan     150    49 brown      light      brown     ## 6 Owen Lars  male  mascu… Tatooine     178   120 brown, gr… light      blue      ## # ℹ 5 more variables: birth_year <dbl>, species <chr>, films <list>, ## #   vehicles <list>, starships <list> # ---------- datawizard ----------- starwars |>   data_relocate(sex:homeworld, after = -1) ## # A tibble: 6 × 14 ##   name     height  mass hair_color skin_color eye_color birth_year species films ##   <chr>     <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr>   <lis> ## 1 Luke Sk…    172    77 blond      fair       blue            19   Human   <chr> ## 2 C-3PO       167    75 NA         gold       yellow         112   Droid   <chr> ## 3 R2-D2        96    32 NA         white, bl… red             33   Droid   <chr> ## 4 Darth V…    202   136 none       white      yellow          41.9 Human   <chr> ## 5 Leia Or…    150    49 brown      light      brown           19   Human   <chr> ## 6 Owen La…    178   120 brown, gr… light      blue            52   Human   <chr> ## # ℹ 5 more variables: vehicles <list>, starships <list>, sex <chr>, ## #   gender <chr>, homeworld <chr>"},{"path":[]},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"longer","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Reshaping","what":"Longer","title":"Coming from 'tidyverse'","text":"Reshaping data wide long long wide format can done data_to_long() data_to_wide(). functions designed match tidyr::pivot_longer() tidyr::pivot_wider() arguments, thing change function name. However, tidyr::pivot_longer() tidyr::pivot_wider() features available yet. use relig_income dataset, {tidyr} vignette. like reshape dataset 3 columns: religion, count, income. column “religion” doesn’t need change, exclude -religion. , remaining column corresponds income category. Therefore, want move column names single column called “income”. Finally, values corresponding columns reshaped single new column, called “count”. explore bit arguments data_to_long(), use another dataset: billboard dataset.","code":"relig_income ## # A tibble: 18 × 11 ##    religion `<$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k` ##    <chr>      <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>      <dbl> ##  1 Agnostic      27        34        60        81        76       137        122 ##  2 Atheist       12        27        37        52        35        70         73 ##  3 Buddhist      27        21        30        34        33        58         62 ##  4 Catholic     418       617       732       670       638      1116        949 ##  5 Don’t k…      15        14        15        11        10        35         21 ##  6 Evangel…     575       869      1064       982       881      1486        949 ##  7 Hindu          1         9         7         9        11        34         47 ##  8 Histori…     228       244       236       238       197       223        131 ##  9 Jehovah…      20        27        24        24        21        30         15 ## 10 Jewish        19        19        25        25        30        95         69 ## 11 Mainlin…     289       495       619       655       651      1107        939 ## 12 Mormon        29        40        48        51        56       112         85 ## 13 Muslim         6         7         9        10         9        23         16 ## 14 Orthodox      13        17        23        32        32        47         38 ## 15 Other C…       9         7        11        13        13        14         18 ## 16 Other F…      20        33        40        46        49        63         46 ## 17 Other W…       5         2         3         4         2         7          3 ## 18 Unaffil…     217       299       374       365       341       528        407 ## # ℹ 3 more variables: `$100-150k` <dbl>, `>150k` <dbl>, ## #   `Don't know/refused` <dbl> # ---------- datawizard ----------- relig_income |>   data_to_long(     -religion,     names_to = \"income\",     values_to = \"count\"   ) # ---------- tidyverse ----------- relig_income |>   pivot_longer(     !religion,     names_to = \"income\",     values_to = \"count\"   ) ## # A tibble: 180 × 3 ##    religion income             count ##    <chr>    <chr>              <dbl> ##  1 Agnostic <$10k                 27 ##  2 Agnostic $10-20k               34 ##  3 Agnostic $20-30k               60 ##  4 Agnostic $30-40k               81 ##  5 Agnostic $40-50k               76 ##  6 Agnostic $50-75k              137 ##  7 Agnostic $75-100k             122 ##  8 Agnostic $100-150k            109 ##  9 Agnostic >150k                 84 ## 10 Agnostic Don't know/refused    96 ## # ℹ 170 more rows billboard ## # A tibble: 317 × 79 ##    artist     track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8 ##    <chr>      <chr> <date>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ##  1 2 Pac      Baby… 2000-02-26      87    82    72    77    87    94    99    NA ##  2 2Ge+her    The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA ##  3 3 Doors D… Kryp… 2000-04-08      81    70    68    67    66    57    54    53 ##  4 3 Doors D… Loser 2000-10-21      76    76    72    69    67    65    55    59 ##  5 504 Boyz   Wobb… 2000-04-15      57    34    25    17    17    31    36    49 ##  6 98^0       Give… 2000-08-19      51    39    34    26    26    19     2     2 ##  7 A*Teens    Danc… 2000-07-08      97    97    96    95   100    NA    NA    NA ##  8 Aaliyah    I Do… 2000-01-29      84    62    51    41    38    35    35    38 ##  9 Aaliyah    Try … 2000-03-18      59    53    38    28    21    18    16    14 ## 10 Adams, Yo… Open… 2000-08-26      76    76    74    69    68    67    61    58 ## # ℹ 307 more rows ## # ℹ 68 more variables: wk9 <dbl>, wk10 <dbl>, wk11 <dbl>, wk12 <dbl>, ## #   wk13 <dbl>, wk14 <dbl>, wk15 <dbl>, wk16 <dbl>, wk17 <dbl>, wk18 <dbl>, ## #   wk19 <dbl>, wk20 <dbl>, wk21 <dbl>, wk22 <dbl>, wk23 <dbl>, wk24 <dbl>, ## #   wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>, wk30 <dbl>, ## #   wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>, wk35 <dbl>, wk36 <dbl>, ## #   wk37 <dbl>, wk38 <dbl>, wk39 <dbl>, wk40 <dbl>, wk41 <dbl>, wk42 <dbl>, … # ---------- datawizard ----------- billboard |>   data_to_long(     cols = starts_with(\"wk\"),     names_to = \"week\",     values_to = \"rank\",     values_drop_na = TRUE   ) # ---------- tidyverse ----------- billboard |>   pivot_longer(     cols = starts_with(\"wk\"),     names_to = \"week\",     values_to = \"rank\",     values_drop_na = TRUE   ) ## # A tibble: 5,307 × 5 ##    artist  track                   date.entered week   rank ##    <chr>   <chr>                   <date>       <chr> <dbl> ##  1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87 ##  2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82 ##  3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72 ##  4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77 ##  5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87 ##  6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94 ##  7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99 ##  8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91 ##  9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87 ## 10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92 ## # ℹ 5,297 more rows"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"wider","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Reshaping","what":"Wider","title":"Coming from 'tidyverse'","text":", use example tidyr vignette show close data_to_wide() pivot_wider() :","code":"fish_encounters ## # A tibble: 114 × 3 ##    fish  station  seen ##    <fct> <fct>   <int> ##  1 4842  Release     1 ##  2 4842  I80_1       1 ##  3 4842  Lisbon      1 ##  4 4842  Rstr        1 ##  5 4842  Base_TD     1 ##  6 4842  BCE         1 ##  7 4842  BCW         1 ##  8 4842  BCE2        1 ##  9 4842  BCW2        1 ## 10 4842  MAE         1 ## # ℹ 104 more rows # ---------- datawizard ----------- fish_encounters |>   data_to_wide(     names_from = \"station\",     values_from = \"seen\"   ) # ---------- tidyverse ----------- fish_encounters |>   pivot_wider(     names_from = station,     values_from = seen   ) ## # A tibble: 19 × 12 ##    fish  Release I80_1 Lisbon  Rstr Base_TD   BCE   BCW  BCE2  BCW2   MAE   MAW ##    <fct>   <int> <int>  <int> <int>   <int> <int> <int> <int> <int> <int> <int> ##  1 4842        1     1      1     1       1     1     1     1     1     1     1 ##  2 4843        1     1      1     1       1     1     1     1     1     1     1 ##  3 4844        1     1      1     1       1     1     1     1     1     1     1 ##  4 4845        1     1      1     1       1    NA    NA    NA    NA    NA    NA ##  5 4847        1     1      1    NA      NA    NA    NA    NA    NA    NA    NA ##  6 4848        1     1      1     1      NA    NA    NA    NA    NA    NA    NA ##  7 4849        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA ##  8 4850        1     1     NA     1       1     1     1    NA    NA    NA    NA ##  9 4851        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA ## 10 4854        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA ## 11 4855        1     1      1     1       1    NA    NA    NA    NA    NA    NA ## 12 4857        1     1      1     1       1     1     1     1     1    NA    NA ## 13 4858        1     1      1     1       1     1     1     1     1     1     1 ## 14 4859        1     1      1     1       1    NA    NA    NA    NA    NA    NA ## 15 4861        1     1      1     1       1     1     1     1     1     1     1 ## 16 4862        1     1      1     1       1     1     1     1     1    NA    NA ## 17 4863        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA ## 18 4864        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA ## 19 4865        1     1      1    NA      NA    NA    NA    NA    NA    NA    NA"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"joining","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Joining","title":"Coming from 'tidyverse'","text":"datawizard, joining datasets done data_join() (alias data_merge()). Contrary dplyr, unique function takes care types join, specified inside function argument join (default, join = \"left\"). , show perform four common joins: full, left, right inner. use datasets band_membersand band_instruments provided dplyr:","code":"band_members ## # A tibble: 3 × 2 ##   name  band    ##   <chr> <chr>   ## 1 Mick  Stones  ## 2 John  Beatles ## 3 Paul  Beatles band_instruments ## # A tibble: 3 × 2 ##   name  plays  ##   <chr> <chr>  ## 1 John  guitar ## 2 Paul  bass   ## 3 Keith guitar"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"full-join","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Joining","what":"Full join","title":"Coming from 'tidyverse'","text":"","code":"# ---------- datawizard ----------- band_members |>   data_join(band_instruments, join = \"full\") # ---------- tidyverse ----------- band_members |>   full_join(band_instruments) ## # A tibble: 4 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 Mick  Stones  NA     ## 2 John  Beatles guitar ## 3 Paul  Beatles bass   ## 4 Keith NA      guitar"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"left-and-right-joins","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Joining","what":"Left and right joins","title":"Coming from 'tidyverse'","text":"","code":"# ---------- datawizard ----------- band_members |>   data_join(band_instruments, join = \"left\") # ---------- tidyverse ----------- band_members |>   left_join(band_instruments) ## # A tibble: 3 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 Mick  Stones  NA     ## 2 John  Beatles guitar ## 3 Paul  Beatles bass # ---------- datawizard ----------- band_members |>   data_join(band_instruments, join = \"right\") # ---------- tidyverse ----------- band_members |>   right_join(band_instruments) ## # A tibble: 3 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 John  Beatles guitar ## 2 Paul  Beatles bass   ## 3 Keith NA      guitar"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"inner-join","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Joining","what":"Inner join","title":"Coming from 'tidyverse'","text":"","code":"# ---------- datawizard ----------- band_members |>   data_join(band_instruments, join = \"inner\") # ---------- tidyverse ----------- band_members |>   inner_join(band_instruments) ## # A tibble: 2 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 John  Beatles guitar ## 2 Paul  Beatles bass"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"uniting","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Uniting","title":"Coming from 'tidyverse'","text":"Uniting variables useful e.g create unique indices combining several variables gather years, months, days single date. data_unite() offers interface close tidyr::unite():","code":"test <- data.frame(   year = 2002:2004,   month = c(\"02\", \"03\", \"09\"),   day = c(\"11\", \"22\", \"28\"),   stringsAsFactors = FALSE ) test ##   year month day ## 1 2002    02  11 ## 2 2003    03  22 ## 3 2004    09  28 # ---------- datawizard ----------- test |>   data_unite(     new_column = \"date\",     select = c(\"year\", \"month\", \"day\"),     separator = \"-\"   ) # ---------- tidyverse ----------- test |>   unite(     col = \"date\",     year, month, day,     sep = \"-\"   ) ##         date ## 1 2002-02-11 ## 2 2003-03-22 ## 3 2004-09-28 # ---------- datawizard ----------- test |>   data_unite(     new_column = \"date\",     select = c(\"year\", \"month\", \"day\"),     separator = \"-\",     append = TRUE   ) # ---------- tidyverse ----------- test |>   unite(     col = \"date\",     year, month, day,     sep = \"-\",     remove = FALSE   ) ##   year month day       date ## 1 2002    02  11 2002-02-11 ## 2 2003    03  22 2003-03-22 ## 3 2004    09  28 2004-09-28"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"separating","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Separating","title":"Coming from 'tidyverse'","text":"Separating variables counterpart uniting variables useful split values multiple columns, e.g. splitting date values years, months days. data_separate() offers interface close tidyr::separate(): Unlike tidyr::separate(), can separate multiple columns one step data_separate().","code":"test <- data.frame(   date_arrival = c(\"2002-02-11\", \"2003-03-22\", \"2004-09-28\"),   date_departure = c(\"2002-03-15\", \"2003-03-28\", \"2004-09-30\"),   stringsAsFactors = FALSE ) test ##   date_arrival date_departure ## 1   2002-02-11     2002-03-15 ## 2   2003-03-22     2003-03-28 ## 3   2004-09-28     2004-09-30 # ---------- datawizard ----------- test |>   data_separate(     select = \"date_arrival\",     new_columns = c(\"Year\", \"Month\", \"Day\")   ) # ---------- tidyverse ----------- test |>   separate(     date_arrival,     into = c(\"Year\", \"Month\", \"Day\")   ) ##   date_departure Year Month Day ## 1     2002-03-15 2002    02  11 ## 2     2003-03-28 2003    03  22 ## 3     2004-09-30 2004    09  28 test |>   data_separate(     new_columns = list(       date_arrival = c(\"Arr_Year\", \"Arr_Month\", \"Arr_Day\"),       date_departure = c(\"Dep_Year\", \"Dep_Month\", \"Dep_Day\")     )   ) ##   Arr_Year Arr_Month Arr_Day Dep_Year Dep_Month Dep_Day ## 1     2002        02      11     2002        03      15 ## 2     2003        03      22     2003        03      28 ## 3     2004        09      28     2004        09      30"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"other-useful-functions","dir":"Articles","previous_headings":"","what":"Other useful functions","title":"Coming from 'tidyverse'","text":"datawizard contains functions necessarily included dplyr tidyr directly modify data. inspired package janitor.","code":""},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"work-with-rownames","dir":"Articles","previous_headings":"Other useful functions","what":"Work with rownames","title":"Coming from 'tidyverse'","text":"can convert column rownames move rownames new column rownames_as_column() column_as_rownames():","code":"mtcars <- head(mtcars) mtcars ##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb ## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 ## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 ## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 ## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 ## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 ## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 mtcars2 <- mtcars |>   rownames_as_column(var = \"model\")  mtcars2 ##               model  mpg cyl disp  hp drat    wt  qsec vs am gear carb ## 1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 ## 2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 ## 3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 ## 4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 ## 5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 ## 6           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 mtcars2 |>   column_as_rownames(var = \"model\") ##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb ## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 ## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 ## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 ## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 ## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 ## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"work-with-row-ids","dir":"Articles","previous_headings":"Other useful functions","what":"Work with row ids","title":"Coming from 'tidyverse'","text":"rowid_as_column() close identical tibble::rowid_to_column(). main difference use grouped data. tibble::rowid_to_column() uses one distinct rowid every row dataset, rowid_as_column() creates one id every row group. Therefore, two rows different groups can row id. means rowid_as_column() closer using n() mutate(), like following:","code":"test <- data.frame(   group = c(\"A\", \"A\", \"B\", \"B\"),   value = c(3, 5, 8, 1),   stringsAsFactors = FALSE ) test ##   group value ## 1     A     3 ## 2     A     5 ## 3     B     8 ## 4     B     1 test |>   data_group(group) |>   tibble::rowid_to_column() ##   rowid group value ## 1     1     A     3 ## 2     2     A     5 ## 3     3     B     8 ## 4     4     B     1 test |>   data_group(group) |>   rowid_as_column() ## # A tibble: 4 × 3 ## # Groups:   group [2] ##   rowid group value ##   <int> <chr> <dbl> ## 1     1 A         3 ## 2     2 A         5 ## 3     1 B         8 ## 4     2 B         1 test |>   data_group(group) |>   mutate(id = seq_len(n())) ## # A tibble: 4 × 3 ## # Groups:   group [2] ##   group value    id ##   <chr> <dbl> <int> ## 1 A         3     1 ## 2 A         5     2 ## 3 B         8     1 ## 4 B         1     2"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"work-with-column-names","dir":"Articles","previous_headings":"Other useful functions","what":"Work with column names","title":"Coming from 'tidyverse'","text":"dealing messy data, sometimes useful use row column names, vice versa. can done row_to_colnames() colnames_to_row().","code":"x <- data.frame(   X_1 = c(NA, \"Title\", 1:3),   X_2 = c(NA, \"Title2\", 4:6) ) x ##     X_1    X_2 ## 1  <NA>   <NA> ## 2 Title Title2 ## 3     1      4 ## 4     2      5 ## 5     3      6 x2 <- x |>   row_to_colnames(row = 2) x2 ##   Title Title2 ## 1  <NA>   <NA> ## 3     1      4 ## 4     2      5 ## 5     3      6 x2 |>   colnames_to_row() ##       x1     x2 ## 1  Title Title2 ## 11  <NA>   <NA> ## 3      1      4 ## 4      2      5 ## 5      3      6"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"take-a-quick-look-at-the-data","dir":"Articles","previous_headings":"Other useful functions","what":"Take a quick look at the data","title":"Coming from 'tidyverse'","text":"","code":"# ---------- datawizard ----------- data_peek(iris) # ---------- tidyverse ----------- glimpse(iris) ## Data frame with 150 rows and 5 variables ##  ## Variable     | Type    | Values                                         ## ----------------------------------------------------------------------- ## Sepal.Length | numeric | 5.1, 4.9, 4.7, 4.6, 5, 5.4, 4.6, 5, 4.4, ...   ## Sepal.Width  | numeric | 3.5, 3, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, ... ## Petal.Length | numeric | 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, ...    ## Petal.Width  | numeric | 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, ...    ## Species      | factor  | setosa, setosa, setosa, setosa, setosa, ..."},{"path":"https://easystats.github.io/datawizard/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Indrajeet Patil. Author. Etienne Bacher. Author, maintainer. Dominique Makowski. Author. Daniel Lüdecke. Author. Mattan S. Ben-Shachar. Author. Brenton M. Wiernik. Author. Rémi Thériault. Contributor. Thomas J. Faulkenberry. Reviewer. Robert Garrett. Reviewer.","code":""},{"path":"https://easystats.github.io/datawizard/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Patil et al., (2022). datawizard: R Package Easy Data Preparation Statistical Transformations. Journal Open Source Software, 7(78), 4684, https://doi.org/10.21105/joss.04684","code":"@Article{,   title = {{datawizard}: An {R} Package for Easy Data Preparation and Statistical Transformations},   author = {Indrajeet Patil and Dominique Makowski and Mattan S. Ben-Shachar and Brenton M. Wiernik and Etienne Bacher and Daniel Lüdecke},   journal = {Journal of Open Source Software},   year = {2022},   volume = {7},   number = {78},   pages = {4684},   doi = {10.21105/joss.04684}, }"},{"path":"https://easystats.github.io/datawizard/index.html","id":"datawizard-easy-data-wrangling-and-statistical-transformations-","dir":"","previous_headings":"","what":"Easy Data Wrangling and Statistical Transformations","title":"Easy Data Wrangling and Statistical Transformations","text":"datawizard lightweight package easily manipulate, clean, transform, prepare data analysis. part easystats ecosystem, suite R packages deal entire statistical analysis, cleaning data reporting results. covers two aspects data preparation: Data manipulation: datawizard offers similar set functions tidyverse packages, dplyr tidyr, select, filter reshape data, key differences. 1) data manipulation functions start prefix data_* (makes easy identify). 2) Although functions can used exactly tidyverse equivalents, also string-friendly (makes easy program use inside functions). Finally, datawizard super lightweight (dependencies, similar poorman), makes awesome developers use packages. Statistical transformations: datawizard also powerful functions easily apply common data transformations, including standardization, normalization, rescaling, rank-transformation, scale reversing, recoding, binning, etc.","code":""},{"path":"https://easystats.github.io/datawizard/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Easy Data Wrangling and Statistical Transformations","text":"Tip Instead library(datawizard), use library(easystats). make features easystats-ecosystem available. stay updated, use easystats::install_latest().","code":""},{"path":"https://easystats.github.io/datawizard/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Easy Data Wrangling and Statistical Transformations","text":"cite package, run following command:","code":"citation(\"datawizard\") To cite package 'datawizard' in publications use:    Patil et al., (2022). datawizard: An R Package for Easy Data   Preparation and Statistical Transformations. Journal of Open Source   Software, 7(78), 4684, https://doi.org/10.21105/joss.04684  A BibTeX entry for LaTeX users is    @Article{,     title = {{datawizard}: An {R} Package for Easy Data Preparation and Statistical Transformations},     author = {Indrajeet Patil and Dominique Makowski and Mattan S. Ben-Shachar and Brenton M. Wiernik and Etienne Bacher and Daniel Lüdecke},     journal = {Journal of Open Source Software},     year = {2022},     volume = {7},     number = {78},     pages = {4684},     doi = {10.21105/joss.04684},   }"},{"path":"https://easystats.github.io/datawizard/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Easy Data Wrangling and Statistical Transformations","text":"courses tutorials statistical modeling assume working clean tidy dataset. practice, however, major part statistical modeling preparing data–cleaning values, creating new columns, reshaping dataset, transforming variables. datawizard provides easy use tools perform common, critical, sometimes tedious data preparation tasks.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/index.html","id":"select-filter-and-remove-variables","dir":"","previous_headings":"Data wrangling","what":"Select, filter and remove variables","title":"Easy Data Wrangling and Statistical Transformations","text":"package provides helpers filter rows meeting certain conditions… … logical expressions: Finding columns data frame, retrieving data selected columns, can achieved using extract_column_names() data_select(): also possible extract one variables: Due consistent API, removing variables just simple:","code":"data_match(mtcars, data.frame(vs = 0, am = 1)) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 data_filter(mtcars, vs == 0 & am == 1) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 # find column names matching a pattern extract_column_names(iris, starts_with(\"Sepal\")) #> [1] \"Sepal.Length\" \"Sepal.Width\"  # return data columns matching a pattern data_select(iris, starts_with(\"Sepal\")) |> head() #>   Sepal.Length Sepal.Width #> 1          5.1         3.5 #> 2          4.9         3.0 #> 3          4.7         3.2 #> 4          4.6         3.1 #> 5          5.0         3.6 #> 6          5.4         3.9 # single variable data_extract(mtcars, \"gear\") #>  [1] 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4  # more variables head(data_extract(iris, ends_with(\"Width\"))) #>   Sepal.Width Petal.Width #> 1         3.5         0.2 #> 2         3.0         0.2 #> 3         3.2         0.2 #> 4         3.1         0.2 #> 5         3.6         0.2 #> 6         3.9         0.4 head(data_remove(iris, starts_with(\"Sepal\"))) #>   Petal.Length Petal.Width Species #> 1          1.4         0.2  setosa #> 2          1.4         0.2  setosa #> 3          1.3         0.2  setosa #> 4          1.5         0.2  setosa #> 5          1.4         0.2  setosa #> 6          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/index.html","id":"reorder-or-rename","dir":"","previous_headings":"Data wrangling","what":"Reorder or rename","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"head(data_relocate(iris, select = \"Species\", before = \"Sepal.Length\")) #>   Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1  setosa          5.1         3.5          1.4         0.2 #> 2  setosa          4.9         3.0          1.4         0.2 #> 3  setosa          4.7         3.2          1.3         0.2 #> 4  setosa          4.6         3.1          1.5         0.2 #> 5  setosa          5.0         3.6          1.4         0.2 #> 6  setosa          5.4         3.9          1.7         0.4 head(data_rename(iris, c(\"Sepal.Length\", \"Sepal.Width\"), c(\"length\", \"width\"))) #>   length width Petal.Length Petal.Width Species #> 1    5.1   3.5          1.4         0.2  setosa #> 2    4.9   3.0          1.4         0.2  setosa #> 3    4.7   3.2          1.3         0.2  setosa #> 4    4.6   3.1          1.5         0.2  setosa #> 5    5.0   3.6          1.4         0.2  setosa #> 6    5.4   3.9          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/index.html","id":"merge","dir":"","previous_headings":"Data wrangling","what":"Merge","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"x <- data.frame(a = 1:3, b = c(\"a\", \"b\", \"c\"), c = 5:7, id = 1:3) y <- data.frame(c = 6:8, d = c(\"f\", \"g\", \"h\"), e = 100:102, id = 2:4)  x #>   a b c id #> 1 1 a 5  1 #> 2 2 b 6  2 #> 3 3 c 7  3 y #>   c d   e id #> 1 6 f 100  2 #> 2 7 g 101  3 #> 3 8 h 102  4  data_merge(x, y, join = \"full\") #>    a    b c id    d   e #> 3  1    a 5  1 <NA>  NA #> 1  2    b 6  2    f 100 #> 2  3    c 7  3    g 101 #> 4 NA <NA> 8  4    h 102  data_merge(x, y, join = \"left\") #>   a b c id    d   e #> 3 1 a 5  1 <NA>  NA #> 1 2 b 6  2    f 100 #> 2 3 c 7  3    g 101  data_merge(x, y, join = \"right\") #>    a    b c id d   e #> 1  2    b 6  2 f 100 #> 2  3    c 7  3 g 101 #> 3 NA <NA> 8  4 h 102  data_merge(x, y, join = \"semi\", by = \"c\") #>   a b c id #> 2 2 b 6  2 #> 3 3 c 7  3  data_merge(x, y, join = \"anti\", by = \"c\") #>   a b c id #> 1 1 a 5  1  data_merge(x, y, join = \"inner\") #>   a b c id d   e #> 1 2 b 6  2 f 100 #> 2 3 c 7  3 g 101  data_merge(x, y, join = \"bind\") #>    a    b c id    d   e #> 1  1    a 5  1 <NA>  NA #> 2  2    b 6  2 <NA>  NA #> 3  3    c 7  3 <NA>  NA #> 4 NA <NA> 6  2    f 100 #> 5 NA <NA> 7  3    g 101 #> 6 NA <NA> 8  4    h 102"},{"path":"https://easystats.github.io/datawizard/index.html","id":"reshape","dir":"","previous_headings":"Data wrangling","what":"Reshape","title":"Easy Data Wrangling and Statistical Transformations","text":"common data wrangling task reshape data. Either go wide/Cartesian long/tidy format way","code":"wide_data <- data.frame(replicate(5, rnorm(10)))  head(data_to_long(wide_data)) #>   name       value #> 1   X1 -0.08281164 #> 2   X2 -1.12490028 #> 3   X3 -0.70632036 #> 4   X4 -0.70278946 #> 5   X5  0.07633326 #> 6   X1  1.93468099 long_data <- data_to_long(wide_data, rows_to = \"Row_ID\") # Save row number  data_to_wide(long_data,   names_from = \"name\",   values_from = \"value\",   id_cols = \"Row_ID\" ) #>    Row_ID          X1          X2          X3         X4          X5 #> 1       1 -0.08281164 -1.12490028 -0.70632036 -0.7027895  0.07633326 #> 2       2  1.93468099 -0.87430362  0.96687656  0.2998642 -0.23035595 #> 3       3 -2.05128979  0.04386162 -0.71016648  1.1494697  0.31746484 #> 4       4  0.27773897 -0.58397514 -0.05917365 -0.3016415 -1.59268440 #> 5       5 -1.52596060 -0.82329858 -0.23094342 -0.5473394 -0.18194062 #> 6       6 -0.26916362  0.11059280  0.69200045 -0.3854041  1.75614174 #> 7       7  1.23305388  0.36472778  1.35682290  0.2763720  0.11394932 #> 8       8  0.63360774  0.05370100  1.78872284  0.1518608 -0.29216508 #> 9       9  0.35271746  1.36867235  0.41071582 -0.4313808  1.75409316 #> 10     10 -0.56048248 -0.38045724 -2.18785470 -1.8705001  1.80958455"},{"path":"https://easystats.github.io/datawizard/index.html","id":"empty-rows-and-columns","dir":"","previous_headings":"Data wrangling","what":"Empty rows and columns","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"tmp <- data.frame(   a = c(1, 2, 3, NA, 5),   b = c(1, NA, 3, NA, 5),   c = c(NA, NA, NA, NA, NA),   d = c(1, NA, 3, NA, 5) )  tmp #>    a  b  c  d #> 1  1  1 NA  1 #> 2  2 NA NA NA #> 3  3  3 NA  3 #> 4 NA NA NA NA #> 5  5  5 NA  5  # indices of empty columns or rows empty_columns(tmp) #> c  #> 3 empty_rows(tmp) #> [1] 4  # remove empty columns or rows remove_empty_columns(tmp) #>    a  b  d #> 1  1  1  1 #> 2  2 NA NA #> 3  3  3  3 #> 4 NA NA NA #> 5  5  5  5 remove_empty_rows(tmp) #>   a  b  c  d #> 1 1  1 NA  1 #> 2 2 NA NA NA #> 3 3  3 NA  3 #> 5 5  5 NA  5  # remove empty columns and rows remove_empty(tmp) #>   a  b  d #> 1 1  1  1 #> 2 2 NA NA #> 3 3  3  3 #> 5 5  5  5"},{"path":"https://easystats.github.io/datawizard/index.html","id":"recode-or-cut-dataframe","dir":"","previous_headings":"Data wrangling","what":"Recode or cut dataframe","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"set.seed(123) x <- sample(1:10, size = 50, replace = TRUE)  table(x) #> x #>  1  2  3  4  5  6  7  8  9 10  #>  2  3  5  3  7  5  5  2 11  7  # cut into 3 groups, based on distribution (quantiles) table(categorize(x, split = \"quantile\", n_groups = 3)) #>  #>  1  2  3  #> 13 19 18"},{"path":"https://easystats.github.io/datawizard/index.html","id":"data-transformations","dir":"","previous_headings":"","what":"Data Transformations","title":"Easy Data Wrangling and Statistical Transformations","text":"packages also contains multiple functions help transform data.","code":""},{"path":"https://easystats.github.io/datawizard/index.html","id":"standardize","dir":"","previous_headings":"Data Transformations","what":"Standardize","title":"Easy Data Wrangling and Statistical Transformations","text":"example, standardize (z-score) data:","code":"# before summary(swiss) #>    Fertility      Agriculture     Examination      Education     #>  Min.   :35.00   Min.   : 1.20   Min.   : 3.00   Min.   : 1.00   #>  1st Qu.:64.70   1st Qu.:35.90   1st Qu.:12.00   1st Qu.: 6.00   #>  Median :70.40   Median :54.10   Median :16.00   Median : 8.00   #>  Mean   :70.14   Mean   :50.66   Mean   :16.49   Mean   :10.98   #>  3rd Qu.:78.45   3rd Qu.:67.65   3rd Qu.:22.00   3rd Qu.:12.00   #>  Max.   :92.50   Max.   :89.70   Max.   :37.00   Max.   :53.00   #>     Catholic       Infant.Mortality #>  Min.   :  2.150   Min.   :10.80    #>  1st Qu.:  5.195   1st Qu.:18.15    #>  Median : 15.140   Median :20.00    #>  Mean   : 41.144   Mean   :19.94    #>  3rd Qu.: 93.125   3rd Qu.:21.70    #>  Max.   :100.000   Max.   :26.60  # after summary(standardize(swiss)) #>    Fertility         Agriculture       Examination         Education       #>  Min.   :-2.81327   Min.   :-2.1778   Min.   :-1.69084   Min.   :-1.0378   #>  1st Qu.:-0.43569   1st Qu.:-0.6499   1st Qu.:-0.56273   1st Qu.:-0.5178   #>  Median : 0.02061   Median : 0.1515   Median :-0.06134   Median :-0.3098   #>  Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000   #>  3rd Qu.: 0.66504   3rd Qu.: 0.7481   3rd Qu.: 0.69074   3rd Qu.: 0.1062   #>  Max.   : 1.78978   Max.   : 1.7190   Max.   : 2.57094   Max.   : 4.3702   #>     Catholic       Infant.Mortality   #>  Min.   :-0.9350   Min.   :-3.13886   #>  1st Qu.:-0.8620   1st Qu.:-0.61543   #>  Median :-0.6235   Median : 0.01972   #>  Mean   : 0.0000   Mean   : 0.00000   #>  3rd Qu.: 1.2464   3rd Qu.: 0.60337   #>  Max.   : 1.4113   Max.   : 2.28566"},{"path":"https://easystats.github.io/datawizard/index.html","id":"winsorize","dir":"","previous_headings":"Data Transformations","what":"Winsorize","title":"Easy Data Wrangling and Statistical Transformations","text":"winsorize data:","code":"# before anscombe #>    x1 x2 x3 x4    y1   y2    y3    y4 #> 1  10 10 10  8  8.04 9.14  7.46  6.58 #> 2   8  8  8  8  6.95 8.14  6.77  5.76 #> 3  13 13 13  8  7.58 8.74 12.74  7.71 #> 4   9  9  9  8  8.81 8.77  7.11  8.84 #> 5  11 11 11  8  8.33 9.26  7.81  8.47 #> 6  14 14 14  8  9.96 8.10  8.84  7.04 #> 7   6  6  6  8  7.24 6.13  6.08  5.25 #> 8   4  4  4 19  4.26 3.10  5.39 12.50 #> 9  12 12 12  8 10.84 9.13  8.15  5.56 #> 10  7  7  7  8  4.82 7.26  6.42  7.91 #> 11  5  5  5  8  5.68 4.74  5.73  6.89  # after winsorize(anscombe) #>    x1 x2 x3 x4   y1   y2   y3   y4 #> 1  10 10 10  8 8.04 9.13 7.46 6.58 #> 2   8  8  8  8 6.95 8.14 6.77 5.76 #> 3  12 12 12  8 7.58 8.74 8.15 7.71 #> 4   9  9  9  8 8.81 8.77 7.11 8.47 #> 5  11 11 11  8 8.33 9.13 7.81 8.47 #> 6  12 12 12  8 8.81 8.10 8.15 7.04 #> 7   6  6  6  8 7.24 6.13 6.08 5.76 #> 8   6  6  6  8 5.68 6.13 6.08 8.47 #> 9  12 12 12  8 8.81 9.13 8.15 5.76 #> 10  7  7  7  8 5.68 7.26 6.42 7.91 #> 11  6  6  6  8 5.68 6.13 6.08 6.89"},{"path":"https://easystats.github.io/datawizard/index.html","id":"center","dir":"","previous_headings":"Data Transformations","what":"Center","title":"Easy Data Wrangling and Statistical Transformations","text":"grand-mean center data","code":"center(anscombe) #>    x1 x2 x3 x4          y1         y2    y3         y4 #> 1   1  1  1 -1  0.53909091  1.6390909 -0.04 -0.9209091 #> 2  -1 -1 -1 -1 -0.55090909  0.6390909 -0.73 -1.7409091 #> 3   4  4  4 -1  0.07909091  1.2390909  5.24  0.2090909 #> 4   0  0  0 -1  1.30909091  1.2690909 -0.39  1.3390909 #> 5   2  2  2 -1  0.82909091  1.7590909  0.31  0.9690909 #> 6   5  5  5 -1  2.45909091  0.5990909  1.34 -0.4609091 #> 7  -3 -3 -3 -1 -0.26090909 -1.3709091 -1.42 -2.2509091 #> 8  -5 -5 -5 10 -3.24090909 -4.4009091 -2.11  4.9990909 #> 9   3  3  3 -1  3.33909091  1.6290909  0.65 -1.9409091 #> 10 -2 -2 -2 -1 -2.68090909 -0.2409091 -1.08  0.4090909 #> 11 -4 -4 -4 -1 -1.82090909 -2.7609091 -1.77 -0.6109091"},{"path":"https://easystats.github.io/datawizard/index.html","id":"ranktransform","dir":"","previous_headings":"Data Transformations","what":"Ranktransform","title":"Easy Data Wrangling and Statistical Transformations","text":"rank-transform data:","code":"# before head(trees) #>   Girth Height Volume #> 1   8.3     70   10.3 #> 2   8.6     65   10.3 #> 3   8.8     63   10.2 #> 4  10.5     72   16.4 #> 5  10.7     81   18.8 #> 6  10.8     83   19.7  # after head(ranktransform(trees)) #>   Girth Height Volume #> 1     1    6.0    2.5 #> 2     2    3.0    2.5 #> 3     3    1.0    1.0 #> 4     4    8.5    5.0 #> 5     5   25.5    7.0 #> 6     6   28.0    9.0"},{"path":"https://easystats.github.io/datawizard/index.html","id":"rescale","dir":"","previous_headings":"Data Transformations","what":"Rescale","title":"Easy Data Wrangling and Statistical Transformations","text":"rescale numeric variable new range:","code":"change_scale(c(0, 1, 5, -5, -2)) #> [1]  50  60 100   0  30 #> (original range = -5 to 5)"},{"path":"https://easystats.github.io/datawizard/index.html","id":"rotate-or-transpose","dir":"","previous_headings":"Data Transformations","what":"Rotate or transpose","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"x <- mtcars[1:3, 1:4]  x #>                mpg cyl disp  hp #> Mazda RX4     21.0   6  160 110 #> Mazda RX4 Wag 21.0   6  160 110 #> Datsun 710    22.8   4  108  93  data_rotate(x) #>      Mazda RX4 Mazda RX4 Wag Datsun 710 #> mpg         21            21       22.8 #> cyl          6             6        4.0 #> disp       160           160      108.0 #> hp         110           110       93.0"},{"path":"https://easystats.github.io/datawizard/index.html","id":"data-properties","dir":"","previous_headings":"","what":"Data properties","title":"Easy Data Wrangling and Statistical Transformations","text":"datawizard provides way provide comprehensive descriptive summary variables dataframe: even just variable also additional data properties can computed using package.","code":"data(iris) describe_distribution(iris) #> Variable     | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |   n | n_Missing #> ---------------------------------------------------------------------------------------- #> Sepal.Length | 5.84 | 0.83 | 1.30 | [4.30, 7.90] |     0.31 |    -0.55 | 150 |         0 #> Sepal.Width  | 3.06 | 0.44 | 0.52 | [2.00, 4.40] |     0.32 |     0.23 | 150 |         0 #> Petal.Length | 3.76 | 1.77 | 3.52 | [1.00, 6.90] |    -0.27 |    -1.40 | 150 |         0 #> Petal.Width  | 1.20 | 0.76 | 1.50 | [0.10, 2.50] |    -0.10 |    -1.34 | 150 |         0 describe_distribution(mtcars$wt) #> Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing #> ------------------------------------------------------------------------ #> 3.22 | 0.98 | 1.19 | [1.51, 5.42] |     0.47 |     0.42 | 32 |         0 x <- (-10:10)^3 + rnorm(21, 0, 100) smoothness(x, method = \"diff\") #> [1] 1.791243 #> attr(,\"class\") #> [1] \"parameters_smoothness\" \"numeric\""},{"path":"https://easystats.github.io/datawizard/index.html","id":"function-design-and-pipe-workflow","dir":"","previous_headings":"","what":"Function design and pipe-workflow","title":"Easy Data Wrangling and Statistical Transformations","text":"design datawizard functions follows design principle makes easy user understand remember functions work: first argument data methods work data frames, two arguments following select exclude variables following arguments arguments related specific tasks functions important, functions accept data frames usually first argument, also return (modified) data frame . Thus, datawizard integrates smoothly “pipe-workflow”.","code":"iris |>   # all rows where Species is \"versicolor\" or \"virginica\"   data_filter(Species %in% c(\"versicolor\", \"virginica\")) |>   # select only columns with \".\" in names (i.e. drop Species)   data_select(contains(\"\\\\.\")) |>   # move columns that ends with \"Length\" to start of data frame   data_relocate(ends_with(\"Length\")) |>   # remove fourth column   data_remove(4) |>   head() #>    Sepal.Length Petal.Length Sepal.Width #> 51          7.0          4.7         3.2 #> 52          6.4          4.5         3.2 #> 53          6.9          4.9         3.1 #> 54          5.5          4.0         2.3 #> 55          6.5          4.6         2.8 #> 56          5.7          4.5         2.8"},{"path":"https://easystats.github.io/datawizard/index.html","id":"contributing-and-support","dir":"","previous_headings":"","what":"Contributing and Support","title":"Easy Data Wrangling and Statistical Transformations","text":"case want file issue contribute another way package, please follow guide. questions functionality, may either contact us via email also file issue.","code":""},{"path":"https://easystats.github.io/datawizard/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Easy Data Wrangling and Statistical Transformations","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust data for the effect of other variable(s) — adjust","title":"Adjust data for the effect of other variable(s) — adjust","text":"function can used adjust data effect variables present dataset. based underlying fitting regressions models, allowing quite flexibility, including factors random effects mixed models (multilevel partialization), continuous variables smooth terms general additive models (non-linear partialization) /fitting models Bayesian framework. values returned function residuals regression models. Note regular correlation two \"adjusted\" variables equivalent partial correlation .","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust data for the effect of other variable(s) — adjust","text":"","code":"adjust(   data,   effect = NULL,   select = is.numeric,   exclude = NULL,   multilevel = FALSE,   additive = FALSE,   bayesian = FALSE,   keep_intercept = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE )  data_adjust(   data,   effect = NULL,   select = is.numeric,   exclude = NULL,   multilevel = FALSE,   additive = FALSE,   bayesian = FALSE,   keep_intercept = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE )"},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust data for the effect of other variable(s) — adjust","text":"data data frame. effect Character vector column names adjusted (regressed ). NULL (default), variables selected. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. multilevel TRUE, factors included random factors. Else, FALSE (default), included fixed effects simple regression model. additive TRUE, continuous variables included smooth terms additive models. goal regress-potential non-linear effects. bayesian TRUE, models fitted Bayesian framework using rstanarm. keep_intercept FALSE (default), intercept model re-added. avoids centering around 0 happens default regressing another variable (see examples visual representation ). ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust data for the effect of other variable(s) — adjust","text":"data frame comparable data, adjusted variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust data for the effect of other variable(s) — adjust","text":"","code":"adjusted_all <- adjust(attitude) head(adjusted_all) #>        rating complaints privileges    learning     raises   critical #> 1  -8.1102953  5.5583770 -15.848949 -2.75102306  0.5742664  15.605502 #> 2   1.6472337  0.0646564  -1.422592 -3.06207012 -1.5567655  -2.315781 #> 3   1.0605589 -7.5116953  11.174609  5.59808033  4.8603132   8.061801 #> 4  -0.2268416  3.8345277  -4.567441  0.03866933 -7.1185324  13.002574 #> 5   6.5462010 -1.2420122  -3.051098  0.87312095 -2.7131349   6.500353 #> 6 -10.9418499  5.2030745   2.664156 -1.24552098  4.1370346 -21.678382 #>      advance #> 1  2.8684130 #> 2  5.3937097 #> 3 -6.4236221 #> 4 -0.3951046 #> 5  2.1988621 #> 6 -3.1912418 adjusted_one <- adjust(attitude, effect = \"complaints\", select = \"rating\") head(adjusted_one) #>        rating complaints privileges learning raises critical advance #> 1  -9.8614202         51         30       39     61       92      45 #> 2   0.3286522         64         51       54     63       73      47 #> 3   3.8009933         70         68       69     76       86      48 #> 4  -0.9167380         63         45       47     54       84      35 #> 5   7.7641147         78         56       66     71       83      47 #> 6 -12.8798594         55         49       44     54       49      34 # \\donttest{ adjust(attitude, effect = \"complaints\", select = \"rating\", bayesian = TRUE) #>          rating complaints privileges learning raises critical advance #> 1   -9.85743877         51         30       39     61       92      45 #> 2    0.34818773         64         51       54     63       73      47 #> 3    3.82770765         70         68       69     76       86      48 #> 4   -0.89839893         63         45       47     54       84      35 #> 5    7.80040088         78         56       66     71       83      47 #> 6  -12.87109216         55         49       44     54       49      34 #> 7   -6.91205231         67         42       56     66       68      35 #> 8    0.06064092         75         50       55     70       66      41 #> 9   -4.21325250         82         72       67     71       83      31 #> 10   6.60842777         61         45       47     62       80      41 #> 11   9.63573453         53         53       58     58       67      34 #> 12   7.36184111         60         47       39     59       74      41 #> 13   7.85501442         62         57       42     55       63      25 #> 14  -8.96666585         83         83       45     59       77      35 #> 15   4.55381423         77         54       72     79       77      46 #> 16  -1.24055927         90         50       72     60       54      36 #> 17  -4.47349254         85         64       69     79       79      63 #> 18   5.36184111         60         65       75     55       80      60 #> 19  -2.17229235         70         46       57     75       85      46 #> 20  -8.13133220         58         68       54     64       78      52 #> 21   5.43010803         40         33       34     43       64      33 #> 22   3.60842777         61         52       62     66       80      41 #> 23 -11.15863897         66         52       50     63       80      37 #> 24  -2.30965193         37         42       58     50       57      49 #> 25   7.88232119         54         42       48     66       75      33 #> 26  -6.44618577         77         66       63     88       76      72 #> 27   7.06064092         75         58       74     80       78      49 #> 28  -9.37791885         57         44       45     51       83      38 #> 29   6.52650746         85         71       71     77       74      55 #> 30   5.78674750         82         39       59     64       78      39 adjust(attitude, effect = \"complaints\", select = \"rating\", additive = TRUE) #>          rating complaints privileges learning raises critical advance #> 1   -9.86142016         51         30       39     61       92      45 #> 2    0.32865220         64         51       54     63       73      47 #> 3    3.80099328         70         68       69     76       86      48 #> 4   -0.91673799         63         45       47     54       84      35 #> 5    7.76411473         78         56       66     71       83      47 #> 6  -12.87985944         55         49       44     54       49      34 #> 7   -6.93517726         67         42       56     66       68      35 #> 8    0.02794419         75         50       55     70       66      41 #> 9   -4.25432454         82         72       67     71       83      31 #> 10   6.59248165         61         45       47     62       80      41 #> 11   9.62936020         53         53       58     58       67      34 #> 12   7.34709147         60         47       39     59       74      41 #> 13   7.83787183         62         57       42     55       63      25 #> 14  -9.00893436         83         83       45     59       77      35 #> 15   4.51872455         77         54       72     79       77      46 #> 16  -1.29120309         90         50       72     60       54      36 #> 17  -4.51815400         85         64       69     79       79      63 #> 18   5.34709147         60         65       75     55       80      60 #> 19  -2.19900672         70         46       57     75       85      46 #> 20  -8.14368889         58         68       54     64       78      52 #> 21   5.43928784         40         33       34     43       64      33 #> 22   3.59248165         61         52       62     66       80      41 #> 23 -11.18056744         66         52       50     63       80      37 #> 24  -2.29688270         37         42       58     50       57      49 #> 25   7.87475038         54         42       48     66       75      33 #> 26  -6.48127545         77         66       63     88       76      72 #> 27   7.02794419         75         58       74     80       78      49 #> 28  -9.38907907         57         44       45     51       83      38 #> 29   6.48184600         85         71       71     77       74      55 #> 30   5.74567546         82         39       59     64       78      39 attitude$complaints_LMH <- cut(attitude$complaints, 3) adjust(attitude, effect = \"complaints_LMH\", select = \"rating\", multilevel = TRUE) #>         rating complaints privileges learning raises critical advance #> 1   -9.9809282         51         30       39     61       92      45 #> 2    2.6250549         64         51       54     63       73      47 #> 3   10.6250549         70         68       69     76       86      48 #> 4    0.6250549         63         45       47     54       84      35 #> 5    5.6503521         78         56       66     71       83      47 #> 6  -17.3749451         55         49       44     54       49      34 #> 7   -2.3749451         67         42       56     66       68      35 #> 8   -4.3496479         75         50       55     70       66      41 #> 9   -3.3496479         82         72       67     71       83      31 #> 10   6.6250549         61         45       47     62       80      41 #> 11  11.0190718         53         53       58     58       67      34 #> 12   6.6250549         60         47       39     59       74      41 #> 13   8.6250549         62         57       42     55       63      25 #> 14  -7.3496479         83         83       45     59       77      35 #> 15   1.6503521         77         54       72     79       77      46 #> 16   5.6503521         90         50       72     60       54      36 #> 17  -1.3496479         85         64       69     79       79      63 #> 18   4.6250549         60         65       75     55       80      60 #> 19   4.6250549         70         46       57     75       85      46 #> 20 -10.3749451         58         68       54     64       78      52 #> 21  -2.9809282         40         33       34     43       64      33 #> 22   3.6250549         61         52       62     66       80      41 #> 23  -7.3749451         66         52       50     63       80      37 #> 24 -12.9809282         37         42       58     50       57      49 #> 25  10.0190718         54         42       48     66       75      33 #> 26  -9.3496479         77         66       63     88       76      72 #> 27   2.6503521         75         58       74     80       78      49 #> 28 -12.3749451         57         44       45     51       83      38 #> 29   9.6503521         85         71       71     77       74      55 #> 30   6.6503521         82         39       59     64       78      39 #>    complaints_LMH #> 1     (36.9,54.7] #> 2     (54.7,72.3] #> 3     (54.7,72.3] #> 4     (54.7,72.3] #> 5     (72.3,90.1] #> 6     (54.7,72.3] #> 7     (54.7,72.3] #> 8     (72.3,90.1] #> 9     (72.3,90.1] #> 10    (54.7,72.3] #> 11    (36.9,54.7] #> 12    (54.7,72.3] #> 13    (54.7,72.3] #> 14    (72.3,90.1] #> 15    (72.3,90.1] #> 16    (72.3,90.1] #> 17    (72.3,90.1] #> 18    (54.7,72.3] #> 19    (54.7,72.3] #> 20    (54.7,72.3] #> 21    (36.9,54.7] #> 22    (54.7,72.3] #> 23    (54.7,72.3] #> 24    (36.9,54.7] #> 25    (36.9,54.7] #> 26    (72.3,90.1] #> 27    (72.3,90.1] #> 28    (54.7,72.3] #> 29    (72.3,90.1] #> 30    (72.3,90.1] # }  # Generate data data <- bayestestR::simulate_correlation(n = 100, r = 0.7) data$V2 <- (5 * data$V2) + 20 # Add intercept  # Adjust adjusted <- adjust(data, effect = \"V1\", select = \"V2\") adjusted_icpt <- adjust(data, effect = \"V1\", select = \"V2\", keep_intercept = TRUE)  # Visualize plot(   data$V1, data$V2,   pch = 19, col = \"blue\",   ylim = c(min(adjusted$V2), max(data$V2)),   main = \"Original (blue), adjusted (green), and adjusted - intercept kept (red) data\" ) abline(lm(V2 ~ V1, data = data), col = \"blue\") points(adjusted$V1, adjusted$V2, pch = 19, col = \"green\") abline(lm(V2 ~ V1, data = adjusted), col = \"green\") points(adjusted_icpt$V1, adjusted_icpt$V2, pch = 19, col = \"red\") abline(lm(V2 ~ V1, data = adjusted_icpt), col = \"red\")"},{"path":"https://easystats.github.io/datawizard/reference/assign_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign variable and value labels — assign_labels","title":"Assign variable and value labels — assign_labels","text":"Assign variable values labels variable variables data frame. Labels stored attributes (\"label\" variable labels \"labels\") value labels.","code":""},{"path":"https://easystats.github.io/datawizard/reference/assign_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign variable and value labels — assign_labels","text":"","code":"assign_labels(x, ...)  # S3 method for class 'numeric' assign_labels(x, variable = NULL, values = NULL, ...)  # S3 method for class 'data.frame' assign_labels(   x,   select = NULL,   exclude = NULL,   values = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/assign_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign variable and value labels — assign_labels","text":"x data frame, factor vector. ... Currently used. variable variable label string. values value labels (named) character vector. values named vector, length labels must equal length unique values. named vector, left-hand side (LHS) value x, right-hand side (RHS) associated value label. Non-matching labels omitted. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/assign_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign variable and value labels — assign_labels","text":"labelled variable, data frame labelled variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/assign_labels.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Assign variable and value labels — assign_labels","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/assign_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign variable and value labels — assign_labels","text":"","code":"x <- 1:3 # labelling by providing required number of labels assign_labels(   x,   variable = \"My x\",   values = c(\"one\", \"two\", \"three\") ) #> [1] 1 2 3 #> attr(,\"label\") #> [1] \"My x\" #> attr(,\"labels\") #>   one   two three  #>     1     2     3   # labelling using named vectors data(iris) out <- assign_labels(   iris$Species,   variable = \"Labelled Species\",   values = c(`setosa` = \"Spec1\", `versicolor` = \"Spec2\", `virginica` = \"Spec3\") ) str(out) #>  Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... #>  - attr(*, \"label\")= chr \"Labelled Species\" #>  - attr(*, \"labels\")= Named chr [1:3] \"setosa\" \"versicolor\" \"virginica\" #>   ..- attr(*, \"names\")= chr [1:3] \"Spec1\" \"Spec2\" \"Spec3\"  # data frame example out <- assign_labels(   iris,   select = \"Species\",   variable = \"Labelled Species\",   values = c(`setosa` = \"Spec1\", `versicolor` = \"Spec2\", `virginica` = \"Spec3\") ) str(out$Species) #>  Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... #>  - attr(*, \"label\")= chr \"Labelled Species\" #>  - attr(*, \"labels\")= Named chr [1:3] \"setosa\" \"versicolor\" \"virginica\" #>   ..- attr(*, \"names\")= chr [1:3] \"Spec1\" \"Spec2\" \"Spec3\"  # Partial labelling x <- 1:5 assign_labels(   x,   variable = \"My x\",   values = c(`1` = \"lowest\", `5` = \"highest\") ) #> [1] 1 2 3 4 5 #> attr(,\"label\") #> [1] \"My x\" #> attr(,\"labels\") #>  lowest highest  #>       1       5"},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode (or ","title":"Recode (or ","text":"functions divides range variables intervals recodes values inside intervals according related interval. basically wrapper around base R's cut(), providing simplified accessible way define interval breaks (cut-values).","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode (or ","text":"","code":"categorize(x, ...)  # S3 method for class 'numeric' categorize(   x,   split = \"median\",   n_groups = NULL,   range = NULL,   lowest = 1,   breaks = \"exclusive\",   labels = NULL,   verbose = TRUE,   ... )  # S3 method for class 'data.frame' categorize(   x,   select = NULL,   exclude = NULL,   split = \"median\",   n_groups = NULL,   range = NULL,   lowest = 1,   breaks = \"exclusive\",   labels = NULL,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode (or ","text":"x (grouped) data frame, numeric vector factor. ... used. split Character vector, indicating breaks split variables, numeric values values indicating breaks. character, may one \"median\", \"mean\", \"quantile\", \"equal_length\", \"equal_range\". \"median\" \"mean\" return dichotomous variables, split mean median, respectively. \"quantile\" \"equal_length\" split variable n_groups groups, group refers interval specific range values. Thus, length interval based number groups. \"equal_range\" also splits variable multiple groups, however, length interval given, number resulting groups (hence, number breaks) determined many intervals can generated, based full range variable. n_groups split \"quantile\" \"equal_length\", defines number requested groups (.e. resulting number levels values) recoded variable(s). \"quantile\" define intervals based distribution variable, \"equal_length\" tries divide range variable pieces equal length. range split = \"equal_range\", defines range values recoded new value. lowest Minimum value recoded variable(s). NULL (default), numeric variables, minimum original input preserved. factors, default minimum 1. split = \"equal_range\", default minimum always 1, unless specified otherwise lowest. breaks Character, indicating whether breaks categorizing data \"inclusive\" (values indicate upper bound previous group interval) \"exclusive\" (values indicate lower bound next group interval begin). Use labels = \"range\" make behaviour easier see. labels Character vector value labels. NULL, categorize() returns factors instead numeric variables, labels used labelling factor levels. Can also \"mean\", \"median\", \"range\" \"observed\" factor labels mean/median, requested range (even values range present data) observed range (range actual recoded values) group. See 'Examples'. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode (or ","text":"x, recoded groups. default x numeric, unless labels specified. case, factor returned, factor levels (.e. recoded groups labelled accordingly.","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"splits-and-breaks-cut-off-values-","dir":"Reference","previous_headings":"","what":"Splits and breaks (cut-off values)","title":"Recode (or ","text":"Breaks default exclusive, means values indicate lower bound next group interval begin. Take simple example, numeric variable values 1 9. median 5, thus first interval ranges 1-4 recoded 1, 5-9 turn 2 (compare cbind(1:9, categorize(1:9))). variable, using split = \"quantile\" n_groups = 3 define breaks 3.67 6.33 (see quantile(1:9, probs = c(1/3, 2/3))), means values 1 3 belong first interval recoded 1 (next interval starts 3.67), 4 6 2 7 9 3. opposite behaviour can achieved using breaks = \"inclusive\", case","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"recoding-into-groups-with-equal-size-or-range","dir":"Reference","previous_headings":"","what":"Recoding into groups with equal size or range","title":"Recode (or ","text":"split = \"equal_length\" split = \"equal_range\" try divide range x intervals similar () length. difference split = \"equal_length\" divide range x n_groups pieces thereby defining intervals used breaks (hence, equivalent cut(x, breaks = n_groups)),  split = \"equal_range\" cut x intervals length range, first interval defaults starts 1. lowest (starting) value interval can defined using lowest argument.","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Recode (or ","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode (or ","text":"","code":"set.seed(123) x <- sample(1:10, size = 50, replace = TRUE)  table(x) #> x #>  1  2  3  4  5  6  7  8  9 10  #>  2  3  5  3  7  5  5  2 11  7   # by default, at median table(categorize(x)) #>  #>  1  2  #> 25 25   # into 3 groups, based on distribution (quantiles) table(categorize(x, split = \"quantile\", n_groups = 3)) #>  #>  1  2  3  #> 13 19 18   # into 3 groups, user-defined break table(categorize(x, split = c(3, 5))) #>  #>  1  2  3  #>  5  8 37   set.seed(123) x <- sample(1:100, size = 500, replace = TRUE)  # into 5 groups, try to recode into intervals of similar length, # i.e. the range within groups is the same for all groups table(categorize(x, split = \"equal_length\", n_groups = 5)) #>  #>   1   2   3   4   5  #>  89 116  96  94 105   # into 5 groups, try to return same range within groups # i.e. 1-20, 21-40, 41-60, etc. Since the range of \"x\" is # 1-100, and we have a range of 20, this results into 5 # groups, and thus is for this particular case identical # to the previous result. table(categorize(x, split = \"equal_range\", range = 20)) #>  #>   1   2   3   4   5  #>  89 116  96  94 105   # return factor with value labels instead of numeric value set.seed(123) x <- sample(1:10, size = 30, replace = TRUE) categorize(x, \"equal_length\", n_groups = 3) #>  [1] 1 1 3 1 2 2 2 2 3 3 2 1 3 3 3 1 3 3 3 3 3 1 2 1 3 2 3 3 3 3 categorize(x, \"equal_length\", n_groups = 3, labels = c(\"low\", \"mid\", \"high\")) #>  [1] low  low  high low  mid  mid  mid  mid  high high mid  low  high high high #> [16] low  high high high high high low  mid  low  high mid  high high high high #> Levels: low mid high  # cut numeric into groups with the mean or median as a label name x <- sample(1:10, size = 30, replace = TRUE) categorize(x, \"equal_length\", n_groups = 3, labels = \"mean\") #>  [1] 8.45 8.45 5.33 8.45 5.33 5.33 8.45 1.57 5.33 8.45 1.57 1.57 8.45 8.45 5.33 #> [16] 5.33 8.45 8.45 5.33 5.33 8.45 5.33 5.33 8.45 1.57 5.33 1.57 1.57 1.57 5.33 #> Levels: 1.57 5.33 8.45 categorize(x, \"equal_length\", n_groups = 3, labels = \"median\") #>  [1] 9.00 9.00 5.50 9.00 5.50 5.50 9.00 2.00 5.50 9.00 2.00 2.00 9.00 9.00 5.50 #> [16] 5.50 9.00 9.00 5.50 5.50 9.00 5.50 5.50 9.00 2.00 5.50 2.00 2.00 2.00 5.50 #> Levels: 2.00 5.50 9.00  # cut numeric into groups with the requested range as a label name # each category has the same range, and labels indicate this range categorize(mtcars$mpg, \"equal_length\", n_groups = 5, labels = \"range\") #>  [1] [19.8,24.5) [19.8,24.5) [19.8,24.5) [19.8,24.5) [15.1,19.8) [15.1,19.8) #>  [7] [10.4,15.1) [19.8,24.5) [19.8,24.5) [15.1,19.8) [15.1,19.8) [15.1,19.8) #> [13] [15.1,19.8) [15.1,19.8) [10.4,15.1) [10.4,15.1) [10.4,15.1) [29.2,33.9] #> [19] [29.2,33.9] [29.2,33.9] [19.8,24.5) [15.1,19.8) [15.1,19.8) [10.4,15.1) #> [25] [15.1,19.8) [24.5,29.2) [24.5,29.2) [29.2,33.9] [15.1,19.8) [15.1,19.8) #> [31] [10.4,15.1) [19.8,24.5) #> Levels: [10.4,15.1) [15.1,19.8) [19.8,24.5) [24.5,29.2) [29.2,33.9] # in this example, each category has the same range, but labels only refer # to the ranges of the actual values (present in the data) inside each group categorize(mtcars$mpg, \"equal_length\", n_groups = 5, labels = \"observed\") #>  [1] (21-24.4)   (21-24.4)   (21-24.4)   (21-24.4)   (15.2-19.7) (15.2-19.7) #>  [7] (10.4-15)   (21-24.4)   (21-24.4)   (15.2-19.7) (15.2-19.7) (15.2-19.7) #> [13] (15.2-19.7) (15.2-19.7) (10.4-15)   (10.4-15)   (10.4-15)   (30.4-33.9) #> [19] (30.4-33.9) (30.4-33.9) (21-24.4)   (15.2-19.7) (15.2-19.7) (10.4-15)   #> [25] (15.2-19.7) (26-27.3)   (26-27.3)   (30.4-33.9) (15.2-19.7) (15.2-19.7) #> [31] (10.4-15)   (21-24.4)   #> Levels: (10.4-15) (15.2-19.7) (21-24.4) (26-27.3) (30.4-33.9)"},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":null,"dir":"Reference","previous_headings":"","what":"Centering (Grand-Mean Centering) — center","title":"Centering (Grand-Mean Centering) — center","text":"Performs grand-mean centering data.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Centering (Grand-Mean Centering) — center","text":"","code":"center(x, ...)  centre(x, ...)  # S3 method for class 'numeric' center(   x,   robust = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   verbose = TRUE,   ... )  # S3 method for class 'data.frame' center(   x,   select = NULL,   exclude = NULL,   robust = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   force = FALSE,   remove_na = c(\"none\", \"selected\", \"all\"),   append = FALSE,   ignore_case = FALSE,   verbose = TRUE,   regex = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Centering (Grand-Mean Centering) — center","text":"x (grouped) data frame, (numeric character) vector factor. ... Currently used. robust Logical, TRUE, centering done subtracting median variables. FALSE, variables centered subtracting mean. weights Can NULL (weighting), : data frames: numeric vector weights, character name column data.frame contains weights. numeric vectors: numeric vector weights. reference data frame variable centrality deviation computed instead input variable. Useful standardizing subset new data according another data frame. center Numeric value, can used alternative reference define reference centrality. center length 1, recycled match length selected variables centering. Else, center must length number selected variables. Values center matched selected variables provided order, unless named vector given. case, names matched names selected variables. verbose Toggle warnings messages. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. force Logical, TRUE, forces centering factors well. Factors converted numerical values, lowest level value 1 (unless factor numeric levels, converted corresponding numeric value). remove_na missing values (NA) treated: \"none\" (default): column's standardization done separately, ignoring NAs. Else, rows NA columns selected select / exclude (\"selected\") columns (\"\") dropped standardization, resulting data frame include cases. append Logical string. TRUE, centered variables get new column names (suffix \"_c\") appended (column bind) x, thus returning original centered variables. FALSE, original variables x overwritten centered versions. character value, centered variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Centering (Grand-Mean Centering) — center","text":"centered variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Centering (Grand-Mean Centering) — center","text":"Difference centering standardizing: Standardized variables computed subtracting mean variable dividing standard deviation, centering variables involves subtraction.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Centering (Grand-Mean Centering) — center","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Centering (Grand-Mean Centering) — center","text":"","code":"data(iris)  # entire data frame or a vector head(iris$Sepal.Width) #> [1] 3.5 3.0 3.2 3.1 3.6 3.9 head(center(iris$Sepal.Width)) #> [1]  0.44266667 -0.05733333  0.14266667  0.04266667  0.54266667  0.84266667 head(center(iris)) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1   -0.7433333  0.44266667       -2.358  -0.9993333  setosa #> 2   -0.9433333 -0.05733333       -2.358  -0.9993333  setosa #> 3   -1.1433333  0.14266667       -2.458  -0.9993333  setosa #> 4   -1.2433333  0.04266667       -2.258  -0.9993333  setosa #> 5   -0.8433333  0.54266667       -2.358  -0.9993333  setosa #> 6   -0.4433333  0.84266667       -2.058  -0.7993333  setosa head(center(iris, force = TRUE)) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1   -0.7433333  0.44266667       -2.358  -0.9993333      -1 #> 2   -0.9433333 -0.05733333       -2.358  -0.9993333      -1 #> 3   -1.1433333  0.14266667       -2.458  -0.9993333      -1 #> 4   -1.2433333  0.04266667       -2.258  -0.9993333      -1 #> 5   -0.8433333  0.54266667       -2.358  -0.9993333      -1 #> 6   -0.4433333  0.84266667       -2.058  -0.7993333      -1  # only the selected columns from a data frame center(anscombe, select = c(\"x1\", \"x3\")) #>    x1 x2 x3 x4    y1   y2    y3    y4 #> 1   1 10  1  8  8.04 9.14  7.46  6.58 #> 2  -1  8 -1  8  6.95 8.14  6.77  5.76 #> 3   4 13  4  8  7.58 8.74 12.74  7.71 #> 4   0  9  0  8  8.81 8.77  7.11  8.84 #> 5   2 11  2  8  8.33 9.26  7.81  8.47 #> 6   5 14  5  8  9.96 8.10  8.84  7.04 #> 7  -3  6 -3  8  7.24 6.13  6.08  5.25 #> 8  -5  4 -5 19  4.26 3.10  5.39 12.50 #> 9   3 12  3  8 10.84 9.13  8.15  5.56 #> 10 -2  7 -2  8  4.82 7.26  6.42  7.91 #> 11 -4  5 -4  8  5.68 4.74  5.73  6.89 center(anscombe, exclude = c(\"x1\", \"x3\")) #>    x1 x2 x3 x4          y1         y2    y3         y4 #> 1  10  1 10 -1  0.53909091  1.6390909 -0.04 -0.9209091 #> 2   8 -1  8 -1 -0.55090909  0.6390909 -0.73 -1.7409091 #> 3  13  4 13 -1  0.07909091  1.2390909  5.24  0.2090909 #> 4   9  0  9 -1  1.30909091  1.2690909 -0.39  1.3390909 #> 5  11  2 11 -1  0.82909091  1.7590909  0.31  0.9690909 #> 6  14  5 14 -1  2.45909091  0.5990909  1.34 -0.4609091 #> 7   6 -3  6 -1 -0.26090909 -1.3709091 -1.42 -2.2509091 #> 8   4 -5  4 10 -3.24090909 -4.4009091 -2.11  4.9990909 #> 9  12  3 12 -1  3.33909091  1.6290909  0.65 -1.9409091 #> 10  7 -2  7 -1 -2.68090909 -0.2409091 -1.08  0.4090909 #> 11  5 -4  5 -1 -1.82090909 -2.7609091 -1.77 -0.6109091  # centering with reference center and scale d <- data.frame(   a = c(-2, -1, 0, 1, 2),   b = c(3, 4, 5, 6, 7) )  # default centering at mean center(d) #>    a  b #> 1 -2 -2 #> 2 -1 -1 #> 3  0  0 #> 4  1  1 #> 5  2  2  # centering, using 0 as mean center(d, center = 0) #>    a b #> 1 -2 3 #> 2 -1 4 #> 3  0 5 #> 4  1 6 #> 5  2 7  # centering, using -5 as mean center(d, center = -5) #>   a  b #> 1 3  8 #> 2 4  9 #> 3 5 10 #> 4 6 11 #> 5 7 12"},{"path":"https://easystats.github.io/datawizard/reference/coef_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the coefficient of variation — coef_var","title":"Compute the coefficient of variation — coef_var","text":"Compute coefficient variation (CV, ratio standard deviation mean, \\(\\sigma/\\mu\\)) set numeric values.","code":""},{"path":"https://easystats.github.io/datawizard/reference/coef_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the coefficient of variation — coef_var","text":"","code":"coef_var(x, ...)  distribution_coef_var(x, ...)  # S3 method for class 'numeric' coef_var(   x,   mu = NULL,   sigma = NULL,   method = c(\"standard\", \"unbiased\", \"median_mad\", \"qcd\"),   trim = 0,   remove_na = FALSE,   n = NULL,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/coef_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the coefficient of variation — coef_var","text":"x numeric vector ratio scale (see details), vector values can coerced one. ... arguments passed computation functions. mu numeric vector mean values use compute coefficient variation. supplied, x used compute mean. sigma numeric vector standard deviation values use compute coefficient variation. supplied, x used compute SD. method Method use compute CV. Can \"standard\" compute dividing standard deviation mean, \"unbiased\" unbiased estimator normally distributed data, one two robust alternatives: \"median_mad\" divide median stats::mad(), \"qcd\" (quartile coefficient dispersion, interquartile range divided sum quartiles [twice midhinge]: \\((Q_3 - Q_1)/(Q_3 + Q_1)\\). trim fraction (0 0.5) values trimmed end x mean standard deviation (measures) computed. Values trim outside range (0 0.5) taken nearest endpoint. remove_na Logical. NA values removed computing (TRUE) (FALSE, default)? n method = \"unbiased\" mu sigma provided (computed x), sample size use adjust computed CV small-sample bias?","code":""},{"path":"https://easystats.github.io/datawizard/reference/coef_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the coefficient of variation — coef_var","text":"computed coefficient variation x.","code":""},{"path":"https://easystats.github.io/datawizard/reference/coef_var.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the coefficient of variation — coef_var","text":"CV applicable values taken ratio scale: values fixed meaningfully defined 0 (either lowest highest possible value), ratios interpretable example, many sandwiches eaten week? 0 means \"none\" 20 sandwiches 4 times 5 sandwiches. center number sandwiches, longer ratio scale (0 \"none\" mean, ratio 4 -2 meaningful). Scaling ratio scale still results ratio scale. can re define \"many half sandwiches eat week ( = sandwiches * 0.5) 0 still mean \"none\", 20 half-sandwiches still 4 times 5 half-sandwiches. means CV invariant shifting, scaling:","code":"sandwiches <- c(0, 4, 15, 0, 0, 5, 2, 7) coef_var(sandwiches) #> [1] 1.239094  coef_var(sandwiches / 2) # same #> [1] 1.239094  coef_var(sandwiches + 4) # different! 0 is no longer meaningful! #> [1] 0.6290784"},{"path":"https://easystats.github.io/datawizard/reference/coef_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the coefficient of variation — coef_var","text":"","code":"coef_var(1:10) #> [1] 0.5504819 coef_var(c(1:10, 100), method = \"median_mad\") #> [1] 0.7413 coef_var(c(1:10, 100), method = \"qcd\") #> [1] 0.4166667 coef_var(mu = 10, sigma = 20) #> [1] 2 coef_var(mu = 10, sigma = 20, method = \"unbiased\", n = 30) #> [1] 2.250614"},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to Numeric (if possible) — coerce_to_numeric","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"Tries convert vector numeric possible (warnings errors). Otherwise, leaves .","code":""},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"","code":"coerce_to_numeric(x)"},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"x vector converted.","code":""},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"Numeric vector (possible)","code":""},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"","code":"coerce_to_numeric(c(\"1\", \"2\")) #> [1] 1 2 coerce_to_numeric(c(\"1\", \"2\", \"A\")) #> [1] \"1\" \"2\" \"A\""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for working with column names — row_to_colnames","title":"Tools for working with column names — row_to_colnames","text":"Tools working column names","code":""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for working with column names — row_to_colnames","text":"","code":"row_to_colnames(x, row = 1, na_prefix = \"x\", verbose = TRUE)  colnames_to_row(x, prefix = \"x\")"},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for working with column names — row_to_colnames","text":"x data frame. row Row use column names. na_prefix Prefix give column name row NA. Default 'x', incremented NA (x1, x2, etc.). verbose Toggle warnings. prefix Prefix give column name. Default 'x', incremented column (x1, x2, etc.).","code":""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for working with column names — row_to_colnames","text":"row_to_colnames() colnames_to_row() return data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools for working with column names — row_to_colnames","text":"","code":"# Convert a row to column names -------------------------------- test <- data.frame(   a = c(\"iso\", 2, 5),   b = c(\"year\", 3, 6),   c = c(\"value\", 5, 7) ) test #>     a    b     c #> 1 iso year value #> 2   2    3     5 #> 3   5    6     7 row_to_colnames(test) #>   iso year value #> 2   2    3     5 #> 3   5    6     7  # Convert column names to row -------------------------------- test <- data.frame(   ARG = c(\"BRA\", \"FRA\"),   `1960` = c(1960, 1960),   `2000` = c(2000, 2000) ) test #>   ARG X1960 X2000 #> 1 BRA  1960  2000 #> 2 FRA  1960  2000 colnames_to_row(test) #>    x1    x2    x3 #> 1 ARG X1960 X2000 #> 2 BRA  1960  2000 #> 3 FRA  1960  2000"},{"path":"https://easystats.github.io/datawizard/reference/contr.deviation.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviation Contrast Matrix — contr.deviation","title":"Deviation Contrast Matrix — contr.deviation","text":"Build deviation contrast matrix, type effects contrast matrix.","code":""},{"path":"https://easystats.github.io/datawizard/reference/contr.deviation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviation Contrast Matrix — contr.deviation","text":"","code":"contr.deviation(n, base = 1, contrasts = TRUE, sparse = FALSE)"},{"path":"https://easystats.github.io/datawizard/reference/contr.deviation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviation Contrast Matrix — contr.deviation","text":"n vector levels factor, number levels. base integer specifying group considered     baseline group. Ignored contrasts FALSE. contrasts logical indicating whether contrasts     computed. sparse logical indicating result sparse     (class dgCMatrix), using     package Matrix.","code":""},{"path":"https://easystats.github.io/datawizard/reference/contr.deviation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Deviation Contrast Matrix — contr.deviation","text":"effects coding, unlike treatment/dummy coding (stats::contr.treatment()), contrast sums 0. regressions models, results intercept represents (unweighted) average group means. ANOVA settings, also guarantees lower order effects represent main effects (simple conditional effects, case using R's default stats::contr.treatment()).  Deviation coding (contr.deviation) type effects coding. deviation coding, coefficients factor variables interpreted difference factor level base level (interpretation treatment/dummy coding). example, factor group levels \"\", \"B\", \"C\", contr.devation, intercept represents overall mean (average group means 3 groups), coefficients groupB groupC represent differences group mean B C group means, respectively.  Sum coding (stats::contr.sum()) another type effects coding. sum coding, coefficients factor variables interpreted difference factor level grand (across-groups) mean. example, factor group levels \"\", \"B\", \"C\", contr.sum, intercept represents overall mean (average group means 3 groups), coefficients group1 group2 represent differences B group means overall mean, respectively.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/contr.deviation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deviation Contrast Matrix — contr.deviation","text":"","code":"if (FALSE) { # !identical(Sys.getenv(\"IN_PKGDOWN\"), \"true\") # \\donttest{ data(\"mtcars\")  mtcars <- data_modify(mtcars, cyl = factor(cyl))  c.treatment <- cbind(Intercept = 1, contrasts(mtcars$cyl)) solve(c.treatment) #>            4 6 8 #> Intercept  1 0 0  # mean of the 1st level #> 6         -1 1 0  # 2nd level - 1st level #> 8         -1 0 1  # 3rd level - 1st level  contrasts(mtcars$cyl) <- contr.sum c.sum <- cbind(Intercept = 1, contrasts(mtcars$cyl)) solve(c.sum) #>                4      6      8 #> Intercept  0.333  0.333  0.333   # overall mean #>            0.667 -0.333 -0.333   # deviation of 1st from overall mean #>           -0.333  0.667 -0.333   # deviation of 2nd from overall mean   contrasts(mtcars$cyl) <- contr.deviation c.deviation <- cbind(Intercept = 1, contrasts(mtcars$cyl)) solve(c.deviation) #>                4     6     8 #> Intercept  0.333 0.333 0.333   # overall mean #> 6         -1.000 1.000 0.000   # 2nd level - 1st level #> 8         -1.000 0.000 1.000   # 3rd level - 1st level  ## With Interactions ----------------------------------------- mtcars <- data_modify(mtcars, am = C(am, contr = contr.deviation)) mtcars <- data_arrange(mtcars, select = c(\"cyl\", \"am\"))  mm <- unique(model.matrix(~ cyl * am, data = mtcars)) rownames(mm) <- c(   \"cyl4.am0\", \"cyl4.am1\", \"cyl6.am0\",   \"cyl6.am1\", \"cyl8.am0\", \"cyl8.am1\" )  solve(mm) #>             cyl4.am0 cyl4.am1 cyl6.am0 cyl6.am1 cyl8.am0 cyl8.am1 #> (Intercept)    0.167    0.167    0.167    0.167    0.167    0.167  # overall mean #> cyl6          -0.500   -0.500    0.500    0.500    0.000    0.000  # cyl MAIN eff: 2nd - 1st #> cyl8          -0.500   -0.500    0.000    0.000    0.500    0.500  # cyl MAIN eff: 2nd - 1st #> am1           -0.333    0.333   -0.333    0.333   -0.333    0.333  # am MAIN eff #> cyl6:am1       1.000   -1.000   -1.000    1.000    0.000    0.000 #> cyl8:am1       1.000   -1.000    0.000    0.000   -1.000    1.000 # } }"},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace missing values in a variable or a data frame. — convert_na_to","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"Replace missing values variable data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"","code":"convert_na_to(x, ...)  # S3 method for class 'numeric' convert_na_to(x, replacement = NULL, verbose = TRUE, ...)  # S3 method for class 'character' convert_na_to(x, replacement = NULL, verbose = TRUE, ...)  # S3 method for class 'data.frame' convert_na_to(   x,   select = NULL,   exclude = NULL,   replacement = NULL,   replace_num = replacement,   replace_char = replacement,   replace_fac = replacement,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"x numeric, factor, character vector, data frame. ... used. replacement Numeric character value used replace NA. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. replace_num Value replace NA variable type numeric. replace_char Value replace NA variable type character. replace_fac Value replace NA variable type factor. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"x, NA values replaced replacement.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"","code":"# Convert NA to 0 in a numeric vector convert_na_to(   c(9, 3, NA, 2, 3, 1, NA, 8),   replacement = 0 ) #> [1] 9 3 0 2 3 1 0 8  # Convert NA to \"missing\" in a character vector convert_na_to(   c(\"a\", NA, \"d\", \"z\", NA, \"t\"),   replacement = \"missing\" ) #> [1] \"a\"       \"missing\" \"d\"       \"z\"       \"missing\" \"t\"        ### For data frames  test_df <- data.frame(   x = c(1, 2, NA),   x2 = c(4, 5, NA),   y = c(\"a\", \"b\", NA) )  # Convert all NA to 0 in numeric variables, and all NA to \"missing\" in # character variables convert_na_to(   test_df,   replace_num = 0,   replace_char = \"missing\" ) #>   x x2       y #> 1 1  4       a #> 2 2  5       b #> 3 0  0 missing  # Convert a specific variable in the data frame convert_na_to(   test_df,   replace_num = 0,   replace_char = \"missing\",   select = \"x\" ) #>   x x2    y #> 1 1  4    a #> 2 2  5    b #> 3 0 NA <NA>  # Convert all variables starting with \"x\" convert_na_to(   test_df,   replace_num = 0,   replace_char = \"missing\",   select = starts_with(\"x\") ) #>   x x2    y #> 1 1  4    a #> 2 2  5    b #> 3 0  0 <NA>  # Convert NA to 1 in variable 'x2' and to 0 in all other numeric # variables convert_na_to(   test_df,   replace_num = 0,   select = list(x2 = 1) ) #>   x x2    y #> 1 1  4    a #> 2 2  5    b #> 3 0  1 <NA>"},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert non-missing values in a variable into missing values. — convert_to_na","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"Convert non-missing values variable missing values.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"","code":"convert_to_na(x, ...)  # S3 method for class 'numeric' convert_to_na(x, na = NULL, verbose = TRUE, ...)  # S3 method for class 'factor' convert_to_na(x, na = NULL, drop_levels = FALSE, verbose = TRUE, ...)  # S3 method for class 'data.frame' convert_to_na(   x,   select = NULL,   exclude = NULL,   na = NULL,   drop_levels = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"x vector, factor data frame. ... used. na Numeric, character vector logical (list numeric, character vectors logicals) values converted NA. Numeric values applied numeric vectors, character values used factors, character vectors date variables, logical values logical vectors. verbose Toggle warnings. drop_levels Logical, factors, specific levels replaced NA, unused levels dropped? select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"x, values na converted NA.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"","code":"x <- sample(1:6, size = 30, replace = TRUE) x #>  [1] 6 4 1 6 6 3 6 5 3 6 2 5 5 3 2 2 2 4 2 2 6 4 4 6 1 6 6 6 3 6 # values 4 and 5 to NA convert_to_na(x, na = 4:5) #>  [1]  6 NA  1  6  6  3  6 NA  3  6  2 NA NA  3  2  2  2 NA  2  2  6 NA NA  6  1 #> [26]  6  6  6  3  6  # data frames set.seed(123) x <- data.frame(   a = sample(1:6, size = 20, replace = TRUE),   b = sample(letters[1:6], size = 20, replace = TRUE),   c = sample(c(30:33, 99), size = 20, replace = TRUE) ) # for all numerics, convert 5 to NA. Character/factor will be ignored. convert_to_na(x, na = 5) #> Could not convert values into `NA` for a factor or character variable. #>   To do this, `na` needs to be a character vector, or a list that contains #>   character vector elements. #>     a b  c #> 1   3 a 33 #> 2   6 e 99 #> 3   3 c 99 #> 4   2 b 32 #> 5   2 b 30 #> 6   6 a 31 #> 7   3 f 99 #> 8  NA c 99 #> 9   4 d 33 #> 10  6 f 99 #> 11  6 a 31 #> 12  1 c 30 #> 13  2 e 30 #> 14  3 d 32 #> 15 NA b 30 #> 16  3 e 99 #> 17  3 a 30 #> 18  1 a 31 #> 19  4 b 33 #> 20  1 c 33  # for numerics, 5 to NA, for character/factor, \"f\" to NA convert_to_na(x, na = list(6, \"f\")) #>     a    b  c #> 1   3    a 33 #> 2  NA    e 99 #> 3   3    c 99 #> 4   2    b 32 #> 5   2    b 30 #> 6  NA    a 31 #> 7   3 <NA> 99 #> 8   5    c 99 #> 9   4    d 33 #> 10 NA <NA> 99 #> 11 NA    a 31 #> 12  1    c 30 #> 13  2    e 30 #> 14  3    d 32 #> 15  5    b 30 #> 16  3    e 99 #> 17  3    a 30 #> 18  1    a 31 #> 19  4    b 33 #> 20  1    c 33  # select specific variables convert_to_na(x, select = c(\"a\", \"b\"), na = list(6, \"f\")) #>     a    b  c #> 1   3    a 33 #> 2  NA    e 99 #> 3   3    c 99 #> 4   2    b 32 #> 5   2    b 30 #> 6  NA    a 31 #> 7   3 <NA> 99 #> 8   5    c 99 #> 9   4    d 33 #> 10 NA <NA> 99 #> 11 NA    a 31 #> 12  1    c 30 #> 13  2    e 30 #> 14  3    d 32 #> 15  5    b 30 #> 16  3    e 99 #> 17  3    a 30 #> 18  1    a 31 #> 19  4    b 33 #> 20  1    c 33"},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrange rows by column values — data_arrange","title":"Arrange rows by column values — data_arrange","text":"data_arrange() orders rows data frame values selected columns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrange rows by column values — data_arrange","text":"","code":"data_arrange(data, select = NULL, safe = TRUE)"},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrange rows by column values — data_arrange","text":"data data frame, object can coerced data frame. select Character vector column names. Use dash just column name arrange decreasing order, example \"-x1\". safe throw error one variables specified exist.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arrange rows by column values — data_arrange","text":"data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arrange rows by column values — data_arrange","text":"","code":"# Arrange using several variables data_arrange(head(mtcars), c(\"gear\", \"carb\")) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4  # Arrange in decreasing order data_arrange(head(mtcars), \"-carb\") #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1  # Throw an error if one of the variables specified doesn't exist try(data_arrange(head(mtcars), c(\"gear\", \"foo\"), safe = FALSE)) #> Error : The following column(s) don't exist in the dataset: foo. #>   Possibly misspelled?"},{"path":"https://easystats.github.io/datawizard/reference/data_codebook.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a codebook of a data frame. — data_codebook","title":"Generate a codebook of a data frame. — data_codebook","text":"data_codebook() generates codebooks data frames, .e. overviews variables information variable (like labels, values value range, frequencies, amount missing values).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_codebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a codebook of a data frame. — data_codebook","text":"","code":"data_codebook(   data,   select = NULL,   exclude = NULL,   variable_label_width = NULL,   value_label_width = NULL,   max_values = 10,   range_at = 6,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'data_codebook' print_html(   x,   font_size = \"100%\",   line_padding = 3,   row_color = \"#eeeeee\",   ... )  # S3 method for class 'data_codebook' display(   object,   format = \"markdown\",   font_size = \"100%\",   line_padding = 3,   row_color = \"#eeeeee\",   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_codebook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a codebook of a data frame. — data_codebook","text":"data data frame, object can coerced data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. variable_label_width Length variable labels. Longer labels wrapped variable_label_width chars. NULL, longer labels split multiple lines. applies labelled data. value_label_width Length value labels. Longer labels shortened, remaining part truncated. applies labelled data factor levels. max_values Number maximum values displayed. Can used avoid many rows variables lots unique values. range_at Indicates many unique values numeric vector needed order print range variable instead frequency table numeric values. Can useful data contains numeric variables unique values full frequency tables instead value ranges displayed. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings messages . ... Arguments passed methods. x (grouped) data frame, vector statistical model (unstandardize() model). font_size HTML tables, font size. line_padding HTML tables, distance (pixel) lines. row_color HTML tables, fill color odd rows. object object returned data_tabulate(). format String, indicating output format. Can \"markdown\" \"html\", \"tt\". format = \"html\" create HTML table using gt package. format = \"tt\" creates tinytable object, either printed markdown HTML table, depending environment. See insight::export_table() details.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_codebook.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a codebook of a data frame. — data_codebook","text":"formatted data frame, summarizing content data frame. Returned columns include column index variables original data frame (ID), column name, variable label (data labelled), type variable, number missing values, unique values (value range), value labels (labelled data), frequency table (N value). columns formatted character vectors.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_codebook.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generate a codebook of a data frame. — data_codebook","text":"methods print() data frame nicer output, well methods printing markdown HTML format (print_md() print_html()). print() method text outputs passes arguments ... insight::export_table().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_codebook.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a codebook of a data frame. — data_codebook","text":"","code":"data(iris) data_codebook(iris, select = starts_with(\"Sepal\")) #> iris (150 rows and 5 variables, 2 shown) #>  #> ID | Name         | Type    | Missings |     Values |   N #> ---+--------------+---------+----------+------------+---- #> 1  | Sepal.Length | numeric | 0 (0.0%) | [4.3, 7.9] | 150 #> ---+--------------+---------+----------+------------+---- #> 2  | Sepal.Width  | numeric | 0 (0.0%) |   [2, 4.4] | 150 #> ---------------------------------------------------------  data(efc) data_codebook(efc) #> efc (100 rows and 5 variables, 5 shown) #>  #> ID | Name     | Label                                    | Type        #> ---+----------+------------------------------------------+------------ #> 1  | c12hour  | average number of hours of care per week | numeric     #> ---+----------+------------------------------------------+------------ #> 2  | e16sex   | elder's gender                           | numeric     #>    |          |                                          |             #> ---+----------+------------------------------------------+------------ #> 3  | e42dep   | elder's dependency                       | categorical #>    |          |                                          |             #>    |          |                                          |             #>    |          |                                          |             #> ---+----------+------------------------------------------+------------ #> 4  | c172code | carer's level of education               | numeric     #>    |          |                                          |             #>    |          |                                          |             #> ---+----------+------------------------------------------+------------ #> 5  | neg_c_7  | Negative impact with 7 items             | numeric     #> ---------------------------------------------------------------------- #>  #> ID |   Missings |   Values | Value Labels                    |          N #> ---+------------+----------+---------------------------------+----------- #> 1  |   2 (2.0%) | [5, 168] |                                 |         98 #> ---+------------+----------+---------------------------------+----------- #> 2  |   0 (0.0%) |        1 | male                            | 46 (46.0%) #>    |            |        2 | female                          | 54 (54.0%) #> ---+------------+----------+---------------------------------+----------- #> 3  |   3 (3.0%) |        1 | independent                     |  2 ( 2.1%) #>    |            |        2 | slightly dependent              |  4 ( 4.1%) #>    |            |        3 | moderately dependent            | 28 (28.9%) #>    |            |        4 | severely dependent              | 63 (64.9%) #> ---+------------+----------+---------------------------------+----------- #> 4  | 10 (10.0%) |        1 | low level of education          |  8 ( 8.9%) #>    |            |        2 | intermediate level of education | 66 (73.3%) #>    |            |        3 | high level of education         | 16 (17.8%) #> ---+------------+----------+---------------------------------+----------- #> 5  |   3 (3.0%) |  [7, 28] |                                 |         97 #> -------------------------------------------------------------------------  # shorten labels data_codebook(efc, variable_label_width = 20, value_label_width = 15) #> efc (100 rows and 5 variables, 5 shown) #>  #> ID | Name     | Label              | Type        |   Missings |   Values #> ---+----------+--------------------+-------------+------------+--------- #> 1  | c12hour  | average number of  | numeric     |   2 (2.0%) | [5, 168] #>    |          | hours of care per  |             |            |          #>    |          | week               |             |            |          #> ---+----------+--------------------+-------------+------------+--------- #> 2  | e16sex   | elder's gender     | numeric     |   0 (0.0%) |        1 #>    |          |                    |             |            |        2 #> ---+----------+--------------------+-------------+------------+--------- #> 3  | e42dep   | elder's dependency | categorical |   3 (3.0%) |        1 #>    |          |                    |             |            |        2 #>    |          |                    |             |            |        3 #>    |          |                    |             |            |        4 #> ---+----------+--------------------+-------------+------------+--------- #> 4  | c172code | carer's level of   | numeric     | 10 (10.0%) |        1 #>    |          | education          |             |            |        2 #>    |          |                    |             |            |        3 #> ---+----------+--------------------+-------------+------------+--------- #> 5  | neg_c_7  | Negative impact    | numeric     |   3 (3.0%) |  [7, 28] #>    |          | with 7 items       |             |            |          #> ------------------------------------------------------------------------ #>  #> ID | Value Labels     |          N #> ---+------------------+----------- #> 1  |                  |         98 #>    |                  |            #>    |                  |            #> ---+------------------+----------- #> 2  | male             | 46 (46.0%) #>    | female           | 54 (54.0%) #> ---+------------------+----------- #> 3  | independent      |  2 ( 2.1%) #>    | slightly...      |  4 ( 4.1%) #>    | moderately...    | 28 (28.9%) #>    | severely...      | 63 (64.9%) #> ---+------------------+----------- #> 4  | low level of...  |  8 ( 8.9%) #>    | intermediate...  | 66 (73.3%) #>    | high level of... | 16 (17.8%) #> ---+------------------+----------- #> 5  |                  |         97 #>    |                  |            #> ----------------------------------  # automatic range for numerics at more than 5 unique values data(mtcars) data_codebook(mtcars, select = starts_with(\"c\")) #> mtcars (32 rows and 11 variables, 2 shown) #>  #> ID | Name | Type    | Missings | Values |          N #> ---+------+---------+----------+--------+----------- #> 2  | cyl  | numeric | 0 (0.0%) |      4 | 11 (34.4%) #>    |      |         |          |      6 |  7 (21.9%) #>    |      |         |          |      8 | 14 (43.8%) #> ---+------+---------+----------+--------+----------- #> 11 | carb | numeric | 0 (0.0%) | [1, 8] |         32 #> ----------------------------------------------------  # force all values to be displayed data_codebook(mtcars, select = starts_with(\"c\"), range_at = 100) #> mtcars (32 rows and 11 variables, 2 shown) #>  #> ID | Name | Type    | Missings | Values |          N #> ---+------+---------+----------+--------+----------- #> 2  | cyl  | numeric | 0 (0.0%) |      4 | 11 (34.4%) #>    |      |         |          |      6 |  7 (21.9%) #>    |      |         |          |      8 | 14 (43.8%) #> ---+------+---------+----------+--------+----------- #> 11 | carb | numeric | 0 (0.0%) |      1 |  7 (21.9%) #>    |      |         |          |      2 | 10 (31.2%) #>    |      |         |          |      3 |  3 ( 9.4%) #>    |      |         |          |      4 | 10 (31.2%) #>    |      |         |          |      6 |  1 ( 3.1%) #>    |      |         |          |      8 |  1 ( 3.1%) #> ----------------------------------------------------"},{"path":"https://easystats.github.io/datawizard/reference/data_duplicated.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract all duplicates — data_duplicated","title":"Extract all duplicates — data_duplicated","text":"Extract duplicates, visual inspection. Note also contains first occurrence future duplicates, unlike duplicated() dplyr::distinct()). Also contains additional column reporting number missing values row, help decision-making selecting duplicates keep.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_duplicated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract all duplicates — data_duplicated","text":"","code":"data_duplicated(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE )"},{"path":"https://easystats.github.io/datawizard/reference/data_duplicated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract all duplicates — data_duplicated","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_duplicated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract all duplicates — data_duplicated","text":"dataframe, containing duplicates.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_duplicated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract all duplicates — data_duplicated","text":"","code":"df1 <- data.frame(   id = c(1, 2, 3, 1, 3),   year = c(2022, 2022, 2022, 2022, 2000),   item1 = c(NA, 1, 1, 2, 3),   item2 = c(NA, 1, 1, 2, 3),   item3 = c(NA, 1, 1, 2, 3) )  data_duplicated(df1, select = \"id\") #>   Row id year item1 item2 item3 count_na #> 1   1  1 2022    NA    NA    NA        3 #> 4   4  1 2022     2     2     2        0 #> 3   3  3 2022     1     1     1        0 #> 5   5  3 2000     3     3     3        0  data_duplicated(df1, select = c(\"id\", \"year\")) #>   Row id year item1 item2 item3 count_na #> 1   1  1 2022    NA    NA    NA        3 #> 4   4  1 2022     2     2     2        0  # Filter to exclude duplicates df2 <- df1[-c(1, 5), ] df2 #>   id year item1 item2 item3 #> 2  2 2022     1     1     1 #> 3  3 2022     1     1     1 #> 4  1 2022     2     2     2"},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract one or more columns or elements from an object — data_extract","title":"Extract one or more columns or elements from an object — data_extract","text":"data_extract() (alias extract()) similar $. extracts either single column element object (e.g., data frame, list), multiple columns resp. elements.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract one or more columns or elements from an object — data_extract","text":"","code":"data_extract(data, select, ...)  # S3 method for class 'data.frame' data_extract(   data,   select,   name = NULL,   extract = \"all\",   as_data_frame = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract one or more columns or elements from an object — data_extract","text":"data object subset. Methods currently available data frames data frame extensions (e.g., tibbles). select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". ... use future methods. name optional argument specifies column used names vector elements extraction. Must specified either literal variable name (e.g., column_name) string (\"column_name\"). name ignored data frame returned. extract String, indicating element extracted select matches multiple variables. Can \"\" (default) return matched variables, \"first\" \"last\" return first last match, \"odd\" \"even\" return odd-numbered even-numbered matches. Note \"first\" \"last\" return vector (unless as_data_frame = TRUE), \"\" can return vector (one match found) data frame (one match). Type safe return values possible extract \"first\" \"last\" (always return vector) as_data_frame = TRUE (always returns data frame). as_data_frame Logical, TRUE, always return data frame, even one variable matched. FALSE, either returns vector data frame. See extract details. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract one or more columns or elements from an object — data_extract","text":"vector (data frame) containing extracted element, NULL matching variable found.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract one or more columns or elements from an object — data_extract","text":"data_extract() can used select multiple variables pull single variable data frame. Thus, return value default type safe - data_extract() either returns vector data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"extracting-single-variables-vectors-","dir":"Reference","previous_headings":"","what":"Extracting single variables (vectors)","title":"Extract one or more columns or elements from an object — data_extract","text":"select name single column, select matches one column, vector returned. single variable also returned extract either \"first \"last\". Setting as_data_frame TRUE overrides behaviour always returns data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"extracting-a-data-frame-of-variables","dir":"Reference","previous_headings":"","what":"Extracting a data frame of variables","title":"Extract one or more columns or elements from an object — data_extract","text":"select character vector containing one column name (numeric vector one valid column indices), select uses one supported select-helpers match multiple columns, data frame returned. Setting as_data_frame TRUE always returns data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract one or more columns or elements from an object — data_extract","text":"","code":"# single variable data_extract(mtcars, cyl, name = gear) #> 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4  #> 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4  data_extract(mtcars, \"cyl\", name = gear) #> 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4  #> 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4  data_extract(mtcars, -1, name = gear) #>                     cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4             6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag         6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710            4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive        6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout     8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Valiant               6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Duster 360            8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 240D             4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Merc 230              4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 280              6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C             6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Merc 450SE            8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL            8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC           8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood    8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial     8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Fiat 128              4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic           4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla        4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Toyota Corona         4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> Dodge Challenger      8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin           8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28            8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird      8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Fiat X1-9             4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Porsche 914-2         4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Lotus Europa          4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Ford Pantera L        8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino          6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora         8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Volvo 142E            4 121.0 109 4.11 2.780 18.60  1  1    4    2 data_extract(mtcars, cyl, name = 0) #>           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive  #>                   6                   6                   4                   6  #>   Hornet Sportabout             Valiant          Duster 360           Merc 240D  #>                   8                   6                   8                   4  #>            Merc 230            Merc 280           Merc 280C          Merc 450SE  #>                   4                   6                   6                   8  #>          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental  #>                   8                   8                   8                   8  #>   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla  #>                   8                   4                   4                   4  #>       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28  #>                   4                   8                   8                   8  #>    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa  #>                   8                   4                   4                   4  #>      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E  #>                   8                   6                   8                   4  data_extract(mtcars, cyl, name = \"row.names\") #>           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive  #>                   6                   6                   4                   6  #>   Hornet Sportabout             Valiant          Duster 360           Merc 240D  #>                   8                   6                   8                   4  #>            Merc 230            Merc 280           Merc 280C          Merc 450SE  #>                   4                   6                   6                   8  #>          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental  #>                   8                   8                   8                   8  #>   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla  #>                   8                   4                   4                   4  #>       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28  #>                   4                   8                   8                   8  #>    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa  #>                   8                   4                   4                   4  #>      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E  #>                   8                   6                   8                   4   # selecting multiple variables head(data_extract(iris, starts_with(\"Sepal\"))) #>   Sepal.Length Sepal.Width #> 1          5.1         3.5 #> 2          4.9         3.0 #> 3          4.7         3.2 #> 4          4.6         3.1 #> 5          5.0         3.6 #> 6          5.4         3.9 head(data_extract(iris, ends_with(\"Width\"))) #>   Sepal.Width Petal.Width #> 1         3.5         0.2 #> 2         3.0         0.2 #> 3         3.2         0.2 #> 4         3.1         0.2 #> 5         3.6         0.2 #> 6         3.9         0.4 head(data_extract(iris, 2:4)) #>   Sepal.Width Petal.Length Petal.Width #> 1         3.5          1.4         0.2 #> 2         3.0          1.4         0.2 #> 3         3.2          1.3         0.2 #> 4         3.1          1.5         0.2 #> 5         3.6          1.4         0.2 #> 6         3.9          1.7         0.4  # select first of multiple variables data_extract(iris, starts_with(\"Sepal\"), extract = \"first\") #>   [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 #>  [19] 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 #>  [37] 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 #>  [55] 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 #>  [73] 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 #>  [91] 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 #> [109] 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 #> [127] 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 #> [145] 6.7 6.7 6.3 6.5 6.2 5.9  # select first of multiple variables, return as data frame head(data_extract(iris, starts_with(\"Sepal\"), extract = \"first\", as_data_frame = TRUE)) #>   Sepal.Length #> 1          5.1 #> 2          4.9 #> 3          4.7 #> 4          4.6 #> 5          5.0 #> 6          5.4"},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a grouped data frame — data_group","title":"Create a grouped data frame — data_group","text":"function comparable dplyr::group_by(), just following datawizard function design. data_ungroup() removes grouping information grouped data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a grouped data frame — data_group","text":"","code":"data_group(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_ungroup(data, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a grouped data frame — data_group","text":"data data frame select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... Arguments passed functions. Mostly used yet.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a grouped data frame — data_group","text":"grouped data frame, .e. data frame additional information grouping structure saved attributes.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a grouped data frame — data_group","text":"","code":"data(efc) suppressPackageStartupMessages(library(poorman, quietly = TRUE))  # total mean efc %>%   summarize(mean_hours = mean(c12hour, na.rm = TRUE)) #>   mean_hours #> 1   85.65306  # mean by educational level efc %>%   data_group(c172code) %>%   summarize(mean_hours = mean(c12hour, na.rm = TRUE)) #> # A tibble: 3 × 2 #> # Groups:   c172code [3] #>   c172code mean_hours #>      <dbl>      <dbl> #> 1        1       87.1 #> 2        2       94.0 #> 3        3       75"},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Return filtered or sliced data frame, or row indices — data_match","title":"Return filtered or sliced data frame, or row indices — data_match","text":"Return filtered (sliced) data frame row indices data frame match specific condition. data_filter() works like data_match(), works logical expressions row indices data frame specify matching conditions.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return filtered or sliced data frame, or row indices — data_match","text":"","code":"data_match(x, to, match = \"and\", return_indices = FALSE, remove_na = TRUE, ...)  data_filter(x, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return filtered or sliced data frame, or row indices — data_match","text":"x data frame. data frame matching specified conditions. Note match value \"\", original row order might changed. See 'Details'. match String, indicating logical operation matching conditions combined. Can \"\" (\"&\"), \"\" (\"|\") \"\" (\"!\"). return_indices Logical, TRUE, return vector rows can used filter original data frame. FALSE (default), returns directly filtered data frame instead row indices. remove_na Logical, TRUE, missing values (NAs) removed filtering data. default behaviour, however, sometimes row indices requested (.e. return_indices=TRUE), might useful preserve NA values, returned row indices match row indices original data frame. ... sequence logical expressions indicating rows keep, numeric vector indicating row indices rows keep. Can also string representation logical expression (e.g. \"x > 4\"), character vector (e.g. c(\"x > 4\", \"y == 2\")) variable contains string representation logical expression. might useful used packages avoid defining undefined global variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return filtered or sliced data frame, or row indices — data_match","text":"filtered data frame, row indices match specified configuration.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return filtered or sliced data frame, or row indices — data_match","text":"data_match(), match either \"\" \"\", original row order x might changed. preserving row order required, use data_filter() instead.   data_match() works data frames match conditions , data_filter() basically wrapper around subset(subset = <filter>). However, unlike subset(), preserves label attributes useful working labelled data.","code":"# mimics subset() behaviour, preserving original row order head(data_filter(mtcars[c(\"mpg\", \"vs\", \"am\")], vs == 0 | am == 1)) #>                    mpg vs am #> Mazda RX4         21.0  0  1 #> Mazda RX4 Wag     21.0  0  1 #> Datsun 710        22.8  1  1 #> Hornet Sportabout 18.7  0  0 #> Duster 360        14.3  0  0 #> Merc 450SE        16.4  0  0  # re-sorting rows head(data_match(mtcars[c(\"mpg\", \"vs\", \"am\")],                 data.frame(vs = 0, am = 1),                 match = \"or\")) #>                    mpg vs am #> Mazda RX4         21.0  0  1 #> Mazda RX4 Wag     21.0  0  1 #> Hornet Sportabout 18.7  0  0 #> Duster 360        14.3  0  0 #> Merc 450SE        16.4  0  0 #> Merc 450SL        17.3  0  0"},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return filtered or sliced data frame, or row indices — data_match","text":"","code":"data_match(mtcars, data.frame(vs = 0, am = 1)) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 data_match(mtcars, data.frame(vs = 0, am = c(0, 1))) #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  # observations where \"vs\" is NOT 0 AND \"am\" is NOT 1 data_match(mtcars, data.frame(vs = 0, am = 1), match = \"not\") #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Valiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Merc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Merc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Toyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 # equivalent to data_filter(mtcars, vs != 0 & am != 1) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Valiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Merc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Merc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Toyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  # observations where EITHER \"vs\" is 0 OR \"am\" is 1 data_match(mtcars, data.frame(vs = 0, am = 1), match = \"or\") #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 # equivalent to data_filter(mtcars, vs == 0 | am == 1) #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  # slice data frame by row indices data_filter(mtcars, 5:10) #>                    mpg cyl  disp  hp drat   wt  qsec vs am gear carb #> Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2 #> Valiant           18.1   6 225.0 105 2.76 3.46 20.22  1  0    3    1 #> Duster 360        14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4 #> Merc 240D         24.4   4 146.7  62 3.69 3.19 20.00  1  0    4    2 #> Merc 230          22.8   4 140.8  95 3.92 3.15 22.90  1  0    4    2 #> Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4  # Define a custom function containing data_filter() my_filter <- function(data, variable) {   data_filter(data, variable) } my_filter(mtcars, \"cyl == 6\") #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Valiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Merc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  # Pass complete filter-condition as string. my_filter <- function(data, condition) {   data_filter(data, condition) } my_filter(mtcars, \"am != 0\") #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Fiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Fiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Lotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Volvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  # string can also be used directly as argument data_filter(mtcars, \"am != 0\") #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Fiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Fiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Lotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Volvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  # or as variable fl <- \"am != 0\" data_filter(mtcars, fl) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Fiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Fiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Lotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Volvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2"},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge (join) two data frames, or a list of data frames — data_merge","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Merge (join) two data frames, list data frames. However, unlike base R's merge(), data_merge() offers methods join data frames, drop data frame column attributes.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"","code":"data_merge(x, ...)  data_join(x, ...)  # S3 method for class 'data.frame' data_merge(x, y, join = \"left\", by = NULL, id = NULL, verbose = TRUE, ...)  # S3 method for class 'list' data_merge(x, join = \"left\", by = NULL, id = NULL, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"x, y data frame merge. x may also list data frames merged. Note list-method y argument. ... used. join Character vector, indicating method joining data frames. Can \"full\", \"left\" (default), \"right\", \"inner\", \"anti\", \"semi\" \"bind\". See details . Specifications columns used merging. id Optional name ID column created indicate source data frames appended rows. applies join = \"bind\". verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"merged data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"merging-data-frames","dir":"Reference","previous_headings":"","what":"Merging data frames","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Merging data frames performed adding rows (cases), columns (variables) source data frame (y) target data frame (x). usually requires one variables included data frames used merging, typically indicated argument. contains variable present data frames, cases matched filtered identical values x y.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"left-and-right-joins","dir":"Reference","previous_headings":"","what":"Left- and right-joins","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Left- right joins usually add new rows (cases), new columns (variables) existing cases x. join = \"left\" join = \"right\" work, must indicate one columns included data frames. join = \"left\", identifier variable, included x y, variables y copied x, cases y matching values identifier variable x (.e. cases x also found y get related values new columns y). match identifiers x y, copied variable y get NA value particular case. variables occur x y, used identifiers (), renamed avoid multiple identical variable names. Cases y values identifier match x's identifier removed. join = \"right\" works similar way join = \"left\", just cases x matching values identifier variable y chosen. base R, equivalent merge(x, y, .x = TRUE) merge(x, y, .y = TRUE).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"full-joins","dir":"Reference","previous_headings":"","what":"Full joins","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Full joins copy cases y x. matching cases data frames, values new variables copied y x. cases y present x, added new rows x. Thus, full joins add new columns (variables), also might add new rows (cases). base R, equivalent merge(x, y, = TRUE).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"inner-joins","dir":"Reference","previous_headings":"","what":"Inner joins","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Inner joins merge two data frames, however, rows (cases) kept present data frames. Thus, inner joins usually add new columns (variables), also remove rows (cases) occur one data frame. base R, equivalent merge(x, y).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"binds","dir":"Reference","previous_headings":"","what":"Binds","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"join = \"bind\" row-binds complete second data frame y x. Unlike simple rbind(), requires columns data frames, join = \"bind\" bind shared columns y x, add new columns y x.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"","code":"x <- data.frame(a = 1:3, b = c(\"a\", \"b\", \"c\"), c = 5:7, id = 1:3) y <- data.frame(c = 6:8, d = c(\"f\", \"g\", \"h\"), e = 100:102, id = 2:4)  x #>   a b c id #> 1 1 a 5  1 #> 2 2 b 6  2 #> 3 3 c 7  3 y #>   c d   e id #> 1 6 f 100  2 #> 2 7 g 101  3 #> 3 8 h 102  4  # \"by\" will default to all shared columns, i.e. \"c\" and \"id\". new columns # \"d\" and \"e\" will be copied from \"y\" to \"x\", but there are only two cases # in \"x\" that have the same values for \"c\" and \"id\" in \"y\". only those cases # have values in the copied columns, the other case gets \"NA\". data_merge(x, y, join = \"left\") #>   a b c id    d   e #> 3 1 a 5  1 <NA>  NA #> 1 2 b 6  2    f 100 #> 2 3 c 7  3    g 101  # we change the id-value here x <- data.frame(a = 1:3, b = c(\"a\", \"b\", \"c\"), c = 5:7, id = 1:3) y <- data.frame(c = 6:8, d = c(\"f\", \"g\", \"h\"), e = 100:102, id = 3:5)  x #>   a b c id #> 1 1 a 5  1 #> 2 2 b 6  2 #> 3 3 c 7  3 y #>   c d   e id #> 1 6 f 100  3 #> 2 7 g 101  4 #> 3 8 h 102  5  # no cases in \"y\" have the same matching \"c\" and \"id\" as in \"x\", thus # copied variables from \"y\" to \"x\" copy no values, all get NA. data_merge(x, y, join = \"left\") #>   a b c id    d  e #> 1 1 a 5  1 <NA> NA #> 2 2 b 6  2 <NA> NA #> 3 3 c 7  3 <NA> NA  # one case in \"y\" has a match in \"id\" with \"x\", thus values for this # case from the remaining variables in \"y\" are copied to \"x\", all other # values (cases) in those remaining variables get NA data_merge(x, y, join = \"left\", by = \"id\") #>   a b id    d   e c.x c.y #> 2 1 a  1 <NA>  NA   5  NA #> 3 2 b  2 <NA>  NA   6  NA #> 1 3 c  3    f 100   7   6  data(mtcars) x <- mtcars[1:5, 1:3] y <- mtcars[28:32, 4:6]  # add ID common column x$id <- 1:5 y$id <- 3:7  # left-join, add new variables and copy values from y to x, # where \"id\" values match data_merge(x, y) #>    mpg cyl disp id  hp drat    wt #> 4 21.0   6  160  1  NA   NA    NA #> 5 21.0   6  160  2  NA   NA    NA #> 1 22.8   4  108  3 113 3.77 1.513 #> 2 21.4   6  258  4 264 4.22 3.170 #> 3 18.7   8  360  5 175 3.62 2.770  # right-join, add new variables and copy values from x to y, # where \"id\" values match data_merge(x, y, join = \"right\") #>    mpg cyl disp id  hp drat    wt #> 1 22.8   4  108  3 113 3.77 1.513 #> 2 21.4   6  258  4 264 4.22 3.170 #> 3 18.7   8  360  5 175 3.62 2.770 #> 4   NA  NA   NA  6 335 3.54 3.570 #> 5   NA  NA   NA  7 109 4.11 2.780  # full-join data_merge(x, y, join = \"full\") #>    mpg cyl disp id  hp drat    wt #> 4 21.0   6  160  1  NA   NA    NA #> 5 21.0   6  160  2  NA   NA    NA #> 1 22.8   4  108  3 113 3.77 1.513 #> 2 21.4   6  258  4 264 4.22 3.170 #> 3 18.7   8  360  5 175 3.62 2.770 #> 6   NA  NA   NA  6 335 3.54 3.570 #> 7   NA  NA   NA  7 109 4.11 2.780   data(mtcars) x <- mtcars[1:5, 1:3] y <- mtcars[28:32, c(1, 4:5)]  # add ID common column x$id <- 1:5 y$id <- 3:7  # left-join, no matching rows (because columns \"id\" and \"disp\" are used) # new variables get all NA values data_merge(x, y) #>    mpg cyl disp id hp drat #> 1 21.0   6  160  1 NA   NA #> 2 21.0   6  160  2 NA   NA #> 3 22.8   4  108  3 NA   NA #> 4 21.4   6  258  4 NA   NA #> 5 18.7   8  360  5 NA   NA  # one common value in \"mpg\", so one row from y is copied to x data_merge(x, y, by = \"mpg\") #>    mpg cyl disp  hp drat id.x id.y #> 2 21.0   6  160  NA   NA    1   NA #> 3 21.0   6  160  NA   NA    2   NA #> 4 22.8   4  108  NA   NA    3   NA #> 1 21.4   6  258 109 4.11    4    7 #> 5 18.7   8  360  NA   NA    5   NA  # only keep rows with matching values in by-column data_merge(x, y, join = \"semi\", by = \"mpg\") #>                 mpg cyl disp id #> Hornet 4 Drive 21.4   6  258  4  # only keep rows with non-matching values in by-column data_merge(x, y, join = \"anti\", by = \"mpg\") #>                    mpg cyl disp id #> Mazda RX4         21.0   6  160  1 #> Mazda RX4 Wag     21.0   6  160  2 #> Datsun 710        22.8   4  108  3 #> Hornet Sportabout 18.7   8  360  5  # merge list of data frames. can be of different rows x <- mtcars[1:5, 1:3] y <- mtcars[28:31, 3:5] z <- mtcars[11:18, c(1, 3:4, 6:8)] x$id <- 1:5 y$id <- 4:7 z$id <- 3:10 data_merge(list(x, y, z), join = \"bind\", by = \"id\", id = \"source\") #>     mpg cyl  disp id  hp drat    wt  qsec vs source #> 1  21.0   6 160.0  1  NA   NA    NA    NA NA      1 #> 2  21.0   6 160.0  2  NA   NA    NA    NA NA      1 #> 3  22.8   4 108.0  3  NA   NA    NA    NA NA      1 #> 4  21.4   6 258.0  4  NA   NA    NA    NA NA      1 #> 5  18.7   8 360.0  5  NA   NA    NA    NA NA      1 #> 6    NA  NA  95.1  4 113 3.77    NA    NA NA      2 #> 7    NA  NA 351.0  5 264 4.22    NA    NA NA      2 #> 8    NA  NA 145.0  6 175 3.62    NA    NA NA      2 #> 9    NA  NA 301.0  7 335 3.54    NA    NA NA      2 #> 10 17.8  NA 167.6  3 123   NA 3.440 18.90  1      3 #> 11 16.4  NA 275.8  4 180   NA 4.070 17.40  0      3 #> 12 17.3  NA 275.8  5 180   NA 3.730 17.60  0      3 #> 13 15.2  NA 275.8  6 180   NA 3.780 18.00  0      3 #> 14 10.4  NA 472.0  7 205   NA 5.250 17.98  0      3 #> 15 10.4  NA 460.0  8 215   NA 5.424 17.82  0      3 #> 16 14.7  NA 440.0  9 230   NA 5.345 17.42  0      3 #> 17 32.4  NA  78.7 10  66   NA 2.200 19.47  1      3"},{"path":"https://easystats.github.io/datawizard/reference/data_modify.html","id":null,"dir":"Reference","previous_headings":"","what":"Create new variables in a data frame — data_modify","title":"Create new variables in a data frame — data_modify","text":"Create new variables modify existing variables data frame. Unlike base::transform(), data_modify() can used grouped data frames, newly created variables can directly used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_modify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create new variables in a data frame — data_modify","text":"","code":"data_modify(data, ...)  # S3 method for class 'data.frame' data_modify(data, ..., .if = NULL, .at = NULL, .modify = NULL)"},{"path":"https://easystats.github.io/datawizard/reference/data_modify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create new variables in a data frame — data_modify","text":"data data frame ... One expressions define new variable name values recoding new variables. expressions can one : sequence named, literal expressions, left-hand side refers name new variable, right-hand side represent values new variable. Example: Sepal.Width = center(Sepal.Width). vector length 1 (recycled match number rows data), length data. variable contains value used. Example:   expression can also provided string wrapped as_expr(). Example:   Note as_expr() real function, used outside data_modify(), hence exported documented. Rather, used internally processing expressions. Using NULL right-hand side removes variable data frame. Example: Petal.Width = NULL. data frames (including grouped ones), function n() can used count number observations thereby, instance, create index values using id = 1:n() id = 3:(n()+2) similar. Note , like as_expr(), n() also true function used outside data_modify(). Note newly created variables can used subsequent expressions, including ... See also 'Examples'. .function returns TRUE columns data frame .applies. argument used combination .modify argument. Note one ..can provided, time. Newly created variables ... can also selected, see 'Examples'. .character vector variable names modified. argument used combination .modify argument. Note one ..can provided, time. Newly created variables ... can also selected, see 'Examples'. .modify function modifies variables defined ... argument used combination either ..argument. Note modified variable (.e. result .modify) must either length 1 length input variable.","code":"a <- \"abc\" data_modify(iris, var_abc = a) # var_abc contains \"abc\" data_modify(iris, as_expr(\"Sepal.Width = center(Sepal.Width)\")) # or a <- \"center(Sepal.Width)\" data_modify(iris, Sepal.Width = as_expr(a)) # or a <- \"Sepal.Width = center(Sepal.Width)\" data_modify(iris, as_expr(a))"},{"path":"https://easystats.github.io/datawizard/reference/data_modify.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create new variables in a data frame — data_modify","text":"data_modify() can also used inside functions. However, recommended pass recode-expression character vector list characters.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_modify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create new variables in a data frame — data_modify","text":"","code":"data(efc) new_efc <- data_modify(   efc,   c12hour_c = center(c12hour),   c12hour_z = c12hour_c / sd(c12hour, na.rm = TRUE),   c12hour_z2 = standardize(c12hour) ) head(new_efc) #>   c12hour e16sex e42dep c172code neg_c_7 c12hour_c  c12hour_z c12hour_z2 #> 1      16      2      3        2      12 -69.65306 -1.0466657 -1.0466657 #> 2     148      2      3        2      20  62.34694  0.9368777  0.9368777 #> 3      70      2      3        1      11 -15.65306 -0.2352161 -0.2352161 #> 4      NA      2   <NA>        2      10        NA         NA         NA #> 5     168      2      4        2      12  82.34694  1.2374146  1.2374146 #> 6      16      2      4        2      19 -69.65306 -1.0466657 -1.0466657  # using strings instead of literal expressions new_efc <- data_modify(   efc,   as_expr(\"c12hour_c = center(c12hour)\"),   as_expr(\"c12hour_z = c12hour_c / sd(c12hour, na.rm = TRUE)\"),   as_expr(\"c12hour_z2 = standardize(c12hour)\") ) head(new_efc) #>   c12hour e16sex e42dep c172code neg_c_7 c12hour_c  c12hour_z c12hour_z2 #> 1      16      2      3        2      12 -69.65306 -1.0466657 -1.0466657 #> 2     148      2      3        2      20  62.34694  0.9368777  0.9368777 #> 3      70      2      3        1      11 -15.65306 -0.2352161 -0.2352161 #> 4      NA      2   <NA>        2      10        NA         NA         NA #> 5     168      2      4        2      12  82.34694  1.2374146  1.2374146 #> 6      16      2      4        2      19 -69.65306 -1.0466657 -1.0466657  # using a character vector, provided a variable xpr <- c(   \"c12hour_c = center(c12hour)\",   \"c12hour_z = c12hour_c / sd(c12hour, na.rm = TRUE)\",   \"c12hour_z2 = standardize(c12hour)\" ) new_efc <- data_modify(efc, as_expr(xpr)) head(new_efc) #>   c12hour e16sex e42dep c172code neg_c_7 c12hour_c  c12hour_z c12hour_z2 #> 1      16      2      3        2      12 -69.65306 -1.0466657 -1.0466657 #> 2     148      2      3        2      20  62.34694  0.9368777  0.9368777 #> 3      70      2      3        1      11 -15.65306 -0.2352161 -0.2352161 #> 4      NA      2   <NA>        2      10        NA         NA         NA #> 5     168      2      4        2      12  82.34694  1.2374146  1.2374146 #> 6      16      2      4        2      19 -69.65306 -1.0466657 -1.0466657  # using character strings, provided as variable stand <- \"c12hour_c / sd(c12hour, na.rm = TRUE)\" new_efc <- data_modify(   efc,   c12hour_c = center(c12hour),   c12hour_z = as_expr(stand) ) head(new_efc) #>   c12hour e16sex e42dep c172code neg_c_7 c12hour_c  c12hour_z #> 1      16      2      3        2      12 -69.65306 -1.0466657 #> 2     148      2      3        2      20  62.34694  0.9368777 #> 3      70      2      3        1      11 -15.65306 -0.2352161 #> 4      NA      2   <NA>        2      10        NA         NA #> 5     168      2      4        2      12  82.34694  1.2374146 #> 6      16      2      4        2      19 -69.65306 -1.0466657  # attributes - in this case, value and variable labels - are preserved str(new_efc) #> 'data.frame':\t100 obs. of  7 variables: #>  $ c12hour  : num  16 148 70 NA 168 16 161 110 28 40 ... #>   ..- attr(*, \"label\")= chr \"average number of hours of care per week\" #>  $ e16sex   : num  2 2 2 2 2 2 1 2 2 2 ... #>   ..- attr(*, \"label\")= chr \"elder's gender\" #>   ..- attr(*, \"labels\")= Named num [1:2] 1 2 #>   .. ..- attr(*, \"names\")= chr [1:2] \"male\" \"female\" #>  $ e42dep   : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 3 3 3 NA 4 4 4 4 4 4 ... #>   ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4 #>   .. ..- attr(*, \"names\")= chr [1:4] \"independent\" \"slightly dependent\" \"moderately dependent\" \"severely dependent\" #>   ..- attr(*, \"label\")= chr \"elder's dependency\" #>  $ c172code : num  2 2 1 2 2 2 2 2 NA 2 ... #>   ..- attr(*, \"label\")= chr \"carer's level of education\" #>   ..- attr(*, \"labels\")= Named num [1:3] 1 2 3 #>   .. ..- attr(*, \"names\")= chr [1:3] \"low level of education\" \"intermediate level of education\" \"high level of education\" #>  $ neg_c_7  : num  12 20 11 10 12 19 15 11 15 10 ... #>   ..- attr(*, \"label\")= chr \"Negative impact with 7 items\" #>  $ c12hour_c: 'dw_transformer' num  -69.7 62.3 -15.7 NA 82.3 ... #>   ..- attr(*, \"center\")= num 85.7 #>   ..- attr(*, \"scale\")= num 1 #>   ..- attr(*, \"robust\")= logi FALSE #>   ..- attr(*, \"label\")= chr \"average number of hours of care per week\" #>  $ c12hour_z: 'dw_transformer' num  -1.047 0.937 -0.235 NA 1.237 ... #>   ..- attr(*, \"center\")= num 85.7 #>   ..- attr(*, \"scale\")= num 1 #>   ..- attr(*, \"robust\")= logi FALSE #>   ..- attr(*, \"label\")= chr \"average number of hours of care per week\"  # using `paste()` to build a string-expression to_standardize <- c(\"Petal.Length\", \"Sepal.Length\") out <- data_modify(   iris,   as_expr(     paste0(to_standardize, \"_stand = standardize(\", to_standardize, \")\")   ) ) head(out) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Petal.Length_stand #> 1          5.1         3.5          1.4         0.2  setosa          -1.335752 #> 2          4.9         3.0          1.4         0.2  setosa          -1.335752 #> 3          4.7         3.2          1.3         0.2  setosa          -1.392399 #> 4          4.6         3.1          1.5         0.2  setosa          -1.279104 #> 5          5.0         3.6          1.4         0.2  setosa          -1.335752 #> 6          5.4         3.9          1.7         0.4  setosa          -1.165809 #>   Sepal.Length_stand #> 1         -0.8976739 #> 2         -1.1392005 #> 3         -1.3807271 #> 4         -1.5014904 #> 5         -1.0184372 #> 6         -0.5353840  # overwrite existing variable, remove old variable out <- data_modify(iris, Petal.Length = 1 / Sepal.Length, Sepal.Length = NULL) head(out) #>   Sepal.Width Petal.Length Petal.Width Species #> 1         3.5    0.1960784         0.2  setosa #> 2         3.0    0.2040816         0.2  setosa #> 3         3.2    0.2127660         0.2  setosa #> 4         3.1    0.2173913         0.2  setosa #> 5         3.6    0.2000000         0.2  setosa #> 6         3.9    0.1851852         0.4  setosa  # works on grouped data grouped_efc <- data_group(efc, \"c172code\") new_efc <- data_modify(   grouped_efc,   c12hour_c = center(c12hour),   c12hour_z = c12hour_c / sd(c12hour, na.rm = TRUE),   c12hour_z2 = standardize(c12hour),   id = 1:n() ) head(new_efc) #> # A tibble: 6 × 9 #> # Groups:   c172code [2] #>   c12hour e16sex e42dep c172code neg_c_7 c12hour_c c12hour_z c12hour_z2    id #>     <dbl>  <dbl> <fct>     <dbl>   <dbl>     <dbl>     <dbl>      <dbl> <int> #> 1      16      2 3             2      12     -78.0    -1.16      -1.16      1 #> 2     148      2 3             2      20      54.0     0.804      0.804     2 #> 3      70      2 3             1      11     -17.1    -0.250     -0.250     1 #> 4      NA      2 NA            2      10      NA      NA         NA         3 #> 5     168      2 4             2      12      74.0     1.10       1.10      4 #> 6      16      2 4             2      19     -78.0    -1.16      -1.16      5  # works from inside functions foo1 <- function(data, ...) {   head(data_modify(data, ...)) } foo1(iris, SW_fraction = Sepal.Width / 10) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species SW_fraction #> 1          5.1         3.5          1.4         0.2  setosa        0.35 #> 2          4.9         3.0          1.4         0.2  setosa        0.30 #> 3          4.7         3.2          1.3         0.2  setosa        0.32 #> 4          4.6         3.1          1.5         0.2  setosa        0.31 #> 5          5.0         3.6          1.4         0.2  setosa        0.36 #> 6          5.4         3.9          1.7         0.4  setosa        0.39 # or foo1(iris, as_expr(\"SW_fraction = Sepal.Width / 10\")) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species SW_fraction #> 1          5.1         3.5          1.4         0.2  setosa        0.35 #> 2          4.9         3.0          1.4         0.2  setosa        0.30 #> 3          4.7         3.2          1.3         0.2  setosa        0.32 #> 4          4.6         3.1          1.5         0.2  setosa        0.31 #> 5          5.0         3.6          1.4         0.2  setosa        0.36 #> 6          5.4         3.9          1.7         0.4  setosa        0.39  # also with string arguments, using `as_expr()` foo2 <- function(data, modification) {   head(data_modify(data, as_expr(modification))) } foo2(iris, \"SW_fraction = Sepal.Width / 10\") #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species SW_fraction #> 1          5.1         3.5          1.4         0.2  setosa        0.35 #> 2          4.9         3.0          1.4         0.2  setosa        0.30 #> 3          4.7         3.2          1.3         0.2  setosa        0.32 #> 4          4.6         3.1          1.5         0.2  setosa        0.31 #> 5          5.0         3.6          1.4         0.2  setosa        0.36 #> 6          5.4         3.9          1.7         0.4  setosa        0.39  # modify at specific positions or if condition is met d <- iris[1:5, ] data_modify(d, .at = \"Species\", .modify = as.numeric) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          5.1         3.5          1.4         0.2       1 #> 2          4.9         3.0          1.4         0.2       1 #> 3          4.7         3.2          1.3         0.2       1 #> 4          4.6         3.1          1.5         0.2       1 #> 5          5.0         3.6          1.4         0.2       1 data_modify(d, .if = is.factor, .modify = as.numeric) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          5.1         3.5          1.4         0.2       1 #> 2          4.9         3.0          1.4         0.2       1 #> 3          4.7         3.2          1.3         0.2       1 #> 4          4.6         3.1          1.5         0.2       1 #> 5          5.0         3.6          1.4         0.2       1  # can be combined with dots data_modify(d, new_length = Petal.Length * 2, .at = \"Species\", .modify = as.numeric) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species new_length #> 1          5.1         3.5          1.4         0.2       1        2.8 #> 2          4.9         3.0          1.4         0.2       1        2.8 #> 3          4.7         3.2          1.3         0.2       1        2.6 #> 4          4.6         3.1          1.5         0.2       1        3.0 #> 5          5.0         3.6          1.4         0.2       1        2.8  # new variables used in `.at` or `.if` data_modify(   d,   new_length = Petal.Length * 2,   .at = c(\"Petal.Length\", \"new_length\"),   .modify = round ) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species new_length #> 1          5.1         3.5            1         0.2  setosa          3 #> 2          4.9         3.0            1         0.2  setosa          3 #> 3          4.7         3.2            1         0.2  setosa          3 #> 4          4.6         3.1            2         0.2  setosa          3 #> 5          5.0         3.6            1         0.2  setosa          3  # combine \"extract_column_names()\" and \".at\" argument out <- data_modify(   d,   .at = extract_column_names(d, select = starts_with(\"Sepal\")),   .modify = as.factor ) # \"Sepal.Length\" and \"Sepal.Width\" are now factors str(out) #> 'data.frame':\t5 obs. of  5 variables: #>  $ Sepal.Length: Factor w/ 5 levels \"4.6\",\"4.7\",\"4.9\",..: 5 3 2 1 4 #>  $ Sepal.Width : Factor w/ 5 levels \"3\",\"3.1\",\"3.2\",..: 4 1 3 2 5 #>  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 #>  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 #>  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1"},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition data — data_partition","title":"Partition data — data_partition","text":"Creates data partitions (instance, training test set) based data frame can also stratified (.e., evenly spread given factor) using argument.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition data — data_partition","text":"","code":"data_partition(   data,   proportion = 0.7,   by = NULL,   seed = NULL,   row_id = \".row_id\",   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partition data — data_partition","text":"data data frame. proportion Scalar (0 1) numeric vector, indicating proportion(s) training set(s). sum proportion must greater 1. remaining part used test set. character vector indicating name(s) column(s) used stratified partitioning. seed random number generator seed. Enter integer (e.g. 123) random sampling time run function. row_id Character string, indicating name column contains row-id's. verbose Toggle messages warnings. ... arguments passed functions.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partition data — data_partition","text":"list data frames. list includes one training set per given proportion remaining data test set. List elements training sets named given proportions (e.g., $p_0.7), test set named $test.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partition data — data_partition","text":"","code":"data(iris) out <- data_partition(iris, proportion = 0.9) out$test #>    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species .row_id #> 1           4.7         3.2          1.3         0.2     setosa       3 #> 2           4.6         3.1          1.5         0.2     setosa       4 #> 3           4.8         3.4          1.6         0.2     setosa      12 #> 4           5.8         4.0          1.2         0.2     setosa      15 #> 5           5.2         3.4          1.4         0.2     setosa      29 #> 6           5.5         4.2          1.4         0.2     setosa      34 #> 7           5.1         3.8          1.6         0.2     setosa      47 #> 8           4.9         2.4          3.3         1.0 versicolor      58 #> 9           6.7         3.0          5.0         1.7 versicolor      78 #> 10          5.5         2.4          3.7         1.0 versicolor      82 #> 11          7.1         3.0          5.9         2.1  virginica     103 #> 12          6.7         3.3          5.7         2.1  virginica     125 #> 13          6.1         3.0          4.9         1.8  virginica     128 #> 14          7.2         3.0          5.8         1.6  virginica     130 #> 15          6.0         3.0          4.8         1.8  virginica     139 nrow(out$p_0.9) #> [1] 135  # Stratify by group (equal proportions of each species) out <- data_partition(iris, proportion = 0.9, by = \"Species\") out$test #>    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species .row_id #> 1           5.4         3.7          1.5         0.2     setosa      11 #> 2           5.7         4.4          1.5         0.4     setosa      16 #> 3           5.2         4.1          1.5         0.1     setosa      33 #> 4           5.5         3.5          1.3         0.2     setosa      37 #> 5           5.1         3.4          1.5         0.2     setosa      40 #> 6           4.9         2.4          3.3         1.0 versicolor      58 #> 7           5.2         2.7          3.9         1.4 versicolor      60 #> 8           6.7         3.0          5.0         1.7 versicolor      78 #> 9           6.0         3.4          4.5         1.6 versicolor      86 #> 10          6.2         2.9          4.3         1.3 versicolor      98 #> 11          6.9         3.2          5.7         2.3  virginica     121 #> 12          7.7         2.8          6.7         2.0  virginica     123 #> 13          6.3         2.7          4.9         1.8  virginica     124 #> 14          6.1         3.0          4.9         1.8  virginica     128 #> 15          6.0         3.0          4.8         1.8  virginica     139  # Create multiple partitions out <- data_partition(iris, proportion = c(0.3, 0.3)) lapply(out, head) #> $p_0.3 #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .row_id #> 1          4.7         3.2          1.3         0.2  setosa       3 #> 2          5.0         3.6          1.4         0.2  setosa       5 #> 3          5.4         3.9          1.7         0.4  setosa       6 #> 4          5.0         3.4          1.5         0.2  setosa       8 #> 5          4.9         3.1          1.5         0.1  setosa      10 #> 6          5.4         3.7          1.5         0.2  setosa      11 #>  #> $p_0.3 #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .row_id #> 1          4.6         3.4          1.4         0.3  setosa       7 #> 2          4.8         3.0          1.4         0.1  setosa      13 #> 3          5.7         4.4          1.5         0.4  setosa      16 #> 4          5.4         3.9          1.3         0.4  setosa      17 #> 5          5.1         3.5          1.4         0.3  setosa      18 #> 6          4.6         3.6          1.0         0.2  setosa      23 #>  #> $test #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .row_id #> 1          5.1         3.5          1.4         0.2  setosa       1 #> 2          4.9         3.0          1.4         0.2  setosa       2 #> 3          4.6         3.1          1.5         0.2  setosa       4 #> 4          4.4         2.9          1.4         0.2  setosa       9 #> 5          4.3         3.0          1.1         0.1  setosa      14 #> 6          5.8         4.0          1.2         0.2  setosa      15 #>   # Create multiple partitions, stratified by group - 30% equally sampled # from species in first training set, 50% in second training set and # remaining 20% equally sampled from each species in test set. out <- data_partition(iris, proportion = c(0.3, 0.5), by = \"Species\") lapply(out, function(i) table(i$Species)) #> $p_0.3 #>  #>     setosa versicolor  virginica  #>         15         15         15  #>  #> $p_0.5 #>  #>     setosa versicolor  virginica  #>         25         25         25  #>  #> $test #>  #>     setosa versicolor  virginica  #>         10         10         10  #>"},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":null,"dir":"Reference","previous_headings":"","what":"Peek at values and type of variables in a data frame — data_peek","title":"Peek at values and type of variables in a data frame — data_peek","text":"function creates table data frame, showing column names, variable types first values (many fit screen).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Peek at values and type of variables in a data frame — data_peek","text":"","code":"data_peek(x, ...)  # S3 method for class 'data.frame' data_peek(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   width = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Peek at values and type of variables in a data frame — data_peek","text":"x data frame. ... used. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. width Maximum width line length display. NULL, width determined using options()$width. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Peek at values and type of variables in a data frame — data_peek","text":"data frame three columns, containing information name, type first values input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Peek at values and type of variables in a data frame — data_peek","text":"show specific limited number variables, use select argument, e.g. select = 1:5 show first five variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Peek at values and type of variables in a data frame — data_peek","text":"","code":"data(efc) data_peek(efc) #> Data frame with 100 rows and 5 variables #>  #> Variable | Type    | Values                                            #> ---------------------------------------------------------------------- #> c12hour  | numeric | 16, 148, 70, NA, 168, 16, 161, 110, 28, 40, ...   #> e16sex   | numeric | 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, ...  #> e42dep   | factor  | 3, 3, 3, NA, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, ... #> c172code | numeric | 2, 2, 1, 2, 2, 2, 2, 2, NA, 2, 2, 2, 3, 1, 3, ... #> neg_c_7  | numeric | 12, 20, 11, 10, 12, 19, 15, 11, 15, 10, 28, ...   # show variables two to four data_peek(efc, select = 2:4) #> Data frame with 100 rows and 5 variables #>  #> Variable | Type    | Values                                            #> ---------------------------------------------------------------------- #> e16sex   | numeric | 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, ...  #> e42dep   | factor  | 3, 3, 3, NA, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, ... #> c172code | numeric | 2, 2, 1, 2, 2, 2, 2, 2, NA, 2, 2, 2, 3, 1, 3, ..."},{"path":"https://easystats.github.io/datawizard/reference/data_prefix_suffix.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a prefix or suffix to column names — data_addprefix","title":"Add a prefix or suffix to column names — data_addprefix","text":"Add prefix suffix column names","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_prefix_suffix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a prefix or suffix to column names — data_addprefix","text":"","code":"data_addprefix(   data,   pattern,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_addsuffix(   data,   pattern,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_prefix_suffix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a prefix or suffix to column names — data_addprefix","text":"data data frame. pattern character string, added prefix suffix column names. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... arguments passed functions.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_prefix_suffix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a prefix or suffix to column names — data_addprefix","text":"","code":"# Add prefix / suffix to all columns head(data_addprefix(iris, \"NEW_\")) #>   NEW_Sepal.Length NEW_Sepal.Width NEW_Petal.Length NEW_Petal.Width NEW_Species #> 1              5.1             3.5              1.4             0.2      setosa #> 2              4.9             3.0              1.4             0.2      setosa #> 3              4.7             3.2              1.3             0.2      setosa #> 4              4.6             3.1              1.5             0.2      setosa #> 5              5.0             3.6              1.4             0.2      setosa #> 6              5.4             3.9              1.7             0.4      setosa head(data_addsuffix(iris, \"_OLD\")) #>   Sepal.Length_OLD Sepal.Width_OLD Petal.Length_OLD Petal.Width_OLD Species_OLD #> 1              5.1             3.5              1.4             0.2      setosa #> 2              4.9             3.0              1.4             0.2      setosa #> 3              4.7             3.2              1.3             0.2      setosa #> 4              4.6             3.1              1.5             0.2      setosa #> 5              5.0             3.6              1.4             0.2      setosa #> 6              5.4             3.9              1.7             0.4      setosa"},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":null,"dir":"Reference","previous_headings":"","what":"Read (import) data files from various sources — data_read","title":"Read (import) data files from various sources — data_read","text":"functions imports data various file types. small wrapper around haven::read_spss(), haven::read_stata(), haven::read_sas(), readxl::read_excel() data.table::fread() resp. readr::read_delim() (latter package data.table installed). Thus, supported file types importing data data files SPSS, SAS Stata, Excel files text files (like '.csv' files). file types passed rio::import(). data_write() works similar way.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read (import) data files from various sources — data_read","text":"","code":"data_read(   path,   path_catalog = NULL,   encoding = NULL,   convert_factors = TRUE,   verbose = TRUE,   ... )  data_write(   data,   path,   delimiter = \",\",   convert_factors = FALSE,   save_labels = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read (import) data files from various sources — data_read","text":"path Character string, file path data file. path_catalog Character string, path catalog file. relevant SAS data files. encoding character encoding used file. Usually needed. convert_factors TRUE (default), numeric variables, values value label, assumed categorical converted factors. FALSE, variable types guessed conversion numeric variables factors performed. data_read(), argument applies file types labelled data, e.g. files SPSS, SAS Stata. See also section 'Differences packages'. data_write(), argument applies text (e.g. .txt .csv) spreadsheet file formats (like .xlsx). Converting factors might useful formats labelled numeric variables converted factors exported character columns - else, value labels lost numeric values written file. verbose Toggle warnings messages. ... Arguments passed related read_*() write_*() functions. data data frame written file. delimiter CSV-files, specifies delimiter. Defaults \",\", particular European regions, \";\" might useful alternative, especially exported CSV-files opened Excel. save_labels applies CSV files. TRUE, value variable labels () saved additional CSV file. file file name exported CSV file, includes \"_labels\" suffix (.e. file name \"mydat.csv\", additional file value variable labels named \"mydat_labels.csv\").","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read (import) data files from various sources — data_read","text":"data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"supported-file-types","dir":"Reference","previous_headings":"","what":"Supported file types","title":"Read (import) data files from various sources — data_read","text":"data_read() wrapper around haven, data.table, readr readxl, nanoparquet rio packages. Currently supported file types .txt, .csv, .xls, .xlsx, .sav, .por, .dta, .sas, .rda, .parquet, .rdata, .rds (related files). file types passed rio::import(). data_write() wrapper around haven, readr, nanoparquet, rio packages, supports writing files formats supported packages.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"compressed-files-zip-and-urls","dir":"Reference","previous_headings":"","what":"Compressed files (zip) and URLs","title":"Read (import) data files from various sources — data_read","text":"data_read() can also read mentioned files URLs inside zip-compressed files. Thus, path can also URL file like \"http://www.url.com/file.csv\". path points zip-compressed file, multiple files inside zip-archive, first supported file extracted loaded.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"general-behaviour","dir":"Reference","previous_headings":"","what":"General behaviour","title":"Read (import) data files from various sources — data_read","text":"data_read() detects appropriate read_*() function based file-extension data file. Thus, cases enough specify path argument. However, control needed, arguments ... passed related read_*() function. applies data_write(), .e. based file extension provided path, appropriate write_*() function used automatically.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"spss-specific-behaviour","dir":"Reference","previous_headings":"","what":"SPSS specific behaviour","title":"Read (import) data files from various sources — data_read","text":"data_read() import user-defined (\"tagged\") NA values SPSS, .e. argument user_na always set FALSE importing SPSS data haven package. Use convert_to_na() define missing values imported data, necessary. Furthermore, data_write() compresses SPSS files default. causes problems (older) SPSS versions, use compress = \"none\", example data_write(data, \"myfile.sav\", compress = \"none\").","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"differences-to-other-packages-that-read-foreign-data-formats","dir":"Reference","previous_headings":"","what":"Differences to other packages that read foreign data formats","title":"Read (import) data files from various sources — data_read","text":"data_read() comparable rio::import(). data files SPSS, SAS Stata, support labelled data, variables converted appropriate type. major difference rio::import() data files SPSS, SAS, Stata, .e. file types support labelled data. data_read() automatically converts fully labelled numeric variables factors, imported value labels set factor levels. numeric variable value labels less value labels values, converted factor. case, value labels preserved \"labels\" attribute. Character vectors preserved. Use convert_factors = FALSE remove automatic conversion numeric variables factors.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":null,"dir":"Reference","previous_headings":"","what":"Relocate (reorder) columns of a data frame — data_relocate","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"data_relocate() reorder columns specific positions, indicated . data_reorder() instead move selected columns beginning data frame. Finally, data_remove() removes columns data frame. functions support select-helpers allow flexible specification search pattern find matching columns, reordered removed.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"","code":"data_relocate(   data,   select,   before = NULL,   after = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_reorder(   data,   select,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_remove(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". , Destination columns. Supplying neither move columns left-hand side; specifying error. Can character vector, indicating name destination column, numeric value, indicating index number destination column. -1, added last column. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... Arguments passed functions. Mostly used yet. exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"data frame reordered columns.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"","code":"# Reorder columns head(data_relocate(iris, select = \"Species\", before = \"Sepal.Length\")) #>   Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1  setosa          5.1         3.5          1.4         0.2 #> 2  setosa          4.9         3.0          1.4         0.2 #> 3  setosa          4.7         3.2          1.3         0.2 #> 4  setosa          4.6         3.1          1.5         0.2 #> 5  setosa          5.0         3.6          1.4         0.2 #> 6  setosa          5.4         3.9          1.7         0.4 head(data_relocate(iris, select = \"Species\", before = \"Sepal.Width\")) #>   Sepal.Length Species Sepal.Width Petal.Length Petal.Width #> 1          5.1  setosa         3.5          1.4         0.2 #> 2          4.9  setosa         3.0          1.4         0.2 #> 3          4.7  setosa         3.2          1.3         0.2 #> 4          4.6  setosa         3.1          1.5         0.2 #> 5          5.0  setosa         3.6          1.4         0.2 #> 6          5.4  setosa         3.9          1.7         0.4 head(data_relocate(iris, select = \"Sepal.Width\", after = \"Species\")) #>   Sepal.Length Petal.Length Petal.Width Species Sepal.Width #> 1          5.1          1.4         0.2  setosa         3.5 #> 2          4.9          1.4         0.2  setosa         3.0 #> 3          4.7          1.3         0.2  setosa         3.2 #> 4          4.6          1.5         0.2  setosa         3.1 #> 5          5.0          1.4         0.2  setosa         3.6 #> 6          5.4          1.7         0.4  setosa         3.9 # which is same as head(data_relocate(iris, select = \"Sepal.Width\", after = -1)) #>   Sepal.Length Petal.Length Petal.Width Species Sepal.Width #> 1          5.1          1.4         0.2  setosa         3.5 #> 2          4.9          1.4         0.2  setosa         3.0 #> 3          4.7          1.3         0.2  setosa         3.2 #> 4          4.6          1.5         0.2  setosa         3.1 #> 5          5.0          1.4         0.2  setosa         3.6 #> 6          5.4          1.7         0.4  setosa         3.9  # Reorder multiple columns head(data_relocate(iris, select = c(\"Species\", \"Petal.Length\"), after = \"Sepal.Width\")) #>   Sepal.Length Sepal.Width Species Petal.Length Petal.Width #> 1          5.1         3.5  setosa          1.4         0.2 #> 2          4.9         3.0  setosa          1.4         0.2 #> 3          4.7         3.2  setosa          1.3         0.2 #> 4          4.6         3.1  setosa          1.5         0.2 #> 5          5.0         3.6  setosa          1.4         0.2 #> 6          5.4         3.9  setosa          1.7         0.4 # which is same as head(data_relocate(iris, select = c(\"Species\", \"Petal.Length\"), after = 2)) #>   Sepal.Length Sepal.Width Species Petal.Length Petal.Width #> 1          5.1         3.5  setosa          1.4         0.2 #> 2          4.9         3.0  setosa          1.4         0.2 #> 3          4.7         3.2  setosa          1.3         0.2 #> 4          4.6         3.1  setosa          1.5         0.2 #> 5          5.0         3.6  setosa          1.4         0.2 #> 6          5.4         3.9  setosa          1.7         0.4  # Reorder columns head(data_reorder(iris, c(\"Species\", \"Sepal.Length\"))) #>   Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1  setosa          5.1         3.5          1.4         0.2 #> 2  setosa          4.9         3.0          1.4         0.2 #> 3  setosa          4.7         3.2          1.3         0.2 #> 4  setosa          4.6         3.1          1.5         0.2 #> 5  setosa          5.0         3.6          1.4         0.2 #> 6  setosa          5.4         3.9          1.7         0.4  # Remove columns head(data_remove(iris, \"Sepal.Length\")) #>   Sepal.Width Petal.Length Petal.Width Species #> 1         3.5          1.4         0.2  setosa #> 2         3.0          1.4         0.2  setosa #> 3         3.2          1.3         0.2  setosa #> 4         3.1          1.5         0.2  setosa #> 5         3.6          1.4         0.2  setosa #> 6         3.9          1.7         0.4  setosa head(data_remove(iris, starts_with(\"Sepal\"))) #>   Petal.Length Petal.Width Species #> 1          1.4         0.2  setosa #> 2          1.4         0.2  setosa #> 3          1.3         0.2  setosa #> 4          1.5         0.2  setosa #> 5          1.4         0.2  setosa #> 6          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename columns and variable names — data_rename","title":"Rename columns and variable names — data_rename","text":"Safe intuitive functions rename variables rows data frames. data_rename() rename column names, .e. facilitates renaming variables. data_rename_rows() convenient shortcut add rename row names data frame, unlike row.names(), input output data frame, thus, integrating smoothly possible pipe-workflow.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename columns and variable names — data_rename","text":"","code":"data_rename(data, select = NULL, replacement = NULL, ...)  data_rename_rows(data, rows = NULL)"},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename columns and variable names — data_rename","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". replacement Character vector. Can one following: character vector indicates new names columns selected select. select replacement must length. string (.e. character vector length 1) \"glue\" styled pattern. Currently supported tokens : {col} replaced column name, .e. corresponding value select. {n} replaced number variable replaced. {letter} replaced alphabetical letters sequential order. 26 letters required, letters repeated, sequential numeric indices (e.g., a1 z1, followed a2 z2). Finally, name user-defined object available environment can used. Note object's name allowed one pre-defined tokens, \"col\", \"n\" \"letter\". example use tokens ...   ... return new column names new_name_from_am new_name_from_vs. See 'Examples'. select named vector, replacement ignored. ... arguments passed functions. rows Vector row names.","code":"data_rename(   mtcars,   select = c(\"am\", \"vs\"),   replacement = \"new_name_from_{col}\" )"},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename columns and variable names — data_rename","text":"modified data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rename columns and variable names — data_rename","text":"select can also named character vector. case, names used rename columns output data frame. named list, use unlist() convert named vector. See 'Examples'.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rename columns and variable names — data_rename","text":"","code":"# Rename columns head(data_rename(iris, \"Sepal.Length\", \"length\")) #>   length Sepal.Width Petal.Length Petal.Width Species #> 1    5.1         3.5          1.4         0.2  setosa #> 2    4.9         3.0          1.4         0.2  setosa #> 3    4.7         3.2          1.3         0.2  setosa #> 4    4.6         3.1          1.5         0.2  setosa #> 5    5.0         3.6          1.4         0.2  setosa #> 6    5.4         3.9          1.7         0.4  setosa  # Use named vector to rename head(data_rename(iris, c(length = \"Sepal.Length\", width = \"Sepal.Width\"))) #>   length width Petal.Length Petal.Width Species #> 1    5.1   3.5          1.4         0.2  setosa #> 2    4.9   3.0          1.4         0.2  setosa #> 3    4.7   3.2          1.3         0.2  setosa #> 4    4.6   3.1          1.5         0.2  setosa #> 5    5.0   3.6          1.4         0.2  setosa #> 6    5.4   3.9          1.7         0.4  setosa  # Change all head(data_rename(iris, replacement = paste0(\"Var\", 1:5))) #>   Var1 Var2 Var3 Var4   Var5 #> 1  5.1  3.5  1.4  0.2 setosa #> 2  4.9  3.0  1.4  0.2 setosa #> 3  4.7  3.2  1.3  0.2 setosa #> 4  4.6  3.1  1.5  0.2 setosa #> 5  5.0  3.6  1.4  0.2 setosa #> 6  5.4  3.9  1.7  0.4 setosa  # Use glue-styled patterns head(data_rename(mtcars[1:3], c(\"mpg\", \"cyl\", \"disp\"), \"formerly_{col}\")) #>                   formerly_mpg formerly_cyl formerly_disp #> Mazda RX4                 21.0            6           160 #> Mazda RX4 Wag             21.0            6           160 #> Datsun 710                22.8            4           108 #> Hornet 4 Drive            21.4            6           258 #> Hornet Sportabout         18.7            8           360 #> Valiant                   18.1            6           225 head(data_rename(mtcars[1:3], c(\"mpg\", \"cyl\", \"disp\"), \"{col}_is_column_{n}\")) #>                   mpg_is_column_1 cyl_is_column_2 disp_is_column_3 #> Mazda RX4                    21.0               6              160 #> Mazda RX4 Wag                21.0               6              160 #> Datsun 710                   22.8               4              108 #> Hornet 4 Drive               21.4               6              258 #> Hornet Sportabout            18.7               8              360 #> Valiant                      18.1               6              225 head(data_rename(mtcars[1:3], c(\"mpg\", \"cyl\", \"disp\"), \"new_{letter}\")) #>                   new_a new_b new_c #> Mazda RX4          21.0     6   160 #> Mazda RX4 Wag      21.0     6   160 #> Datsun 710         22.8     4   108 #> Hornet 4 Drive     21.4     6   258 #> Hornet Sportabout  18.7     8   360 #> Valiant            18.1     6   225  # User-defined glue-styled patterns from objects in environment x <- c(\"hi\", \"there\", \"!\") head(data_rename(mtcars[1:3], c(\"mpg\", \"cyl\", \"disp\"), \"col_{x}\")) #>                   col_hi col_there col_! #> Mazda RX4           21.0         6   160 #> Mazda RX4 Wag       21.0         6   160 #> Datsun 710          22.8         4   108 #> Hornet 4 Drive      21.4         6   258 #> Hornet Sportabout   18.7         8   360 #> Valiant             18.1         6   225"},{"path":"https://easystats.github.io/datawizard/reference/data_replicate.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand (i.e. replicate rows) a data frame — data_replicate","title":"Expand (i.e. replicate rows) a data frame — data_replicate","text":"Expand data frame replicating rows based another variable contains counts replications per row.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_replicate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand (i.e. replicate rows) a data frame — data_replicate","text":"","code":"data_replicate(   data,   expand = NULL,   select = NULL,   exclude = NULL,   remove_na = FALSE,   ignore_case = FALSE,   verbose = TRUE,   regex = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_replicate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand (i.e. replicate rows) a data frame — data_replicate","text":"data data frame. expand name column contains counts replications row. Can also numeric value, indicating position column. Note variable indicated expand must integer vector. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. remove_na Logical. TRUE, missing values column provided expand removed data frame. FALSE expand contains missing values, function throw error. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. verbose Toggle warnings. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. ... Currently used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_replicate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand (i.e. replicate rows) a data frame — data_replicate","text":"dataframe row replicated many times defined expand.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_replicate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand (i.e. replicate rows) a data frame — data_replicate","text":"","code":"data(mtcars) data_replicate(head(mtcars), \"carb\") #>     mpg cyl disp  hp drat    wt  qsec vs am gear #> 1  21.0   6  160 110 3.90 2.620 16.46  0  1    4 #> 2  21.0   6  160 110 3.90 2.620 16.46  0  1    4 #> 3  21.0   6  160 110 3.90 2.620 16.46  0  1    4 #> 4  21.0   6  160 110 3.90 2.620 16.46  0  1    4 #> 5  21.0   6  160 110 3.90 2.875 17.02  0  1    4 #> 6  21.0   6  160 110 3.90 2.875 17.02  0  1    4 #> 7  21.0   6  160 110 3.90 2.875 17.02  0  1    4 #> 8  21.0   6  160 110 3.90 2.875 17.02  0  1    4 #> 9  22.8   4  108  93 3.85 2.320 18.61  1  1    4 #> 10 21.4   6  258 110 3.08 3.215 19.44  1  0    3 #> 11 18.7   8  360 175 3.15 3.440 17.02  0  0    3 #> 12 18.7   8  360 175 3.15 3.440 17.02  0  0    3 #> 13 18.1   6  225 105 2.76 3.460 20.22  1  0    3"},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore the type of columns according to a reference data frame — data_restoretype","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"Restore type columns according reference data frame","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"","code":"data_restoretype(data, reference = NULL, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"data data frame restore column types. reference reference data frame find correct column types. NULL, column converted numeric generate NAs. example, c(\"1\", \"2\") can converted numeric c(\"Sepal.Length\"). ... Currently used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"data frame columns whose types restored based reference data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"","code":"data <- data.frame(   Sepal.Length = c(\"1\", \"3\", \"2\"),   Species = c(\"setosa\", \"versicolor\", \"setosa\"),   New = c(\"1\", \"3\", \"4\") )  fixed <- data_restoretype(data, reference = iris) summary(fixed) #>   Sepal.Length       Species      New            #>  Min.   :1.0   setosa    :2   Length:3           #>  1st Qu.:1.5   versicolor:1   Class :character   #>  Median :2.0   virginica :0   Mode  :character   #>  Mean   :2.0                                     #>  3rd Qu.:2.5                                     #>  Max.   :3.0"},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":null,"dir":"Reference","previous_headings":"","what":"Rotate a data frame — data_rotate","title":"Rotate a data frame — data_rotate","text":"function rotates data frame, .e. columns become rows vice versa. equivalent using t() restores data.frame class, preserves attributes prints warning data type modified (see example).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rotate a data frame — data_rotate","text":"","code":"data_rotate(data, rownames = NULL, colnames = FALSE, verbose = TRUE)  data_transpose(data, rownames = NULL, colnames = FALSE, verbose = TRUE)"},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rotate a data frame — data_rotate","text":"data data frame. rownames Character vector (optional). NULL, data frame's rownames added (first) column output, rownames name column. colnames Logical character vector (optional). TRUE, values first column x used column names rotated data frame. character vector, values column used column names. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rotate a data frame — data_rotate","text":"(rotated) data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rotate a data frame — data_rotate","text":"","code":"x <- mtcars[1:3, 1:4]  x #>                mpg cyl disp  hp #> Mazda RX4     21.0   6  160 110 #> Mazda RX4 Wag 21.0   6  160 110 #> Datsun 710    22.8   4  108  93  data_rotate(x) #>      Mazda RX4 Mazda RX4 Wag Datsun 710 #> mpg         21            21       22.8 #> cyl          6             6        4.0 #> disp       160           160      108.0 #> hp         110           110       93.0 data_rotate(x, rownames = \"property\") #>   property Mazda RX4 Mazda RX4 Wag Datsun 710 #> 1      mpg        21            21       22.8 #> 2      cyl         6             6        4.0 #> 3     disp       160           160      108.0 #> 4       hp       110           110       93.0  # use values in 1. column as column name data_rotate(x, colnames = TRUE) #>       21  21 22.8 #> cyl    6   6    4 #> disp 160 160  108 #> hp   110 110   93 data_rotate(x, rownames = \"property\", colnames = TRUE) #>   property  21  21 22.8 #> 1      cyl   6   6    4 #> 2     disp 160 160  108 #> 3       hp 110 110   93  # use either first column or specific column for column names x <- data.frame(a = 1:5, b = 11:15, c = 21:25) data_rotate(x, colnames = TRUE) #>    1  2  3  4  5 #> b 11 12 13 14 15 #> c 21 22 23 24 25 data_rotate(x, colnames = \"c\") #>   21 22 23 24 25 #> a  1  2  3  4  5 #> b 11 12 13 14 15"},{"path":"https://easystats.github.io/datawizard/reference/data_seek.html","id":null,"dir":"Reference","previous_headings":"","what":"Find variables by their names, variable or value labels — data_seek","title":"Find variables by their names, variable or value labels — data_seek","text":"functions seeks variables data frame, based patterns either match variable name (column name), variable labels, value labels factor levels. Matching variable value labels works \"labelled\" data, .e. variables either label attribute labels attribute. data_seek() particular useful larger data frames labelled data - finding correct variable name can challenge. function helps find required variables, certain patterns variable names labels known.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_seek.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find variables by their names, variable or value labels — data_seek","text":"","code":"data_seek(data, pattern, seek = c(\"names\", \"labels\"), fuzzy = FALSE)"},{"path":"https://easystats.github.io/datawizard/reference/data_seek.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find variables by their names, variable or value labels — data_seek","text":"data data frame. pattern Character string (regular expression) matched data. May also character vector length > 1. pattern searched column names, variable label value labels attributes, factor levels variables data. seek Character vector, indicating pattern sought. Use one following options: \"names\": Searches column names. \"column_names\" \"columns\" aliases \"names\". \"labels\": Searches variable labels. applies label attribute set variable. \"values\": Searches value labels factor levels. applies labels attribute set variable, variable factor. \"levels\" alias \"values\". \"\": Searches . fuzzy Logical. TRUE, \"fuzzy matching\" (partial close distance matching) used find pattern.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_seek.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find variables by their names, variable or value labels — data_seek","text":"data frame three columns: column index, column name - available - variable label matched variables data.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_seek.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find variables by their names, variable or value labels — data_seek","text":"","code":"# seek variables with \"Length\" in variable name or labels data_seek(iris, \"Length\") #> index |       column |       labels #> ----------------------------------- #>     1 | Sepal.Length | Sepal.Length #>     3 | Petal.Length | Petal.Length  # seek variables with \"dependency\" in names or labels # column \"e42dep\" has a label-attribute \"elder's dependency\" data(efc) data_seek(efc, \"dependency\") #> index | column |             labels #> ----------------------------------- #>     3 | e42dep | elder's dependency  # \"female\" only appears as value label attribute - default search is in # variable names and labels only, so no match data_seek(efc, \"female\") #> No matches found. # when we seek in all sources, we find the variable \"e16sex\" data_seek(efc, \"female\", seek = \"all\") #> index | column |         labels #> ------------------------------- #>     2 | e16sex | elder's gender  # typo, no match data_seek(iris, \"Lenght\") #> No matches found. # typo, fuzzy match data_seek(iris, \"Lenght\", fuzzy = TRUE) #> index |       column |       labels #> ----------------------------------- #>     1 | Sepal.Length | Sepal.Length #>     3 | Petal.Length | Petal.Length"},{"path":"https://easystats.github.io/datawizard/reference/data_separate.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate single variable into multiple variables — data_separate","title":"Separate single variable into multiple variables — data_separate","text":"Separates single variable multiple new variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_separate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate single variable into multiple variables — data_separate","text":"","code":"data_separate(   data,   select = NULL,   new_columns = NULL,   separator = \"[^[:alnum:]]+\",   guess_columns = NULL,   merge_multiple = FALSE,   merge_separator = \"\",   fill = \"right\",   extra = \"drop_right\",   convert_na = TRUE,   exclude = NULL,   append = FALSE,   ignore_case = FALSE,   verbose = TRUE,   regex = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_separate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate single variable into multiple variables — data_separate","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". new_columns names new columns, character vector. one variable selected (select), new names prefixed name original column. new_columns can also list (named) character vectors multiple variables separated. See 'Examples'. separator Separator columns. Can character vector, treated regular expression, numeric vector indicates positions string values split. guess_columns new_columns given, required number new columns guessed based results value splitting. example, variable split three new columns, considered required number new columns, columns named \"split_1\", \"split_2\" \"split_3\". values variable split different amount new columns, guess_column can either \"mode\" (number new columns based common number splits), \"min\" \"max\" use minimum resp. maximum number possible splits required number columns. merge_multiple Logical, TRUE one variable selected separating, new columns can merged. Value pairs split variables merged. merge_separator Separator string merge_multiple = TRUE. Defines string used merge values together. fill deal values return fewer new columns splitting? Can \"left\" (fill missing columns left NA), \"right\" (fill missing columns right NA) \"value_left\" \"value_right\" fill missing columns left right left-right-values. extra deal values return many new columns splitting? Can \"drop_left\" \"drop_right\" drop left-right-values, \"merge_left\" \"merge_right\" merge left- right-value together, keeping remaining values . convert_na Logical, TRUE, character \"NA\" values converted real NA values. exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical, FALSE (default), removes original columns separated. TRUE, columns preserved new columns appended data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. verbose Toggle warnings. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. ... Currently used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_separate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Separate single variable into multiple variables — data_separate","text":"data frame newly created variable(s), - append = TRUE - data including new variables.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_separate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Separate single variable into multiple variables — data_separate","text":"","code":"# simple case d <- data.frame(   x = c(\"1.a.6\", \"2.b.7\", \"3.c.8\"),   stringsAsFactors = FALSE ) d #>       x #> 1 1.a.6 #> 2 2.b.7 #> 3 3.c.8 data_separate(d, new_columns = c(\"a\", \"b\", \"c\")) #>   a b c #> 1 1 a 6 #> 2 2 b 7 #> 3 3 c 8  # guess number of columns d <- data.frame(   x = c(\"1.a.6\", NA, \"2.b.6.7\", \"3.c\", \"x.y.z\"),   stringsAsFactors = FALSE ) d #>         x #> 1   1.a.6 #> 2    <NA> #> 3 2.b.6.7 #> 4     3.c #> 5   x.y.z data_separate(d, guess_columns = \"mode\") #> Column `x` had different number of values after splitting. Variable was #>   split into 3 columns. #> `x` returned more columns than expected after splitting. Right-most #>   columns have been dropped. #> `x`returned fewer columns than expected after splitting. Right-most #>   columns were filled with `NA`. #>    x_1  x_2  x_3 #> 1    1    a    6 #> 2 <NA> <NA> <NA> #> 3    2    b    6 #> 4    3    c <NA> #> 5    x    y    z  data_separate(d, guess_columns = \"max\") #> Column `x` had different number of values after splitting. Variable was #>   split into 4 columns. #> `x`returned fewer columns than expected after splitting. Right-most #>   columns were filled with `NA`. #>    x_1  x_2  x_3  x_4 #> 1    1    a    6 <NA> #> 2 <NA> <NA> <NA> <NA> #> 3    2    b    6    7 #> 4    3    c <NA> <NA> #> 5    x    y    z <NA>  # drop left-most column data_separate(d, guess_columns = \"mode\", extra = \"drop_left\") #> Column `x` had different number of values after splitting. Variable was #>   split into 3 columns. #> `x` returned more columns than expected after splitting. Left-most #>   columns have been dropped. #> `x`returned fewer columns than expected after splitting. Right-most #>   columns were filled with `NA`. #>    x_1  x_2  x_3 #> 1    1    a    6 #> 2 <NA> <NA> <NA> #> 3    b    6    7 #> 4    3    c <NA> #> 5    x    y    z  # merge right-most column data_separate(d, guess_columns = \"mode\", extra = \"merge_right\") #> Column `x` had different number of values after splitting. Variable was #>   split into 3 columns. #> `x` returned more columns than expected after splitting. Right-most #>   columns have been merged together. #> `x`returned fewer columns than expected after splitting. Right-most #>   columns were filled with `NA`. #>    x_1  x_2  x_3 #> 1    1    a    6 #> 2 <NA> <NA> <NA> #> 3    2    b  6 7 #> 4    3    c <NA> #> 5    x    y    z  # fill columns with fewer values with left-most values data_separate(d, guess_columns = \"mode\", fill = \"value_left\") #> Column `x` had different number of values after splitting. Variable was #>   split into 3 columns. #> `x` returned more columns than expected after splitting. Right-most #>   columns have been dropped. #> `x`returned fewer columns than expected after splitting. Left-most #>   columns were filled with first value. #>    x_1  x_2  x_3 #> 1    1    a    6 #> 2 <NA> <NA> <NA> #> 3    2    b    6 #> 4    3    3    c #> 5    x    y    z  # fill and merge data_separate(   d,   guess_columns = \"mode\",   fill = \"value_left\",   extra = \"merge_right\" ) #> Column `x` had different number of values after splitting. Variable was #>   split into 3 columns. #> `x` returned more columns than expected after splitting. Right-most #>   columns have been merged together. #> `x`returned fewer columns than expected after splitting. Left-most #>   columns were filled with first value. #>    x_1  x_2  x_3 #> 1    1    a    6 #> 2 <NA> <NA> <NA> #> 3    2    b  6 7 #> 4    3    3    c #> 5    x    y    z  # multiple columns to split d <- data.frame(   x = c(\"1.a.6\", \"2.b.7\", \"3.c.8\"),   y = c(\"x.y.z\", \"10.11.12\", \"m.n.o\"),   stringsAsFactors = FALSE ) d #>       x        y #> 1 1.a.6    x.y.z #> 2 2.b.7 10.11.12 #> 3 3.c.8    m.n.o # split two columns, default column names data_separate(d, guess_columns = \"mode\") #>   x_1 x_2 x_3 y_1 y_2 y_3 #> 1   1   a   6   x   y   z #> 2   2   b   7  10  11  12 #> 3   3   c   8   m   n   o  # split into new named columns, repeating column names data_separate(d, new_columns = c(\"a\", \"b\", \"c\")) #>   x_a x_b x_c y_a y_b y_c #> 1   1   a   6   x   y   z #> 2   2   b   7  10  11  12 #> 3   3   c   8   m   n   o  # split selected variable new columns data_separate(d, select = \"y\", new_columns = c(\"a\", \"b\", \"c\")) #>       x  a  b  c #> 1 1.a.6  x  y  z #> 2 2.b.7 10 11 12 #> 3 3.c.8  m  n  o  # merge multiple split columns data_separate(   d,   new_columns = c(\"a\", \"b\", \"c\"),   merge_multiple = TRUE ) #>     a   b   c #> 1  1x  ay  6z #> 2 210 b11 712 #> 3  3m  cn  8o  # merge multiple split columns data_separate(   d,   new_columns = c(\"a\", \"b\", \"c\"),   merge_multiple = TRUE,   merge_separator = \"-\" ) #>      a    b    c #> 1  1-x  a-y  6-z #> 2 2-10 b-11 7-12 #> 3  3-m  c-n  8-o  # separate multiple columns, give proper column names d_sep <- data.frame(   x = c(\"1.a.6\", \"2.b.7.d\", \"3.c.8\", \"5.j\"),   y = c(\"m.n.99.22\", \"77.f.g.34\", \"44.9\", NA),   stringsAsFactors = FALSE )  data_separate(   d_sep,   select = c(\"x\", \"y\"),   new_columns = list(     x = c(\"A\", \"B\", \"C\"), # separate \"x\" into three columns     y = c(\"EE\", \"FF\", \"GG\", \"HH\") # separate \"y\" into four columns   ),   verbose = FALSE ) #>   A B    C   EE   FF   GG   HH #> 1 1 a    6    m    n   99   22 #> 2 2 b    7   77    f    g   34 #> 3 3 c    8   44    9 <NA> <NA> #> 4 5 j <NA> <NA> <NA> <NA> <NA>"},{"path":"https://easystats.github.io/datawizard/reference/data_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize data — data_summary","title":"Summarize data — data_summary","text":"function can used compute summary statistics data frame matrix.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize data — data_summary","text":"","code":"data_summary(x, ...)  # S3 method for class 'data.frame' data_summary(x, ..., by = NULL, remove_na = FALSE)"},{"path":"https://easystats.github.io/datawizard/reference/data_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize data — data_summary","text":"x (grouped) data frame. ... One named expressions define new variable name function compute summary statistic. Example: mean_sepal_width = mean(Sepal.Width). expression can also provided character string, e.g. \"mean_sepal_width = mean(Sepal.Width)\". summary function n() can used count number observations. Optional character string, indicating names one variables data frame. supplied, data split variables summary statistics computed group. remove_na Logical. TRUE, missing values omitted grouping variable. FALSE (default), missing values included level grouping variable.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize data — data_summary","text":"data frame requested summary statistics.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize data — data_summary","text":"","code":"data(iris) data_summary(iris, MW = mean(Sepal.Width), SD = sd(Sepal.Width)) #>   MW |   SD #> ----------- #> 3.06 | 0.44 data_summary(   iris,   MW = mean(Sepal.Width),   SD = sd(Sepal.Width),   by = \"Species\" ) #> Species    |   MW |   SD #> ------------------------ #> setosa     | 3.43 | 0.38 #> versicolor | 2.77 | 0.31 #> virginica  | 2.97 | 0.32  # same as d <- data_group(iris, \"Species\") data_summary(d, MW = mean(Sepal.Width), SD = sd(Sepal.Width)) #> Species    |   MW |   SD #> ------------------------ #> setosa     | 3.43 | 0.38 #> versicolor | 2.77 | 0.31 #> virginica  | 2.97 | 0.32  # multiple groups data(mtcars) data_summary(mtcars, MW = mean(mpg), SD = sd(mpg), by = c(\"am\", \"gear\")) #> am | gear |    MW |   SD #> ------------------------ #>  0 |    3 | 16.11 | 3.37 #>  0 |    4 | 21.05 | 3.07 #>  1 |    4 | 26.27 | 5.41 #>  1 |    5 | 21.38 | 6.66  # expressions can also be supplied as character strings data_summary(mtcars, \"MW = mean(mpg)\", \"SD = sd(mpg)\", by = c(\"am\", \"gear\")) #> am | gear |    MW |   SD #> ------------------------ #>  0 |    3 | 16.11 | 3.37 #>  0 |    4 | 21.05 | 3.07 #>  1 |    4 | 26.27 | 5.41 #>  1 |    5 | 21.38 | 6.66  # count observations within groups data_summary(mtcars, observations = n(), by = c(\"am\", \"gear\")) #> am | gear | observations #> ------------------------ #>  0 |    3 |           15 #>  0 |    4 |            4 #>  1 |    4 |            8 #>  1 |    5 |            5  # first and last observations of \"mpg\" within groups data_summary(   mtcars,   first = mpg[1],   last = mpg[length(mpg)],   by = c(\"am\", \"gear\") ) #> am | gear | first |  last #> ------------------------- #>  0 |    3 | 21.40 | 19.20 #>  0 |    4 | 24.40 | 17.80 #>  1 |    4 | 21.00 | 21.40 #>  1 |    5 | 26.00 | 15.00"},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create frequency and crosstables of variables — data_tabulate","title":"Create frequency and crosstables of variables — data_tabulate","text":"function creates frequency crosstables variables, including number levels/values well distribution raw, valid cumulative percentages. crosstables, row, column cell percentages can calculated.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create frequency and crosstables of variables — data_tabulate","text":"","code":"data_tabulate(x, ...)  # Default S3 method data_tabulate(   x,   by = NULL,   drop_levels = FALSE,   weights = NULL,   remove_na = FALSE,   proportions = NULL,   name = NULL,   verbose = TRUE,   ... )  # S3 method for class 'data.frame' data_tabulate(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   by = NULL,   drop_levels = FALSE,   weights = NULL,   remove_na = FALSE,   proportions = NULL,   collapse = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'datawizard_tables' as.data.frame(   x,   row.names = NULL,   optional = FALSE,   ...,   stringsAsFactors = FALSE,   add_total = FALSE )  # S3 method for class 'datawizard_table' as.table(x, remove_na = TRUE, simplify = FALSE, verbose = TRUE, ...)  # S3 method for class 'datawizard_table' print(x, big_mark = NULL, ...)  # S3 method for class 'datawizard_table' display(object, big_mark = NULL, format = \"markdown\", ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create frequency and crosstables of variables — data_tabulate","text":"x (grouped) data frame, vector factor. ... used. Optional vector factor. supplied, crosstable created. x data frame, can also character string indicating name variable x. drop_levels Logical, FALSE, factor levels occur data included table (frequency zero), else unused factor levels dropped frequency table. weights Optional numeric vector weights. Must length x. weights supplied, weighted frequencies calculated. remove_na Logical, FALSE, missing values included frequency crosstable, else missing values omitted. Note default .table() method remove_na = TRUE, missing values included returned table, makes sense post-processing table, e.g. using chisq.test(). proportions Optional character string, indicating type percentages calculated. applies crosstables, .e. NULL. Can \"row\" (row percentages), \"column\" (column percentages) \"full\" (calculate relative frequencies full table). name Optional character string, includes name used printing. verbose Toggle warnings messages. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. collapse Logical, TRUE collapses multiple tables one larger table printing. affects printing, returned object. row.names NULL character vector giving row     names data frame.  Missing values allowed. optional logical. TRUE, setting row names     converting column names (syntactic names: see     make.names) optional.  Note R's     base package .data.frame() methods use     optional column names treatment, basically     meaning data.frame(*, check.names = !optional).     See also make.names argument matrix method. stringsAsFactors logical: character vector converted     factor? add_total crosstables (.e. NULL), row column total N values added data frame. add_total effect .data.frame() simple frequency tables. simplify Logical, TRUE, returned table simplified single table object one frequency contingency table input. Else, always multiple table inputs simplify = FALSE, list tables returned. relevant .table() methods. ensure consistent output, default FALSE. big_mark Optional character string, indicating big mark used large numbers. NULL (default), big mark added automatically large numbers (.e. numbers 5 digits). want remove big mark, set big_mark = \"\". object object returned data_tabulate(). format String, indicating output format. Can \"markdown\" \"html\", \"tt\". format = \"html\" create HTML table using gt package. format = \"tt\" creates tinytable object, either printed markdown HTML table, depending environment. See insight::export_table() details.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create frequency and crosstables of variables — data_tabulate","text":"data frame, list data frames, one frequency table data frame per variable.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create frequency and crosstables of variables — data_tabulate","text":".data.frame() method, return frequency tables data frame. structure returned object nested data frame, first column contains name variable frequencies calculated, second column list column contains frequency tables data frame. See 'Examples'. also .table() method, returns table object frequencies variable. useful statistical analysis, e.g. using chisq.test() frequency table. See 'Examples'.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create frequency and crosstables of variables — data_tabulate","text":"print_html() print_md() methods available printing frequency crosstables HTML markdown format, e.g. print_html(data_tabulate(x)). print() method text outputs passes arguments ... insight::export_table().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"crosstables","dir":"Reference","previous_headings":"","what":"Crosstables","title":"Create frequency and crosstables of variables — data_tabulate","text":"supplied, crosstable created. crosstable includes <NA> (missing) values default. first column indicates values x, first row indicates values (including missing values). last row column contain total frequencies row column, respectively. Setting remove_na = FALSE omit missing values crosstable. Setting proportions \"row\" \"column\" add row column percentages. Setting proportions \"full\" add relative frequencies full table.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create frequency and crosstables of variables — data_tabulate","text":"","code":"# frequency tables ------- # ------------------------ data(efc)  # vector/factor data_tabulate(efc$c172code) #> carer's level of education (efc$c172code) <numeric> #> # total N=100 valid N=90 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  8 |     8 |    8.89 |         8.89 #> 2     | 66 |    66 |   73.33 |        82.22 #> 3     | 16 |    16 |   17.78 |       100.00 #> <NA>  | 10 |    10 |    <NA> |         <NA>  # drop missing values data_tabulate(efc$c172code, remove_na = TRUE) #> carer's level of education (efc$c172code) <numeric> #> # total N=90 valid N=90 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  8 |  8.89 |    8.89 |         8.89 #> 2     | 66 | 73.33 |   73.33 |        82.22 #> 3     | 16 | 17.78 |   17.78 |       100.00  # data frame data_tabulate(efc, c(\"e42dep\", \"c172code\")) #> elder's dependency (e42dep) <categorical> #> # total N=100 valid N=97 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  2 |     2 |    2.06 |         2.06 #> 2     |  4 |     4 |    4.12 |         6.19 #> 3     | 28 |    28 |   28.87 |        35.05 #> 4     | 63 |    63 |   64.95 |       100.00 #> <NA>  |  3 |     3 |    <NA> |         <NA> #>  #> carer's level of education (c172code) <numeric> #> # total N=100 valid N=90 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  8 |     8 |    8.89 |         8.89 #> 2     | 66 |    66 |   73.33 |        82.22 #> 3     | 16 |    16 |   17.78 |       100.00 #> <NA>  | 10 |    10 |    <NA> |         <NA>  # grouped data frame suppressPackageStartupMessages(library(poorman, quietly = TRUE)) efc %>%   group_by(c172code) %>%   data_tabulate(\"e16sex\") #> elder's gender (e16sex) <numeric> #> Grouped by c172code (1) #> # total N=8 valid N=8 #>  #> Value | N | Raw % | Valid % | Cumulative % #> ------+---+-------+---------+------------- #> 1     | 5 | 62.50 |   62.50 |        62.50 #> 2     | 3 | 37.50 |   37.50 |       100.00 #> <NA>  | 0 |  0.00 |    <NA> |         <NA> #>  #> elder's gender (e16sex) <numeric> #> Grouped by c172code (2) #> # total N=66 valid N=66 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     | 32 | 48.48 |   48.48 |        48.48 #> 2     | 34 | 51.52 |   51.52 |       100.00 #> <NA>  |  0 |  0.00 |    <NA> |         <NA> #>  #> elder's gender (e16sex) <numeric> #> Grouped by c172code (3) #> # total N=16 valid N=16 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  4 |    25 |      25 |           25 #> 2     | 12 |    75 |      75 |          100 #> <NA>  |  0 |     0 |    <NA> |         <NA> #>  #> elder's gender (e16sex) <numeric> #> Grouped by c172code (NA) #> # total N=10 valid N=10 #>  #> Value | N | Raw % | Valid % | Cumulative % #> ------+---+-------+---------+------------- #> 1     | 5 |    50 |      50 |           50 #> 2     | 5 |    50 |      50 |          100 #> <NA>  | 0 |     0 |    <NA> |         <NA>  # collapse tables efc %>%   group_by(c172code) %>%   data_tabulate(\"e16sex\", collapse = TRUE) #> # Frequency Table #>  #> Variable |         Group | Value |  N | Raw % | Valid % | Cumulative % #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   |  c172code (1) |     1 |  5 | 62.50 |   62.50 |        62.50 #>          |               |     2 |  3 | 37.50 |   37.50 |       100.00 #>          |               |  <NA> |  0 |  0.00 |    <NA> |         <NA> #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   |  c172code (2) |     1 | 32 | 48.48 |   48.48 |        48.48 #>          |               |     2 | 34 | 51.52 |   51.52 |       100.00 #>          |               |  <NA> |  0 |  0.00 |    <NA> |         <NA> #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   |  c172code (3) |     1 |  4 |    25 |      25 |           25 #>          |               |     2 | 12 |    75 |      75 |          100 #>          |               |  <NA> |  0 |     0 |    <NA> |         <NA> #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   | c172code (NA) |     1 |  5 |    50 |      50 |           50 #>          |               |     2 |  5 |    50 |      50 |          100 #>          |               |  <NA> |  0 |     0 |    <NA> |         <NA> #> ----------------------------------------------------------------------  # for larger N's (> 100000), a big mark is automatically added set.seed(123) x <- sample(1:3, 1e6, TRUE) data_tabulate(x, name = \"Large Number\") #> Large Number (x) <integer> #> # total N=1,000,000 valid N=1,000,000 #>  #> Value |       N | Raw % | Valid % | Cumulative % #> ------+---------+-------+---------+------------- #> 1     | 333,852 | 33.39 |   33.39 |        33.39 #> 2     | 332,910 | 33.29 |   33.29 |        66.68 #> 3     | 333,238 | 33.32 |   33.32 |       100.00 #> <NA>  |       0 |  0.00 |    <NA> |         <NA>  # to remove the big mark, use \"print(..., big_mark = \"\")\" print(data_tabulate(x), big_mark = \"\") #> x <integer> #> # total N=1000000 valid N=1000000 #>  #> Value |      N | Raw % | Valid % | Cumulative % #> ------+--------+-------+---------+------------- #> 1     | 333852 | 33.39 |   33.39 |        33.39 #> 2     | 332910 | 33.29 |   33.29 |        66.68 #> 3     | 333238 | 33.32 |   33.32 |       100.00 #> <NA>  |      0 |  0.00 |    <NA> |         <NA>  # weighted frequencies set.seed(123) efc$weights <- abs(rnorm(n = nrow(efc), mean = 1, sd = 0.5)) data_tabulate(efc$e42dep, weights = efc$weights) #> elder's dependency (efc$e42dep) <categorical> #> # total N=105 valid N=100 (weighted) #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  3 |  2.86 |       3 |            3 #> 2     |  4 |  3.81 |       4 |            7 #> 3     | 26 | 24.76 |      26 |           33 #> 4     | 67 | 63.81 |      67 |          100 #> <NA>  |  5 |  4.76 |    <NA> |         <NA>  # crosstables ------ # ------------------  # add some missing values set.seed(123) efc$e16sex[sample.int(nrow(efc), 5)] <- NA  data_tabulate(efc, \"c172code\", by = \"e16sex\") #> c172code | male | female | <NA> | Total #> ---------+------+--------+------+------ #> 1        |    5 |      2 |    1 |     8 #> 2        |   30 |     34 |    2 |    66 #> 3        |    4 |     10 |    2 |    16 #> <NA>     |    5 |      5 |    0 |    10 #> ---------+------+--------+------+------ #> Total    |   44 |     51 |    5 |   100  # add row and column percentages data_tabulate(efc, \"c172code\", by = \"e16sex\", proportions = \"row\") #> c172code |       male |     female |      <NA> | Total #> ---------+------------+------------+-----------+------ #> 1        |  5 (62.5%) |  2 (25.0%) | 1 (12.5%) |     8 #> 2        | 30 (45.5%) | 34 (51.5%) | 2  (3.0%) |    66 #> 3        |  4 (25.0%) | 10 (62.5%) | 2 (12.5%) |    16 #> <NA>     |  5 (50.0%) |  5 (50.0%) | 0  (0.0%) |    10 #> ---------+------------+------------+-----------+------ #> Total    |         44 |         51 |         5 |   100 data_tabulate(efc, \"c172code\", by = \"e16sex\", proportions = \"column\") #> c172code |       male |     female |      <NA> | Total #> ---------+------------+------------+-----------+------ #> 1        |  5 (11.4%) |  2  (3.9%) | 1 (20.0%) |     8 #> 2        | 30 (68.2%) | 34 (66.7%) | 2 (40.0%) |    66 #> 3        |  4  (9.1%) | 10 (19.6%) | 2 (40.0%) |    16 #> <NA>     |  5 (11.4%) |  5  (9.8%) | 0  (0.0%) |    10 #> ---------+------------+------------+-----------+------ #> Total    |         44 |         51 |         5 |   100  # omit missing values data_tabulate(   efc$c172code,   by = efc$e16sex,   proportions = \"column\",   remove_na = TRUE ) #> efc$c172code |       male |     female | Total #> -------------+------------+------------+------ #> 1            |  5 (12.8%) |  2  (4.3%) |     7 #> 2            | 30 (76.9%) | 34 (73.9%) |    64 #> 3            |  4 (10.3%) | 10 (21.7%) |    14 #> -------------+------------+------------+------ #> Total        |         39 |         46 |    85  # round percentages out <- data_tabulate(efc, \"c172code\", by = \"e16sex\", proportions = \"column\") print(out, digits = 0) #> c172code |     male |   female |    <NA> | Total #> ---------+----------+----------+---------+------ #> 1        |  5 (11%) |  2  (4%) | 1 (20%) |     8 #> 2        | 30 (68%) | 34 (67%) | 2 (40%) |    66 #> 3        |  4  (9%) | 10 (20%) | 2 (40%) |    16 #> <NA>     |  5 (11%) |  5 (10%) | 0  (0%) |    10 #> ---------+----------+----------+---------+------ #> Total    |       44 |       51 |       5 |   100  # coerce to data frames result <- data_tabulate(efc, \"c172code\", by = \"e16sex\") as.data.frame(result) #>        var        table #> 1 c172code c(1, 2, .... as.data.frame(result)$table #> [[1]] #>   c172code male female NA #> 1        1    5      2  1 #> 2        2   30     34  2 #> 3        3    4     10  2 #> 4     <NA>    5      5  0 #>  as.data.frame(result, add_total = TRUE)$table #> [[1]] #>   c172code male female <NA> Total #> 1        1    5      2    1     8 #> 2        2   30     34    2    66 #> 3        3    4     10    2    16 #> 4     <NA>    5      5    0    10 #> 5    Total   44     51    5   100 #>   # post-processing ------ # ----------------------  out <- data_tabulate(efc, \"c172code\", by = \"e16sex\") # we need to simplify the output, else we get a list of tables suppressWarnings(chisq.test(as.table(out, simplify = TRUE))) #> Removing NA values from frequency table. #>  #> \tPearson's Chi-squared test #>  #> data:  as.table(out, simplify = TRUE) #> X-squared = 3.5548, df = 2, p-value = 0.1691 #>   # apply chisq.test to each table out <- data_tabulate(efc, c(\"c172code\", \"e16sex\")) suppressWarnings(lapply(as.table(out), chisq.test)) #> Removing NA values from frequency table. #> [[1]] #>  #> \tChi-squared test for given probabilities #>  #> data:  X[[i]] #> X-squared = 65.867, df = 2, p-value = 4.98e-15 #>  #>  #> [[2]] #>  #> \tChi-squared test for given probabilities #>  #> data:  X[[i]] #> X-squared = 0.51579, df = 1, p-value = 0.4726 #>  #>   # can also handle grouped data frames d <- data_group(mtcars, \"am\") x <- data_tabulate(d, \"cyl\", by = \"gear\") as.table(x) #> $`am (0)` #>    3  4 #> 4  1  2 #> 6  2  2 #> 8 12  0 #>  #> $`am (1)` #>   4 5 #> 4 6 2 #> 6 2 1 #> 8 0 2 #>"},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape (pivot) data from wide to long — data_to_long","title":"Reshape (pivot) data from wide to long — data_to_long","text":"function \"lengthens\" data, increasing number rows decreasing number columns. dependency-free base-R equivalent tidyr::pivot_longer().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape (pivot) data from wide to long — data_to_long","text":"","code":"data_to_long(   data,   select = \"all\",   names_to = \"name\",   names_prefix = NULL,   names_sep = NULL,   names_pattern = NULL,   values_to = \"value\",   values_drop_na = FALSE,   rows_to = NULL,   ignore_case = FALSE,   regex = FALSE,   ...,   cols )  reshape_longer(   data,   select = \"all\",   names_to = \"name\",   names_prefix = NULL,   names_sep = NULL,   names_pattern = NULL,   values_to = \"value\",   values_drop_na = FALSE,   rows_to = NULL,   ignore_case = FALSE,   regex = FALSE,   ...,   cols )"},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape (pivot) data from wide to long — data_to_long","text":"data data frame convert long format, rows fewer columns operation. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". names_to name new column (variable) contain names columns select values, identify source values. names_to can character vector one column name, case names_sep names_pattern must provided order identify parts column names go newly created columns. See also 'Examples'. names_prefix regular expression used remove matching text start variable name. names_sep, names_pattern names_to contains multiple values, argument controls column name broken . names_pattern takes regular expression containing matching groups, .e. \"()\". values_to name new column contain values columns select. values_drop_na TRUE, drop rows contain NA values_to column. effectively converts explicit missing values implicit missing values, generally used missing values data created structure. rows_to name column contain row names row numbers original data. NULL, removed. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. ... Currently used. cols Identical select. argument ensure compatibility tidyr::pivot_longer(). select cols provided, cols used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape (pivot) data from wide to long — data_to_long","text":"tibble provided input, reshape_longer() also returns tibble. Otherwise, returns data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reshape (pivot) data from wide to long — data_to_long","text":"Reshaping data long format usually means input data frame wide format, multiple measurements taken subject stored multiple columns (variables). long format stores information single column, measurement per subject stored separate row. values variables select repeated. necessary information data_to_long() : columns contain repeated measurements (select). name newly created column contain names columns select (names_to), identify source values. names_to can also character vector one column name, case names_sep names_pattern must provided specify parts column names go newly created columns. name newly created column contains values columns select (values_to). words: repeated measurements spread across several columns gathered single column (values_to), original column names, identify source gathered values, stored one new columns (names_to).","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape (pivot) data from wide to long — data_to_long","text":"","code":"wide_data <- setNames(   data.frame(replicate(2, rnorm(8))),   c(\"Time1\", \"Time2\") ) wide_data$ID <- 1:8 wide_data #>        Time1       Time2 ID #> 1  1.2394959  2.52833655  1 #> 2 -0.1089660  0.54909674  2 #> 3 -0.1172420  0.23821292  3 #> 4  0.1830826 -1.04889314  4 #> 5  1.2805549  1.29476325  5 #> 6 -1.7272706  0.82553984  6 #> 7  1.6901844 -0.05568601  7 #> 8  0.5038124 -0.78438222  8  # Default behaviour (equivalent to tidyr::pivot_longer(wide_data, cols = 1:3)) # probably doesn't make much sense to mix \"time\" and \"id\" data_to_long(wide_data) #>     name       value #> 1  Time1  1.23949589 #> 2  Time2  2.52833655 #> 3     ID  1.00000000 #> 4  Time1 -0.10896597 #> 5  Time2  0.54909674 #> 6     ID  2.00000000 #> 7  Time1 -0.11724196 #> 8  Time2  0.23821292 #> 9     ID  3.00000000 #> 10 Time1  0.18308261 #> 11 Time2 -1.04889314 #> 12    ID  4.00000000 #> 13 Time1  1.28055488 #> 14 Time2  1.29476325 #> 15    ID  5.00000000 #> 16 Time1 -1.72727063 #> 17 Time2  0.82553984 #> 18    ID  6.00000000 #> 19 Time1  1.69018435 #> 20 Time2 -0.05568601 #> 21    ID  7.00000000 #> 22 Time1  0.50381245 #> 23 Time2 -0.78438222 #> 24    ID  8.00000000  # Customizing the names data_to_long(   wide_data,   select = c(\"Time1\", \"Time2\"),   names_to = \"Timepoint\",   values_to = \"Score\" ) #>    ID Timepoint       Score #> 1   1     Time1  1.23949589 #> 2   1     Time2  2.52833655 #> 3   2     Time1 -0.10896597 #> 4   2     Time2  0.54909674 #> 5   3     Time1 -0.11724196 #> 6   3     Time2  0.23821292 #> 7   4     Time1  0.18308261 #> 8   4     Time2 -1.04889314 #> 9   5     Time1  1.28055488 #> 10  5     Time2  1.29476325 #> 11  6     Time1 -1.72727063 #> 12  6     Time2  0.82553984 #> 13  7     Time1  1.69018435 #> 14  7     Time2 -0.05568601 #> 15  8     Time1  0.50381245 #> 16  8     Time2 -0.78438222  # Reshape multiple columns into long format. mydat <- data.frame(   age = c(20, 30, 40),   sex = c(\"Female\", \"Male\", \"Male\"),   score_t1 = c(30, 35, 32),   score_t2 = c(33, 34, 37),   score_t3 = c(36, 35, 38),   speed_t1 = c(2, 3, 1),   speed_t2 = c(3, 4, 5),   speed_t3 = c(1, 8, 6) ) # The column names are split into two columns: \"type\" and \"time\". The # pattern for splitting column names is provided in `names_pattern`. Values # of all \"score_*\" and \"speed_*\" columns are gathered into a single column # named \"count\". data_to_long(   mydat,   select = 3:8,   names_to = c(\"type\", \"time\"),   names_pattern = \"(score|speed)_t(\\\\d+)\",   values_to = \"count\" ) #>    age    sex  type time count #> 1   20 Female score    1    30 #> 2   20 Female score    2    33 #> 3   20 Female score    3    36 #> 4   20 Female speed    1     2 #> 5   20 Female speed    2     3 #> 6   20 Female speed    3     1 #> 7   30   Male score    1    35 #> 8   30   Male score    2    34 #> 9   30   Male score    3    35 #> 10  30   Male speed    1     3 #> 11  30   Male speed    2     4 #> 12  30   Male speed    3     8 #> 13  40   Male score    1    32 #> 14  40   Male score    2    37 #> 15  40   Male score    3    38 #> 16  40   Male speed    1     1 #> 17  40   Male speed    2     5 #> 18  40   Male speed    3     6  # Full example # ------------------ data <- psych::bfi # Wide format with one row per participant's personality test  # Pivot long format very_long_data <- data_to_long(data,   select = regex(\"\\\\d\"), # Select all columns that contain a digit   names_to = \"Item\",   values_to = \"Score\",   rows_to = \"Participant\" ) head(very_long_data) #>   gender education age Participant Item Score #> 1      1        NA  16       61617   A1     2 #> 2      1        NA  16       61617   A2     4 #> 3      1        NA  16       61617   A3     3 #> 4      1        NA  16       61617   A4     4 #> 5      1        NA  16       61617   A5     4 #> 6      1        NA  16       61617   C1     2  even_longer_data <- data_to_long(   tidyr::who,   select = new_sp_m014:newrel_f65,   names_to = c(\"diagnosis\", \"gender\", \"age\"),   names_pattern = \"new_?(.*)_(.)(.*)\",   values_to = \"count\" ) head(even_longer_data) #> # A tibble: 6 × 8 #>   country     iso2  iso3   year diagnosis gender age   count #>   <chr>       <chr> <chr> <dbl> <chr>     <chr>  <chr> <dbl> #> 1 Afghanistan AF    AFG    1980 sp        m      014      NA #> 2 Afghanistan AF    AFG    1980 sp        m      1524     NA #> 3 Afghanistan AF    AFG    1980 sp        m      2534     NA #> 4 Afghanistan AF    AFG    1980 sp        m      3544     NA #> 5 Afghanistan AF    AFG    1980 sp        m      4554     NA #> 6 Afghanistan AF    AFG    1980 sp        m      5564     NA"},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape (pivot) data from long to wide — data_to_wide","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"function \"widens\" data, increasing number columns decreasing number rows. dependency-free base-R equivalent tidyr::pivot_wider().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"","code":"data_to_wide(   data,   id_cols = NULL,   values_from = \"Value\",   names_from = \"Name\",   names_sep = \"_\",   names_prefix = \"\",   names_glue = NULL,   values_fill = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  reshape_wider(   data,   id_cols = NULL,   values_from = \"Value\",   names_from = \"Name\",   names_sep = \"_\",   names_prefix = \"\",   names_glue = NULL,   values_fill = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"data data frame convert wide format, columns fewer rows post-widening pre-widening. id_cols name column identifies rows data observations grouped gathered data spread new columns. Usually, variable containing ID observations repeatedly measured. NULL, use remaining columns names_from values_from ID columns. id_cols can also character vector one name identifier columns. See also 'Details' 'Examples'. values_from name columns original data contains values used fill new columns created widened data. Can also one selection helpers (see argument select data_select()). names_from name column original data whose values used naming new columns created widened data. unique value column become name one new columns. case names_prefix provided, column names concatenated string given names_prefix. values_from specifies one variable widened, new column names combination old column names values_from values names_from, avoid duplicate column names. names_sep names_from values_from contains multiple variables, used join values together single string use column name. names_prefix String added start every variable name. particularly useful names_from numeric vector want create syntactic variable names. names_glue Instead names_sep names_prefix, can supply glue specification uses names_from columns create custom column names. Note delimiters supported names_glue curly brackets, { }. values_fill Defunct argument, function anymore. removed future versions. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... used now.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"tibble provided input, data_to_wide() also returns tibble. Otherwise, returns data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"Reshaping data wide format usually means input data frame long format, multiple measurements taken subject stored multiple rows. wide format stores information single row, measurement stored separate column. Thus, necessary information data_to_wide() : name column(s) identify groups repeated measurements (id_cols). name column whose values become new column names (names_from). Since values may necessarily reflect appropriate column names, can use names_prefix add prefix newly created column name. name column(s) contain values (values_from) new columns created names_from. words: repeated measurements, indicated id_cols, saved column values_from spread new columns, named values names_from. See also 'Examples'.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"","code":"data_long <- read.table(header = TRUE, text = \"  subject sex condition measurement        1   M   control         7.9        1   M     cond1        12.3        1   M     cond2        10.7        2   F   control         6.3        2   F     cond1        10.6        2   F     cond2        11.1        3   F   control         9.5        3   F     cond1        13.1        3   F     cond2        13.8        4   M   control        11.5        4   M     cond1        13.4        4   M     cond2        12.9\")  # converting long data into wide format data_to_wide(   data_long,   id_cols = \"subject\",   names_from = \"condition\",   values_from = \"measurement\" ) #>   subject control cond1 cond2 #> 1       1     7.9  12.3  10.7 #> 2       2     6.3  10.6  11.1 #> 3       3     9.5  13.1  13.8 #> 4       4    11.5  13.4  12.9  # converting long data into wide format with custom column names data_to_wide(   data_long,   id_cols = \"subject\",   names_from = \"condition\",   values_from = \"measurement\",   names_prefix = \"Var.\",   names_sep = \".\" ) #>   subject Var.control Var.cond1 Var.cond2 #> 1       1         7.9      12.3      10.7 #> 2       2         6.3      10.6      11.1 #> 3       3         9.5      13.1      13.8 #> 4       4        11.5      13.4      12.9  # converting long data into wide format, combining multiple columns production <- expand.grid(   product = c(\"A\", \"B\"),   country = c(\"AI\", \"EI\"),   year = 2000:2014 ) production <- data_filter(production, (product == \"A\" & country == \"AI\") | product == \"B\") production$production <- rnorm(nrow(production))  data_to_wide(   production,   names_from = c(\"product\", \"country\"),   values_from = \"production\",   names_glue = \"prod_{product}_{country}\" ) #>    year   prod_A_AI  prod_B_AI   prod_B_EI #> 1  2000 -0.21586539 -0.3349128 -1.08569914 #> 2  2001 -0.08542326  1.0706105 -0.14539355 #> 3  2002 -1.16554485 -0.8185157  0.68493608 #> 4  2003 -0.32005642 -1.3115224 -0.59960833 #> 5  2004 -0.12941069  0.8867361 -0.15139596 #> 6  2005  0.32979120 -3.2273228 -0.77179177 #> 7  2006  0.28654857 -1.2205120  0.43455038 #> 8  2007  0.80017687 -0.1639310  1.24291877 #> 9  2008 -0.93438506  0.3937087  0.40363146 #> 10 2009 -0.88643672 -1.3189376  0.02884391 #> 11 2010 -0.43212979  1.6898725  1.22839278 #> 12 2011  0.27602348 -1.0489755 -0.52086934 #> 13 2012  1.62320252 -1.0700682  1.68588724 #> 14 2013 -0.24168977 -0.4682005 -0.77297823 #> 15 2014  2.14991934 -1.3343536  0.49587048  # reshaping multiple long columns into wide format. to avoid duplicate # column names, new names are a combination of the old column names in # `values_from` and the values from `names_from` data_long <- read.table(header = TRUE, text = \" subject_id time score anxiety test          1    1    10       5   NA          1    2    NA       7   NA          2    1    15       6   NA          2    2    12      NA   NA          3    1    18       8   NA          5    2    11       4   NA          4    1    NA       5   NA          4    2    14      NA   NA\")  data_to_wide(   data_long,   id_cols = \"subject_id\",   names_from = \"time\",   values_from = c(\"score\", \"anxiety\", \"test\") ) #>   subject_id score_1 score_2 anxiety_1 anxiety_2 test_1 test_2 #> 1          1      10      NA         5         7     NA     NA #> 2          2      15      12         6        NA     NA     NA #> 3          3      18      NA         8        NA     NA     NA #> 4          5      NA      11        NA         4     NA     NA #> 5          4      NA      14         5        NA     NA     NA  # using the \"sleepstudy\" dataset data(sleepstudy, package = \"lme4\")  # the sleepstudy data contains repeated measurements of average reaction # times for each subjects over multiple days, in a sleep deprivation study. # It is in long-format, i.e. each row corresponds to a single measurement. # The variable \"Days\" contains the timepoint of the measurement, and # \"Reaction\" contains the measurement itself. Converting this data to wide # format will create a new column for each day, with the reaction time as the # value. head(sleepstudy) #>   Reaction Days Subject #> 1 249.5600    0     308 #> 2 258.7047    1     308 #> 3 250.8006    2     308 #> 4 321.4398    3     308 #> 5 356.8519    4     308 #> 6 414.6901    5     308  data_to_wide(   sleepstudy,   id_cols = \"Subject\",   names_from = \"Days\",   values_from = \"Reaction\" ) #>    Subject        0        1        2        3        4        5        6 #> 1      308 249.5600 258.7047 250.8006 321.4398 356.8519 414.6901 382.2038 #> 2      309 222.7339 205.2658 202.9778 204.7070 207.7161 215.9618 213.6303 #> 3      310 199.0539 194.3322 234.3200 232.8416 229.3074 220.4579 235.4208 #> 4      330 321.5426 300.4002 283.8565 285.1330 285.7973 297.5855 280.2396 #> 5      331 287.6079 285.0000 301.8206 320.1153 316.2773 293.3187 290.0750 #> 6      332 234.8606 242.8118 272.9613 309.7688 317.4629 309.9976 454.1619 #> 7      333 283.8424 289.5550 276.7693 299.8097 297.1710 338.1665 332.0265 #> 8      334 265.4731 276.2012 243.3647 254.6723 279.0244 284.1912 305.5248 #> 9      335 241.6083 273.9472 254.4907 270.8021 251.4519 254.6362 245.4523 #> 10     337 312.3666 313.8058 291.6112 346.1222 365.7324 391.8385 404.2601 #> 11     349 236.1032 230.3167 238.9256 254.9220 250.7103 269.7744 281.5648 #> 12     350 256.2968 243.4543 256.2046 255.5271 268.9165 329.7247 379.4445 #> 13     351 250.5265 300.0576 269.8939 280.5891 271.8274 304.6336 287.7466 #> 14     352 221.6771 298.1939 326.8785 346.8555 348.7402 352.8287 354.4266 #> 15     369 271.9235 268.4369 257.2424 277.6566 314.8222 317.2135 298.1353 #> 16     370 225.2640 234.5235 238.9008 240.4730 267.5373 344.1937 281.1481 #> 17     371 269.8804 272.4428 277.8989 281.7895 279.1705 284.5120 259.2658 #> 18     372 269.4117 273.4740 297.5968 310.6316 287.1726 329.6076 334.4818 #>           7        8        9 #> 1  290.1486 430.5853 466.3535 #> 2  217.7272 224.2957 237.3142 #> 3  255.7511 261.0125 247.5153 #> 4  318.2613 305.3495 354.0487 #> 5  334.8177 293.7469 371.5811 #> 6  346.8311 330.3003 253.8644 #> 7  348.8399 333.3600 362.0428 #> 8  331.5229 335.7469 377.2990 #> 9  235.3110 235.7541 237.2466 #> 10 416.6923 455.8643 458.9167 #> 11 308.1020 336.2806 351.6451 #> 12 362.9184 394.4872 389.0527 #> 13 266.5955 321.5418 347.5655 #> 14 360.4326 375.6406 388.5417 #> 15 348.1229 340.2800 366.5131 #> 16 347.5855 365.1630 372.2288 #> 17 304.6306 350.7807 369.4692 #> 18 343.2199 369.1417 364.1236  # clearer column names data_to_wide(   sleepstudy,   id_cols = \"Subject\",   names_from = \"Days\",   values_from = \"Reaction\",   names_prefix = \"Reaction_Day_\" ) #>    Subject Reaction_Day_0 Reaction_Day_1 Reaction_Day_2 Reaction_Day_3 #> 1      308       249.5600       258.7047       250.8006       321.4398 #> 2      309       222.7339       205.2658       202.9778       204.7070 #> 3      310       199.0539       194.3322       234.3200       232.8416 #> 4      330       321.5426       300.4002       283.8565       285.1330 #> 5      331       287.6079       285.0000       301.8206       320.1153 #> 6      332       234.8606       242.8118       272.9613       309.7688 #> 7      333       283.8424       289.5550       276.7693       299.8097 #> 8      334       265.4731       276.2012       243.3647       254.6723 #> 9      335       241.6083       273.9472       254.4907       270.8021 #> 10     337       312.3666       313.8058       291.6112       346.1222 #> 11     349       236.1032       230.3167       238.9256       254.9220 #> 12     350       256.2968       243.4543       256.2046       255.5271 #> 13     351       250.5265       300.0576       269.8939       280.5891 #> 14     352       221.6771       298.1939       326.8785       346.8555 #> 15     369       271.9235       268.4369       257.2424       277.6566 #> 16     370       225.2640       234.5235       238.9008       240.4730 #> 17     371       269.8804       272.4428       277.8989       281.7895 #> 18     372       269.4117       273.4740       297.5968       310.6316 #>    Reaction_Day_4 Reaction_Day_5 Reaction_Day_6 Reaction_Day_7 Reaction_Day_8 #> 1        356.8519       414.6901       382.2038       290.1486       430.5853 #> 2        207.7161       215.9618       213.6303       217.7272       224.2957 #> 3        229.3074       220.4579       235.4208       255.7511       261.0125 #> 4        285.7973       297.5855       280.2396       318.2613       305.3495 #> 5        316.2773       293.3187       290.0750       334.8177       293.7469 #> 6        317.4629       309.9976       454.1619       346.8311       330.3003 #> 7        297.1710       338.1665       332.0265       348.8399       333.3600 #> 8        279.0244       284.1912       305.5248       331.5229       335.7469 #> 9        251.4519       254.6362       245.4523       235.3110       235.7541 #> 10       365.7324       391.8385       404.2601       416.6923       455.8643 #> 11       250.7103       269.7744       281.5648       308.1020       336.2806 #> 12       268.9165       329.7247       379.4445       362.9184       394.4872 #> 13       271.8274       304.6336       287.7466       266.5955       321.5418 #> 14       348.7402       352.8287       354.4266       360.4326       375.6406 #> 15       314.8222       317.2135       298.1353       348.1229       340.2800 #> 16       267.5373       344.1937       281.1481       347.5855       365.1630 #> 17       279.1705       284.5120       259.2658       304.6306       350.7807 #> 18       287.1726       329.6076       334.4818       343.2199       369.1417 #>    Reaction_Day_9 #> 1        466.3535 #> 2        237.3142 #> 3        247.5153 #> 4        354.0487 #> 5        371.5811 #> 6        253.8644 #> 7        362.0428 #> 8        377.2990 #> 9        237.2466 #> 10       458.9167 #> 11       351.6451 #> 12       389.0527 #> 13       347.5655 #> 14       388.5417 #> 15       366.5131 #> 16       372.2288 #> 17       369.4692 #> 18       364.1236  # For unequal group sizes, missing information is filled with NA d <- subset(sleepstudy, Days %in% c(0, 1, 2, 3, 4))[c(1:9, 11:13, 16:17, 21), ]  # long format, different number of \"Subjects\" d #>    Reaction Days Subject #> 1  249.5600    0     308 #> 2  258.7047    1     308 #> 3  250.8006    2     308 #> 4  321.4398    3     308 #> 5  356.8519    4     308 #> 11 222.7339    0     309 #> 12 205.2658    1     309 #> 13 202.9778    2     309 #> 14 204.7070    3     309 #> 21 199.0539    0     310 #> 22 194.3322    1     310 #> 23 234.3200    2     310 #> 31 321.5426    0     330 #> 32 300.4002    1     330 #> 41 287.6079    0     331  data_to_wide(   d,   id_cols = \"Subject\",   names_from = \"Days\",   values_from = \"Reaction\",   names_prefix = \"Reaction_Day_\" ) #>   Subject Reaction_Day_0 Reaction_Day_1 Reaction_Day_2 Reaction_Day_3 #> 1     308       249.5600       258.7047       250.8006       321.4398 #> 2     309       222.7339       205.2658       202.9778       204.7070 #> 3     310       199.0539       194.3322       234.3200             NA #> 4     330       321.5426       300.4002             NA             NA #> 5     331       287.6079             NA             NA             NA #>   Reaction_Day_4 #> 1       356.8519 #> 2             NA #> 3             NA #> 4             NA #> 5             NA"},{"path":"https://easystats.github.io/datawizard/reference/data_unique.html","id":null,"dir":"Reference","previous_headings":"","what":"Keep only one row from all with duplicated IDs — data_unique","title":"Keep only one row from all with duplicated IDs — data_unique","text":"rows least one duplicated ID, keep one. Methods selecting duplicated row either first duplicate, last duplicate, \"best\" duplicate (default), based duplicate smallest number NA. case ties, picks first duplicate, one likely valid authentic, given practice effects. Contrarily dplyr::distinct(), data_unique() keeps columns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_unique.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Keep only one row from all with duplicated IDs — data_unique","text":"","code":"data_unique(   data,   select = NULL,   keep = \"best\",   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE )"},{"path":"https://easystats.github.io/datawizard/reference/data_unique.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Keep only one row from all with duplicated IDs — data_unique","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". keep method used duplicate selection, either \"best\" (default), \"first\", \"last\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_unique.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Keep only one row from all with duplicated IDs — data_unique","text":"data frame, containing chosen duplicates.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_unique.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Keep only one row from all with duplicated IDs — data_unique","text":"","code":"df1 <- data.frame(   id = c(1, 2, 3, 1, 3),   item1 = c(NA, 1, 1, 2, 3),   item2 = c(NA, 1, 1, 2, 3),   item3 = c(NA, 1, 1, 2, 3) )  data_unique(df1, select = \"id\") #> (2 duplicates removed, with method 'best') #>   id item1 item2 item3 #> 1  1     2     2     2 #> 2  2     1     1     1 #> 3  3     1     1     1"},{"path":"https://easystats.github.io/datawizard/reference/data_unite.html","id":null,"dir":"Reference","previous_headings":"","what":"Unite (","title":"Unite (","text":"Merge values multiple variables per observation one new variable.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_unite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unite (","text":"","code":"data_unite(   data,   new_column = NULL,   select = NULL,   exclude = NULL,   separator = \"_\",   append = FALSE,   remove_na = FALSE,   ignore_case = FALSE,   verbose = TRUE,   regex = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_unite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unite (","text":"data data frame. new_column name new column, string. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. separator character use values. append Logical, FALSE (default), removes original columns united. TRUE, columns preserved new column appended data frame. remove_na Logical, TRUE, missing values (NA) included united values. FALSE, missing values represented \"NA\" united values. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. verbose Toggle warnings. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. ... Currently used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_unite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unite (","text":"data, newly created variable.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_unite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unite (","text":"","code":"d <- data.frame(   x = 1:3,   y = letters[1:3],   z = 6:8 ) d #>   x y z #> 1 1 a 6 #> 2 2 b 7 #> 3 3 c 8 data_unite(d, new_column = \"xyz\") #>     xyz #> 1 1_a_6 #> 2 2_b_7 #> 3 3_c_8 data_unite(d, new_column = \"xyz\", remove = FALSE) #>     xyz #> 1 1_a_6 #> 2 2_b_7 #> 3 3_c_8 data_unite(d, new_column = \"xyz\", select = c(\"x\", \"z\")) #>   y xyz #> 1 a 1_6 #> 2 b 2_7 #> 3 c 3_8 data_unite(d, new_column = \"xyz\", select = c(\"x\", \"z\"), append = TRUE) #>   x y z xyz #> 1 1 a 6 1_6 #> 2 2 b 7 2_7 #> 3 3 c 8 3_8"},{"path":"https://easystats.github.io/datawizard/reference/datawizard-package.html","id":null,"dir":"Reference","previous_headings":"","what":"datawizard: Easy Data Wrangling and Statistical Transformations — datawizard-package","title":"datawizard: Easy Data Wrangling and Statistical Transformations — datawizard-package","text":"lightweight package assist key steps involved data analysis workflow: wrangling raw data get needed form, applying preprocessing steps statistical transformations, compute statistical summaries data properties distributions. also data wrangling backend packages 'easystats' ecosystem. Reference: Patil et al. (2022) doi:10.21105/joss.04684 .","code":""},{"path":"https://easystats.github.io/datawizard/reference/datawizard-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"datawizard: Easy Data Wrangling and Statistical Transformations — datawizard-package","text":"datawizard","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/datawizard-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"datawizard: Easy Data Wrangling and Statistical Transformations — datawizard-package","text":"Maintainer: Etienne Bacher etienne.bacher@protonmail.com (ORCID) Authors: Indrajeet Patil patilindrajeet.science@gmail.com (ORCID) Dominique Makowski dom.makowski@gmail.com (ORCID) Daniel Lüdecke d.luedecke@uke.de (ORCID) Mattan S. Ben-Shachar matanshm@post.bgu.ac.il (ORCID) Brenton M. Wiernik brenton@wiernik.org (ORCID) contributors: Rémi Thériault remi.theriault@mail.mcgill.ca (ORCID) [contributor] Thomas J. Faulkenberry faulkenberry@tarleton.edu [reviewer] Robert Garrett rcg4@illinois.edu [reviewer]","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute group-meaned and de-meaned variables — demean","title":"Compute group-meaned and de-meaned variables — demean","text":"demean() computes group- de-meaned versions variable can used regression analysis model - within-subject effect (person-mean centering centering within clusters). degroup() generic terms centering-operation. demean() always uses mean-centering, degroup() can also use mode median centering.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute group-meaned and de-meaned variables — demean","text":"","code":"demean(   x,   select,   by,   nested = FALSE,   suffix_demean = \"_within\",   suffix_groupmean = \"_between\",   append = TRUE,   add_attributes = TRUE,   verbose = TRUE )  degroup(   x,   select,   by,   nested = FALSE,   center = \"mean\",   suffix_demean = \"_within\",   suffix_groupmean = \"_between\",   append = TRUE,   add_attributes = TRUE,   verbose = TRUE )  detrend(   x,   select,   by,   nested = FALSE,   center = \"mean\",   suffix_demean = \"_within\",   suffix_groupmean = \"_between\",   append = TRUE,   add_attributes = TRUE,   verbose = TRUE )"},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute group-meaned and de-meaned variables — demean","text":"x data frame. select Character vector (formula) names variables select group- de-meaned. Character vector (formula) name variable indicates group- cluster-ID. cross-classified nested designs, can also identify two variables group- cluster-IDs. data nested treated , set nested = TRUE. Else, defines two variables nested = FALSE, cross-classified design assumed. Note demean() degroup() handle mix nested cross-classified designs one model. nested designs, can : character vector name variable indicates levels, ordered highest level lowest (e.g. = c(\"L4\", \"L3\", \"L2\"). character vector variable names format = \"L4/L3/L2\", levels separated /. See also section De-meaning cross-classified designs De-meaning nested designs . nested Logical, TRUE, data treated nested. FALSE, data treated cross-classified. applies contains one variable. suffix_demean, suffix_groupmean String value, appended names group-meaned de-meaned variables x. default, de-meaned variables suffixed \"_within\" grouped-meaned variables \"_between\". append Logical, TRUE (default), group- de-meaned variables appended (column bind) original data x, thus returning original de-/group-meaned variables. add_attributes Logical, TRUE, returned variables gain attributes indicate within- -effects. relevant printing model_parameters() - cases, within- -effects printed separated blocks. verbose Toggle warnings messages. center Method centering. demean() always performs mean-centering, degroup() can use center = \"median\" center = \"mode\" median- mode-centering, also \"min\" \"max\".","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute group-meaned and de-meaned variables — demean","text":"data frame group-/de-meaned variables, get suffix \"_between\" (group-meaned variable) \"_within\" (de-meaned variable) default. cross-classified nested designs, name pattern group-meaned variables name centered variable followed name variable indicates related grouping level, e.g. predictor_L3_between predictor_L2_between.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"heterogeneity-bias","dir":"Reference","previous_headings":"","what":"Heterogeneity Bias","title":"Compute group-meaned and de-meaned variables — demean","text":"Mixed models include different levels sources variability, .e. error terms level. macro-indicators (level-2 predictors, higher-level units, general: group-level predictors vary within across groups) included fixed effects (.e. treated covariate level-1), variance left unaccounted covariate absorbed error terms level-1 level-2 (Bafumi Gelman 2006; Gelman Hill 2007, Chapter 12.6.): \"covariates contain two parts: one specific higher-level entity vary occasions, one represents difference occasions, within higher-level entities\" (Bell et al. 2015). Hence, error terms correlated covariate, violates one assumptions mixed models (iid, independent identically distributed error terms). bias also called heterogeneity bias (Bell et al. 2015). resolve problem, level-2 predictors used (level-1) covariates separated \"within\" \"\" effects \"de-meaning\" \"group-meaning\": demeaning time-varying predictors, \"higher level, mean term longer constrained Level 1 effects, free account higher-level variance associated variable\" (Bell et al. 2015).","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"panel-data-and-correlating-fixed-and-group-effects","dir":"Reference","previous_headings":"","what":"Panel data and correlating fixed and group effects","title":"Compute group-meaned and de-meaned variables — demean","text":"demean() intended create group- de-meaned variables panel regression models (fixed effects models), complex random-effect-within-models (see Bell et al. 2015, 2018), group-effects (random effects) fixed effects correlate (see Bafumi Gelman 2006). can happen, instance, analyzing panel data, can lead Heterogeneity Bias. control correlating predictors group effects, recommended include group-meaned de-meaned version time-varying covariates (group-meaned version time-invariant covariates higher level, e.g. level-2 predictors) model. , one can fit complex multilevel models panel data, including time-varying predictors, time-invariant predictors random effects.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"why-mixed-models-are-preferred-over-fixed-effects-models","dir":"Reference","previous_headings":"","what":"Why mixed models are preferred over fixed effects models","title":"Compute group-meaned and de-meaned variables — demean","text":"mixed models approach can model causes endogeneity explicitly including (separated) within- -effects time-varying fixed effects including time-constant fixed effects. Furthermore, mixed models also include random effects, thus mixed models approach superior classic fixed-effects models, lack information variation group-effects -subject effects. Furthermore, fixed effects regression include random slopes, means fixed effects regressions neglecting \"cross-cluster differences effects lower-level controls () reduces precision estimated context effects, resulting unnecessarily wide confidence intervals low statistical power\" (Heisig et al. 2017).","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"terminology","dir":"Reference","previous_headings":"","what":"Terminology","title":"Compute group-meaned and de-meaned variables — demean","text":"group-meaned variable simply mean independent variable within group (id-level cluster) represented . represents cluster-mean independent variable. regression coefficient group-meaned variable -subject-effect. de-meaned variable centered version group-meaned variable. De-meaning sometimes also called person-mean centering centering within clusters. regression coefficient de-meaned variable represents within-subject-effect.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-with-continuous-predictors","dir":"Reference","previous_headings":"","what":"De-meaning with continuous predictors","title":"Compute group-meaned and de-meaned variables — demean","text":"continuous time-varying predictors, recommendation include de-meaned group-meaned versions fixed effects, raw (untransformed) time-varying predictors . de-meaned predictor also included random effect (random slope). regression models, coefficient de-meaned predictors indicates within-subject effect, coefficient group-meaned predictor indicates -subject effect.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-with-binary-predictors","dir":"Reference","previous_headings":"","what":"De-meaning with binary predictors","title":"Compute group-meaned and de-meaned variables — demean","text":"binary time-varying predictors, two recommendations. First include raw (untransformed) binary predictor fixed effect de-meaned variable random effect (random slope). alternative add de-meaned version(s) binary time-varying covariates additional fixed effect well (instead adding random slope). Centering time-varying binary variables obtain within-effects (level 1) necessary. sensible interpretation left typical 0/1 format (Hoffmann 2015, chapter 8-2.). demean() thus coerce categorical time-varying predictors numeric compute de- group-meaned versions variables, raw (untransformed) binary predictor de-meaned version added model.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-of-factors-with-more-than-levels","dir":"Reference","previous_headings":"","what":"De-meaning of factors with more than 2 levels","title":"Compute group-meaned and de-meaned variables — demean","text":"Factors two levels demeaned two ways: first, also converted numeric de-meaned; second, dummy variables created (binary, 0/1 coding level) binary dummy-variables de-meaned way (described ). Packages like panelr internally convert factors dummies demeaning, behaviour can mimicked .","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-interaction-terms","dir":"Reference","previous_headings":"","what":"De-meaning interaction terms","title":"Compute group-meaned and de-meaned variables — demean","text":"multiple ways deal interaction terms within- -effects. classical approach simply use product term de-meaned variables (.e. introducing de-meaned variables interaction term model formula, e.g. y ~ x_within * time_within). approach, however, might subject bias (see Giesselmann & Schmidt-Catran 2020). Another option first calculate product term apply de-meaning . approach produces estimator \"reflects unit-level differences interacted variables whose moderators vary within units\", desirable within interaction two time-dependent variables required. demean() internally select contains interaction terms. third option, interaction result genuine within estimator, \"double de-mean\" interaction terms (Giesselmann & Schmidt-Catran 2018), however, currently supported demean(). required, wmb() function panelr package used. de-mean interaction terms within-models, simply specify term interaction select-argument, e.g. select = \"*b\" (see 'Examples').","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-for-cross-classified-designs","dir":"Reference","previous_headings":"","what":"De-meaning for cross-classified designs","title":"Compute group-meaned and de-meaned variables — demean","text":"demean() can handle cross-classified designs, data two groups higher (.e. second) level. cases, -argument can identify two variables represent cross-classified group- cluster-IDs. de-meaned variables cross-classified designs simply subtracting group means individual value, .e. fully cluster-mean-centering (see Guo et al. 2024 details). Note de-meaning cross-classified designs equivalent de-meaning nested data structures models three levels. Set nested = TRUE explicitly assume nested design. cross-classified designs, de-meaning supposed work models like y ~ x + (1|level3) + (1|level2), models like y ~ x + (1|level3/level2). Note demean() degroup() handle mix nested cross-classified designs one model.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-for-nested-designs","dir":"Reference","previous_headings":"","what":"De-meaning for nested designs","title":"Compute group-meaned and de-meaned variables — demean","text":"Brincks et al. (2017) suggested algorithm center variables nested designs, implemented demean(). nested designs, set nested = TRUE specify variables indicate different levels descending order argument. E.g., = c(\"level4\", \"level3, \"level2\") assumes model like y ~ x + (1|level4/level3/level2). alternative notation -argument = \"level4/level3/level2\", similar formula notation.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"analysing-panel-data-with-mixed-models-using-lme-","dir":"Reference","previous_headings":"","what":"Analysing panel data with mixed models using lme4","title":"Compute group-meaned and de-meaned variables — demean","text":"description translate formulas described Bell et al. 2018 R using lmer() lme4 can found vignette.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute group-meaned and de-meaned variables — demean","text":"Bafumi J, Gelman . 2006. Fitting Multilevel Models Predictors Group Effects Correlate. . Philadelphia, PA: Annual meeting American Political Science Association. Bell , Fairbrother M, Jones K. 2019. Fixed Random Effects Models: Making Informed Choice. Quality & Quantity (53); 1051-1074 Bell , Jones K. 2015. Explaining Fixed Effects: Random Effects Modeling Time-Series Cross-Sectional Panel Data. Political Science Research Methods, 3(1), 133–153. Brincks, . M., Enders, C. K., Llabre, M. M., Bulotsky-Shearer, R. J., Prado, G., Feaster, D. J. (2017). Centering Predictor Variables Three-Level Contextual Models. Multivariate Behavioral Research, 52(2), 149–163. https://doi.org/10.1080/00273171.2016.1256753 Gelman , Hill J. 2007. Data Analysis Using Regression Multilevel/Hierarchical Models. Analytical Methods Social Research. Cambridge, New York: Cambridge University Press Giesselmann M, Schmidt-Catran, AW. 2020. Interactions fixed effects regression models. Sociological Methods & Research, 1–28. https://doi.org/10.1177/0049124120914934 Guo Y, Dhaliwal J, Rights JD. 2024. Disaggregating level-specific effects cross-classified multilevel models. Behavior Research Methods, 56(4), 3023–3057. Heisig JP, Schaeffer M, Giesecke J. 2017. Costs Simplicity: Multilevel Models May Benefit Accounting Cross-Cluster Differences Effects Controls. American Sociological Review 82 (4): 796–827. Hoffman L. 2015. Longitudinal analysis: modeling within-person fluctuation change. New York: Routledge","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute group-meaned and de-meaned variables — demean","text":"","code":"data(iris) iris$ID <- sample(1:4, nrow(iris), replace = TRUE) # fake-ID iris$binary <- as.factor(rbinom(150, 1, .35)) # binary variable  x <- demean(iris, select = c(\"Sepal.Length\", \"Petal.Length\"), by = \"ID\") head(x) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species ID binary #> 1          5.1         3.5          1.4         0.2  setosa  2      0 #> 2          4.9         3.0          1.4         0.2  setosa  2      0 #> 3          4.7         3.2          1.3         0.2  setosa  3      1 #> 4          4.6         3.1          1.5         0.2  setosa  4      0 #> 5          5.0         3.6          1.4         0.2  setosa  4      0 #> 6          5.4         3.9          1.7         0.4  setosa  2      0 #>   Sepal.Length_between Petal.Length_between Sepal.Length_within #> 1             5.681579             3.434211          -0.5815789 #> 2             5.681579             3.434211          -0.7815789 #> 3             5.789189             3.451351          -1.0891892 #> 4             5.748718             3.684615          -1.1487179 #> 5             5.748718             3.684615          -0.7487179 #> 6             5.681579             3.434211          -0.2815789 #>   Petal.Length_within #> 1           -2.034211 #> 2           -2.034211 #> 3           -2.151351 #> 4           -2.184615 #> 5           -2.284615 #> 6           -1.734211  x <- demean(iris, select = c(\"Sepal.Length\", \"binary\", \"Species\"), by = \"ID\") #> Categorical predictors (binary, Species) have been coerced to numeric #>   values to compute de- and group-meaned variables. head(x) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species ID binary #> 1          5.1         3.5          1.4         0.2  setosa  2      0 #> 2          4.9         3.0          1.4         0.2  setosa  2      0 #> 3          4.7         3.2          1.3         0.2  setosa  3      1 #> 4          4.6         3.1          1.5         0.2  setosa  4      0 #> 5          5.0         3.6          1.4         0.2  setosa  4      0 #> 6          5.4         3.9          1.7         0.4  setosa  2      0 #>   Sepal.Length_between binary_between Species_between Species_setosa_between #> 1             5.681579      0.4473684       0.8947368              0.4210526 #> 2             5.681579      0.4473684       0.8947368              0.4210526 #> 3             5.789189      0.2432432       0.8648649              0.4324324 #> 4             5.748718      0.2307692       0.9487179              0.2820513 #> 5             5.748718      0.2307692       0.9487179              0.2820513 #> 6             5.681579      0.4473684       0.8947368              0.4210526 #>   Species_versicolor_between Species_virginica_between Sepal.Length_within #> 1                  0.2631579                 0.3157895          -0.5815789 #> 2                  0.2631579                 0.3157895          -0.7815789 #> 3                  0.2702703                 0.2972973          -1.0891892 #> 4                  0.4871795                 0.2307692          -1.1487179 #> 5                  0.4871795                 0.2307692          -0.7487179 #> 6                  0.2631579                 0.3157895          -0.2815789 #>   binary_within Species_within Species_setosa_within Species_versicolor_within #> 1    -0.4473684     -0.8947368             0.5789474                -0.2631579 #> 2    -0.4473684     -0.8947368             0.5789474                -0.2631579 #> 3     0.7567568     -0.8648649             0.5675676                -0.2702703 #> 4    -0.2307692     -0.9487179             0.7179487                -0.4871795 #> 5    -0.2307692     -0.9487179             0.7179487                -0.4871795 #> 6    -0.4473684     -0.8947368             0.5789474                -0.2631579 #>   Species_virginica_within #> 1               -0.3157895 #> 2               -0.3157895 #> 3               -0.2972973 #> 4               -0.2307692 #> 5               -0.2307692 #> 6               -0.3157895   # demean interaction term x*y dat <- data.frame(   a = c(1, 2, 3, 4, 1, 2, 3, 4),   x = c(4, 3, 3, 4, 1, 2, 1, 2),   y = c(1, 2, 1, 2, 4, 3, 2, 1),   ID = c(1, 2, 3, 1, 2, 3, 1, 2) ) demean(dat, select = c(\"a\", \"x*y\"), by = \"ID\") #>   a x y ID a_between x_y_between   a_within x_y_within #> 1 1 4 1  1  2.666667    4.666667 -1.6666667 -0.6666667 #> 2 2 3 2  2  2.333333    4.000000 -0.3333333  2.0000000 #> 3 3 3 1  3  2.500000    4.500000  0.5000000 -1.5000000 #> 4 4 4 2  1  2.666667    4.666667  1.3333333  3.3333333 #> 5 1 1 4  2  2.333333    4.000000 -1.3333333  0.0000000 #> 6 2 2 3  3  2.500000    4.500000 -0.5000000  1.5000000 #> 7 3 1 2  1  2.666667    4.666667  0.3333333 -2.6666667 #> 8 4 2 1  2  2.333333    4.000000  1.6666667 -2.0000000  # or in formula-notation demean(dat, select = ~ a + x * y, by = ~ID) #>   a x y ID a_between x_y_between   a_within x_y_within #> 1 1 4 1  1  2.666667    4.666667 -1.6666667 -0.6666667 #> 2 2 3 2  2  2.333333    4.000000 -0.3333333  2.0000000 #> 3 3 3 1  3  2.500000    4.500000  0.5000000 -1.5000000 #> 4 4 4 2  1  2.666667    4.666667  1.3333333  3.3333333 #> 5 1 1 4  2  2.333333    4.000000 -1.3333333  0.0000000 #> 6 2 2 3  3  2.500000    4.500000 -0.5000000  1.5000000 #> 7 3 1 2  1  2.666667    4.666667  0.3333333 -2.6666667 #> 8 4 2 1  2  2.333333    4.000000  1.6666667 -2.0000000"},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe a distribution — describe_distribution","title":"Describe a distribution — describe_distribution","text":"function describes distribution set indices (e.g., measures centrality, dispersion, range, skewness, kurtosis).","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe a distribution — describe_distribution","text":"","code":"describe_distribution(x, ...)  # S3 method for class 'numeric' describe_distribution(   x,   centrality = \"mean\",   dispersion = TRUE,   iqr = TRUE,   range = TRUE,   quartiles = FALSE,   ci = NULL,   iterations = 100,   threshold = 0.1,   verbose = TRUE,   ... )  # S3 method for class 'factor' describe_distribution(x, dispersion = TRUE, range = TRUE, verbose = TRUE, ...)  # S3 method for class 'data.frame' describe_distribution(   x,   select = NULL,   exclude = NULL,   centrality = \"mean\",   dispersion = TRUE,   iqr = TRUE,   range = TRUE,   quartiles = FALSE,   include_factors = FALSE,   ci = NULL,   iterations = 100,   threshold = 0.1,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   by = NULL,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe a distribution — describe_distribution","text":"x numeric vector, character vector, data frame, list. See Details. ... Additional arguments passed methods. centrality point-estimates (centrality indices) compute. Character (vector) list one options: \"median\", \"mean\", \"MAP\" (see map_estimate()), \"trimmed\" (just mean(x, trim = threshold)), \"mode\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). Dispersion available \"MAP\" \"mode\" centrality indices. iqr Logical, TRUE, interquartile range calculated (based stats::IQR(), using type = 6). range Return range (min max). quartiles Return first third quartiles (25th 75th percentiles). ci Confidence Interval (CI) level. Default NULL, .e. confidence intervals computed. NULL, confidence intervals based bootstrap replicates (see iterations). iterations number bootstrap replicates computing confidence intervals. applies ci NULL. Defaults 100. stable results, increase number iterations, note can also increase computation time significantly. threshold centrality = \"trimmed\" (.e. trimmed mean), indicates fraction (0 0.5) observations trimmed end vector mean computed. verbose Show silence warnings messages. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. include_factors Logical, TRUE, factors included output, however, columns range (first last factor levels) well n missing contain information. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. Column names indicating split data various groups describing distribution. groups added potentially existing groups created data_group().","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe a distribution — describe_distribution","text":"data frame columns describe properties variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Describe a distribution — describe_distribution","text":"x data frame, numeric variables kept displayed summary default. x list, behavior different whether x stored list. x stored (example, describe_distribution(mylist) mylist created ), artificial variable names used summary (Var_1, Var_2, etc.). x unstored list (example, describe_distribution(list(mtcars$mpg))), \"mtcars$mpg\" used variable name.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Describe a distribution — describe_distribution","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe a distribution — describe_distribution","text":"","code":"describe_distribution(rnorm(100)) #>  Mean |   SD |  IQR |         Range | Skewness | Kurtosis |   n | n_Missing #> --------------------------------------------------------------------------- #> -0.05 | 1.07 | 1.69 | [-3.31, 2.46] |    -0.31 |    -0.07 | 100 |         0  data(iris) describe_distribution(iris) #> Variable     | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |   n | n_Missing #> ---------------------------------------------------------------------------------------- #> Sepal.Length | 5.84 | 0.83 | 1.30 | [4.30, 7.90] |     0.31 |    -0.55 | 150 |         0 #> Sepal.Width  | 3.06 | 0.44 | 0.52 | [2.00, 4.40] |     0.32 |     0.23 | 150 |         0 #> Petal.Length | 3.76 | 1.77 | 3.52 | [1.00, 6.90] |    -0.27 |    -1.40 | 150 |         0 #> Petal.Width  | 1.20 | 0.76 | 1.50 | [0.10, 2.50] |    -0.10 |    -1.34 | 150 |         0 describe_distribution(iris, include_factors = TRUE, quartiles = TRUE) #> Variable     | Mean |   SD |  IQR |               Range |  Quartiles | Skewness #> ------------------------------------------------------------------------------- #> Sepal.Length | 5.84 | 0.83 | 1.30 |          [4.3, 7.9] | 5.10, 6.40 |     0.31 #> Sepal.Width  | 3.06 | 0.44 | 0.52 |            [2, 4.4] | 2.80, 3.30 |     0.32 #> Petal.Length | 3.76 | 1.77 | 3.52 |            [1, 6.9] | 1.60, 5.10 |    -0.27 #> Petal.Width  | 1.20 | 0.76 | 1.50 |          [0.1, 2.5] | 0.30, 1.80 |    -0.10 #> Species      |      |      |      | [setosa, virginica] |            |     0.00 #>  #> Variable     | Kurtosis |   n | n_Missing #> ----------------------------------------- #> Sepal.Length |    -0.55 | 150 |         0 #> Sepal.Width  |     0.23 | 150 |         0 #> Petal.Length |    -1.40 | 150 |         0 #> Petal.Width  |    -1.34 | 150 |         0 #> Species      |    -1.51 | 150 |         0 describe_distribution(list(mtcars$mpg, mtcars$cyl)) #> Variable   |  Mean |   SD |  IQR |          Range | Skewness | Kurtosis |  n | n_Missing #> ---------------------------------------------------------------------------------------- #> mtcars$mpg | 20.09 | 6.03 | 7.53 | [10.40, 33.90] |     0.67 |    -0.02 | 32 |         0 #> mtcars$cyl |  6.19 | 1.79 | 4.00 |   [4.00, 8.00] |    -0.19 |    -1.76 | 32 |         0"},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute mode for a statistical distribution — distribution_mode","title":"Compute mode for a statistical distribution — distribution_mode","text":"Compute mode statistical distribution","code":""},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute mode for a statistical distribution — distribution_mode","text":"","code":"distribution_mode(x)"},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute mode for a statistical distribution — distribution_mode","text":"x atomic vector, list, data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute mode for a statistical distribution — distribution_mode","text":"value appears frequently provided data. returned data structure entered one.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute mode for a statistical distribution — distribution_mode","text":"","code":"distribution_mode(c(1, 2, 3, 3, 4, 5)) #> [1] 3 distribution_mode(c(1.5, 2.3, 3.7, 3.7, 4.0, 5)) #> [1] 3.7"},{"path":"https://easystats.github.io/datawizard/reference/dot-is_deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a message saying that an argument is deprecated and that the user should use its replacement instead. — .is_deprecated","title":"Print a message saying that an argument is deprecated and that the user should use its replacement instead. — .is_deprecated","text":"Print message saying argument deprecated user use replacement instead.","code":""},{"path":"https://easystats.github.io/datawizard/reference/dot-is_deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a message saying that an argument is deprecated and that the user should use its replacement instead. — .is_deprecated","text":"","code":".is_deprecated(arg, replacement)"},{"path":"https://easystats.github.io/datawizard/reference/dot-is_deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a message saying that an argument is deprecated and that the user should use its replacement instead. — .is_deprecated","text":"arg Argument deprecated replacement Argument replaces deprecated argument","code":""},{"path":"https://easystats.github.io/datawizard/reference/efc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from the EFC Survey — efc","title":"Sample dataset from the EFC Survey — efc","text":"Selected variables EUROFAMCARE survey. Useful testing \"real-life\" data sets, including random missing values. data set also value variable label attributes.","code":""},{"path":"https://easystats.github.io/datawizard/reference/extract_column_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Find or get columns in a data frame based on search patterns — data_select","title":"Find or get columns in a data frame based on search patterns — data_select","text":"extract_column_names() returns column names data set match certain search pattern, data_select() returns found data.","code":""},{"path":"https://easystats.github.io/datawizard/reference/extract_column_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find or get columns in a data frame based on search patterns — data_select","text":"","code":"data_select(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  extract_column_names(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  find_columns(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/extract_column_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find or get columns in a data frame based on search patterns — data_select","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... Arguments passed functions. Mostly used yet.","code":""},{"path":"https://easystats.github.io/datawizard/reference/extract_column_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find or get columns in a data frame based on search patterns — data_select","text":"extract_column_names() returns character vector column names matched pattern select exclude, NULL matching column name found. data_select() returns data frame matching columns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/extract_column_names.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find or get columns in a data frame based on search patterns — data_select","text":"Specifically data_select(), select can also named character vector. case, names used rename columns output data frame. See 'Examples'. Note possible either pass entire select helper pattern inside select helper function argument:   means also possible use loop values arguments patterns:   However, behavior limited \"single-level function\". work nested functions, like :   case, better pass whole select helper argument outer():","code":"foo <- function(data, pattern) {   extract_column_names(data, select = starts_with(pattern)) } foo(iris, pattern = \"Sep\")  foo2 <- function(data, pattern) {   extract_column_names(data, select = pattern) } foo2(iris, pattern = starts_with(\"Sep\")) for (i in c(\"Sepal\", \"Sp\")) {   head(iris) |>     extract_column_names(select = starts_with(i)) |>     print() } inner <- function(data, arg) {   extract_column_names(data, select = arg) } outer <- function(data, arg) {   inner(data, starts_with(arg)) } outer(iris, \"Sep\") outer <- function(data, arg) {   inner(data, arg) } outer(iris, starts_with(\"Sep\"))"},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/extract_column_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find or get columns in a data frame based on search patterns — data_select","text":"","code":"# Find column names by pattern extract_column_names(iris, starts_with(\"Sepal\")) #> [1] \"Sepal.Length\" \"Sepal.Width\"  extract_column_names(iris, ends_with(\"Width\")) #> [1] \"Sepal.Width\" \"Petal.Width\" extract_column_names(iris, regex(\"\\\\.\")) #> [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  extract_column_names(iris, c(\"Petal.Width\", \"Sepal.Length\")) #> [1] \"Petal.Width\"  \"Sepal.Length\"  # starts with \"Sepal\", but not allowed to end with \"width\" extract_column_names(iris, starts_with(\"Sepal\"), exclude = contains(\"Width\")) #> [1] \"Sepal.Length\"  # find numeric with mean > 3.5 numeric_mean_35 <- function(x) is.numeric(x) && mean(x, na.rm = TRUE) > 3.5 extract_column_names(iris, numeric_mean_35) #> [1] \"Sepal.Length\" \"Petal.Length\"  # find column names, using range extract_column_names(mtcars, c(cyl:hp, wt)) #> [1] \"cyl\"  \"disp\" \"hp\"   \"wt\"    # find range of column names by range, using character vector extract_column_names(mtcars, c(\"cyl:hp\", \"wt\")) #> [1] \"cyl\"  \"disp\" \"hp\"   \"wt\"    # rename returned columns for \"data_select()\" head(data_select(mtcars, c(`Miles per Gallon` = \"mpg\", Cylinders = \"cyl\"))) #>                   Miles per Gallon Cylinders #> Mazda RX4                     21.0         6 #> Mazda RX4 Wag                 21.0         6 #> Datsun 710                    22.8         4 #> Hornet 4 Drive                21.4         6 #> Hornet Sportabout             18.7         8 #> Valiant                       18.1         6"},{"path":"https://easystats.github.io/datawizard/reference/labels_to_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert value labels into factor levels — labels_to_levels","title":"Convert value labels into factor levels — labels_to_levels","text":"Convert value labels factor levels","code":""},{"path":"https://easystats.github.io/datawizard/reference/labels_to_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert value labels into factor levels — labels_to_levels","text":"","code":"labels_to_levels(x, ...)  # S3 method for class 'factor' labels_to_levels(x, verbose = TRUE, ...)  # S3 method for class 'data.frame' labels_to_levels(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   append = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/labels_to_levels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert value labels into factor levels — labels_to_levels","text":"x data frame factor. variable types (e.g. numerics) allowed. ... Currently used. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/labels_to_levels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert value labels into factor levels — labels_to_levels","text":"x, factors former levels replaced value labels.","code":""},{"path":"https://easystats.github.io/datawizard/reference/labels_to_levels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert value labels into factor levels — labels_to_levels","text":"labels_to_levels() allows use value labels factors levels.","code":""},{"path":"https://easystats.github.io/datawizard/reference/labels_to_levels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert value labels into factor levels — labels_to_levels","text":"","code":"data(efc) # create factor x <- as.factor(efc$c172code) # add value labels - these are not factor levels yet x <- assign_labels(x, values = c(`1` = \"low\", `2` = \"mid\", `3` = \"high\")) levels(x) #> [1] \"1\" \"2\" \"3\" data_tabulate(x) #> x <categorical> #> # total N=100 valid N=90 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  8 |     8 |    8.89 |         8.89 #> 2     | 66 |    66 |   73.33 |        82.22 #> 3     | 16 |    16 |   17.78 |       100.00 #> <NA>  | 10 |    10 |    <NA> |         <NA>  x <- labels_to_levels(x) levels(x) #> [1] \"low\"  \"mid\"  \"high\" data_tabulate(x) #> x <categorical> #> # total N=100 valid N=90 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> low   |  8 |     8 |    8.89 |         8.89 #> mid   | 66 |    66 |   73.33 |        82.22 #> high  | 16 |    16 |   17.78 |       100.00 #> <NA>  | 10 |    10 |    <NA> |         <NA>"},{"path":"https://easystats.github.io/datawizard/reference/makepredictcall.dw_transformer.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility Function for Safe Prediction with datawizard transformers — makepredictcall.dw_transformer","title":"Utility Function for Safe Prediction with datawizard transformers — makepredictcall.dw_transformer","text":"function allows use () datawizard's transformers inside model formula. See examples .  Currently, center(), standardize(), normalize(), & rescale() supported.","code":""},{"path":"https://easystats.github.io/datawizard/reference/makepredictcall.dw_transformer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility Function for Safe Prediction with datawizard transformers — makepredictcall.dw_transformer","text":"","code":"# S3 method for class 'dw_transformer' makepredictcall(var, call)"},{"path":"https://easystats.github.io/datawizard/reference/makepredictcall.dw_transformer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility Function for Safe Prediction with datawizard transformers — makepredictcall.dw_transformer","text":"var variable. call term formula, call.","code":""},{"path":"https://easystats.github.io/datawizard/reference/makepredictcall.dw_transformer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility Function for Safe Prediction with datawizard transformers — makepredictcall.dw_transformer","text":"replacement call predvars attribute   terms.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/makepredictcall.dw_transformer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility Function for Safe Prediction with datawizard transformers — makepredictcall.dw_transformer","text":"","code":"data(\"mtcars\") train <- mtcars[1:30, ] test <- mtcars[31:32, ]  m1 <- lm(mpg ~ center(hp), data = train) predict(m1, newdata = test) # Data is \"centered\" before the prediction is made, #> Maserati Bora    Volvo 142E  #>      4.269496     22.911189  # according to the center of the old data  m2 <- lm(mpg ~ standardize(hp), data = train) m3 <- lm(mpg ~ scale(hp), data = train) # same as above predict(m2, newdata = test) # Data is \"standardized\" before the prediction is made. #> Maserati Bora    Volvo 142E  #>      4.269496     22.911189  predict(m3, newdata = test) # Data is \"standardized\" before the prediction is made. #> Maserati Bora    Volvo 142E  #>      4.269496     22.911189    m4 <- lm(mpg ~ normalize(hp), data = mtcars) m5 <- lm(mpg ~ rescale(hp, to = c(-3, 3)), data = mtcars)  (newdata <- data.frame(hp = c(range(mtcars$hp), 400))) # 400 is outside original range! #>    hp #> 1  52 #> 2 335 #> 3 400  model.frame(delete.response(terms(m4)), data = newdata) #>   normalize(hp) #> 1      0.000000 #> 2      1.000000 #> 3      1.229682 model.frame(delete.response(terms(m5)), data = newdata) #>   rescale(hp, to = c(-3, 3)) #> 1                  -3.000000 #> 2                   3.000000 #> 3                   4.378092"},{"path":"https://easystats.github.io/datawizard/reference/mean_sd.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Helpers — mean_sd","title":"Summary Helpers — mean_sd","text":"Summary Helpers","code":""},{"path":"https://easystats.github.io/datawizard/reference/mean_sd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Helpers — mean_sd","text":"","code":"mean_sd(x, times = 1L, remove_na = TRUE, named = TRUE, ...)  median_mad(   x,   times = 1L,   remove_na = TRUE,   constant = 1.4826,   named = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/mean_sd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Helpers — mean_sd","text":"x numeric vector (one can coerced one via .numeric()) summarized. times many SDs Mean (MADs around Median) remove_na Logical. NA values removed computing (TRUE) (FALSE, default)? named vector named? (E.g., c(\"-SD\" = -1, Mean = 1, \"+SD\" = 2).) ... used. constant scale factor.","code":""},{"path":"https://easystats.github.io/datawizard/reference/mean_sd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Helpers — mean_sd","text":"(possibly named) numeric vector length 2*times + 1 SDs mean, mean, SDs mean (median MAD).","code":""},{"path":"https://easystats.github.io/datawizard/reference/mean_sd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Helpers — mean_sd","text":"","code":"mean_sd(mtcars$mpg) #>      -SD     Mean      +SD  #> 14.06368 20.09062 26.11757   mean_sd(mtcars$mpg, times = 2L) #>     -2 SD     -1 SD      Mean     +1 SD     +2 SD  #>  8.036729 14.063677 20.090625 26.117573 32.144521   median_mad(mtcars$mpg) #>     -MAD   Median     +MAD  #> 13.78851 19.20000 24.61149"},{"path":"https://easystats.github.io/datawizard/reference/means_by_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of mean values by group — means_by_group","title":"Summary of mean values by group — means_by_group","text":"Computes summary table means groups.","code":""},{"path":"https://easystats.github.io/datawizard/reference/means_by_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of mean values by group — means_by_group","text":"","code":"means_by_group(x, ...)  # S3 method for class 'numeric' means_by_group(x, by = NULL, ci = 0.95, weights = NULL, digits = NULL, ...)  # S3 method for class 'data.frame' means_by_group(   x,   select = NULL,   by = NULL,   ci = 0.95,   weights = NULL,   digits = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/means_by_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of mean values by group — means_by_group","text":"x vector data frame. ... Currently used x numeric vector, factor indicates group-classifying categories. x data frame, character string, naming variable x used grouping. Numeric vectors coerced factors. refer single variable. ci Level confidence interval mean estimates. Default 0.95. Use ci = NA suppress confidence intervals. weights x numeric vector, weights vector weights applied weight observations. x data frame, weights can also character string indicating name variable x used weighting. Default NULL, weights used. digits Optional scalar, indicating amount digits decimal point rounding estimates values. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/means_by_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of mean values by group — means_by_group","text":"data frame information mean summary statistics sub-group.","code":""},{"path":"https://easystats.github.io/datawizard/reference/means_by_group.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of mean values by group — means_by_group","text":"function comparable aggregate(x, , mean), provides information, including summary statistics One-Way-ANOVA using x dependent independent variable. emmeans::contrast() used get p-values sub-group. P-values indicate whether group-mean significantly different total mean.","code":""},{"path":"https://easystats.github.io/datawizard/reference/means_by_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of mean values by group — means_by_group","text":"","code":"data(efc) means_by_group(efc, \"c12hour\", \"e42dep\") #> # Mean of average number of hours of care per week by elder's dependency #>  #> Category             |   Mean |  N |    SD |           95% CI |      p #> ---------------------------------------------------------------------- #> independent          |  17.00 |  2 | 11.31 | [-68.46, 102.46] | 0.573  #> slightly dependent   |  34.25 |  4 | 29.97 | [-26.18,  94.68] | 0.626  #> moderately dependent |  52.75 | 28 | 51.83 | [ 29.91,  75.59] | > .999 #> severely dependent   | 106.97 | 63 | 65.88 | [ 91.74, 122.19] | 0.001  #> Total                |  86.46 | 97 | 66.40 |                  |        #>  #> Anova: R2=0.186; adj.R2=0.160; F=7.098; p<.001  data(iris) means_by_group(iris, \"Sepal.Width\", \"Species\") #> # Mean of Sepal.Width by Species #>  #> Category   | Mean |   N |   SD |       95% CI |      p #> ------------------------------------------------------ #> setosa     | 3.43 |  50 | 0.38 | [3.33, 3.52] | < .001 #> versicolor | 2.77 |  50 | 0.31 | [2.68, 2.86] | < .001 #> virginica  | 2.97 |  50 | 0.32 | [2.88, 3.07] | 0.035  #> Total      | 3.06 | 150 | 0.44 |              |        #>  #> Anova: R2=0.401; adj.R2=0.393; F=49.160; p<.001  # weighting efc$weight <- abs(rnorm(n = nrow(efc), mean = 1, sd = .5)) means_by_group(efc, \"c12hour\", \"e42dep\", weights = \"weight\") #> # Mean of average number of hours of care per week by elder's dependency #>  #> Category             |   Mean |  N |    SD |           95% CI |      p #> ---------------------------------------------------------------------- #> independent          |  17.86 |  3 | 11.31 | [-50.28,  86.00] | 0.417  #> slightly dependent   |  34.93 |  5 | 30.14 | [-17.67,  87.53] | 0.591  #> moderately dependent |  49.00 | 28 | 47.17 | [ 27.08,  70.93] | 0.841  #> severely dependent   | 105.33 | 58 | 66.80 | [ 90.13, 120.54] | < .001 #> Total                |  82.20 | 97 | 65.86 |                  |        #>  #> Anova: R2=0.211; adj.R2=0.186; F=8.288; p<.001"},{"path":"https://easystats.github.io/datawizard/reference/nhanes_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from the National Health and Nutrition Examination Survey — nhanes_sample","title":"Sample dataset from the National Health and Nutrition Examination Survey — nhanes_sample","text":"Selected variables National Health Nutrition Examination Survey used example Lumley (2010), Appendix E.","code":""},{"path":"https://easystats.github.io/datawizard/reference/nhanes_sample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample dataset from the National Health and Nutrition Examination Survey — nhanes_sample","text":"Lumley T (2010). Complex Surveys: guide analysis using R. Wiley","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize numeric variable to 0-1 range — normalize","title":"Normalize numeric variable to 0-1 range — normalize","text":"Performs normalization data, .e., scales variables range 0 - 1. special case rescale(). unnormalize() counterpart, works variables normalized normalize().","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize numeric variable to 0-1 range — normalize","text":"","code":"normalize(x, ...)  # S3 method for class 'numeric' normalize(x, include_bounds = TRUE, verbose = TRUE, ...)  # S3 method for class 'data.frame' normalize(   x,   select = NULL,   exclude = NULL,   include_bounds = TRUE,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  unnormalize(x, ...)  # S3 method for class 'numeric' unnormalize(x, verbose = TRUE, ...)  # S3 method for class 'data.frame' unnormalize(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'grouped_df' unnormalize(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize numeric variable to 0-1 range — normalize","text":"x numeric vector, (grouped) data frame, matrix. See 'Details'. ... Arguments passed methods. include_bounds Numeric logical. Using can useful case beta-regression, response variable allowed include zeros ones. TRUE, input normalized range includes zero one. FALSE, return value compressed, using Smithson Verkuilen's (2006) formula (x * (n - 1) + 0.5) / n, avoid zeros ones normalized variables. Else, numeric (e.g., 0.001), include_bounds defines \"distance\" lower upper bound, .e. normalized vectors rescaled range 0 + include_bounds 1 - include_bounds. verbose Toggle warnings messages . select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, standardized variables get new column names (suffix \"_z\") appended (column bind) x, thus returning original standardized variables. FALSE, original variables x overwritten standardized versions. character value, standardized variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize numeric variable to 0-1 range — normalize","text":"normalized object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize numeric variable to 0-1 range — normalize","text":"x matrix, normalization performed across values (column- row-wise). column-wise normalization, convert matrix data.frame. x grouped data frame (grouped_df), normalization performed separately group.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Normalize numeric variable to 0-1 range — normalize","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normalize numeric variable to 0-1 range — normalize","text":"Smithson M, Verkuilen J (2006). Better Lemon Squeezer? Maximum-Likelihood Regression Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54–71.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize numeric variable to 0-1 range — normalize","text":"","code":"normalize(c(0, 1, 5, -5, -2)) #> [1] 0.5 0.6 1.0 0.0 0.3 #> (original range = -5 to 5) #>  normalize(c(0, 1, 5, -5, -2), include_bounds = FALSE) #> [1] 0.50 0.58 0.90 0.10 0.34 #> (original range = -5 to 5) #>  # use a value defining the bounds normalize(c(0, 1, 5, -5, -2), include_bounds = .001) #> [1] 0.5000 0.5998 0.9990 0.0010 0.3004 #> (original range = -5 to 5) #>   head(normalize(trees)) #>        Girth     Height      Volume #> 1 0.00000000 0.29166667 0.001497006 #> 2 0.02439024 0.08333333 0.001497006 #> 3 0.04065041 0.00000000 0.000000000 #> 4 0.17886179 0.37500000 0.092814371 #> 5 0.19512195 0.75000000 0.128742515 #> 6 0.20325203 0.83333333 0.142215569"},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":null,"dir":"Reference","previous_headings":"","what":"(Signed) rank transformation — ranktransform","title":"(Signed) rank transformation — ranktransform","text":"Transform numeric values integers rank (.e., 1st smallest, 2nd smallest, 3rd smallest, etc.). Setting sign argument TRUE give signed ranks, ranking done according absolute size sign preserved (.e., 2, 1, -3, 4).","code":""},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Signed) rank transformation — ranktransform","text":"","code":"ranktransform(x, ...)  # S3 method for class 'numeric' ranktransform(   x,   sign = FALSE,   method = \"average\",   zeros = \"na\",   verbose = TRUE,   ... )  # S3 method for class 'data.frame' ranktransform(   x,   select = NULL,   exclude = NULL,   sign = FALSE,   method = \"average\",   ignore_case = FALSE,   regex = FALSE,   zeros = \"na\",   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Signed) rank transformation — ranktransform","text":"x Object. ... Arguments passed methods. sign Logical, TRUE, return signed ranks. method Treatment ties. Can one \"average\" (default), \"first\", \"last\", \"random\", \"max\" \"min\". See rank() details. zeros handle zeros. \"na\" (default), marked NA. \"signrank\", kept ranking marked zeros. used sign = TRUE. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Signed) rank transformation — ranktransform","text":"rank-transformed object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"(Signed) rank transformation — ranktransform","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Signed) rank transformation — ranktransform","text":"","code":"ranktransform(c(0, 1, 5, -5, -2)) #> [1] 3 4 5 1 2  # By default, zeros are converted to NA suppressWarnings(   ranktransform(c(0, 1, 5, -5, -2), sign = TRUE) ) #> [1]   NA  1.0  3.5 -3.5 -2.0 ranktransform(c(0, 1, 5, -5, -2), sign = TRUE, zeros = \"signrank\") #> [1]  0.0  2.0  4.5 -4.5 -3.0  head(ranktransform(trees)) #>   Girth Height Volume #> 1     1    6.0    2.5 #> 2     2    3.0    2.5 #> 3     3    1.0    1.0 #> 4     4    8.5    5.0 #> 5     5   25.5    7.0 #> 6     6   28.0    9.0"},{"path":"https://easystats.github.io/datawizard/reference/recode_into.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode values from one or more variables into a new variable — recode_into","title":"Recode values from one or more variables into a new variable — recode_into","text":"functions recodes values one variables new variable. convenient function avoid nested ifelse() statements, similar dplyr::case_when().","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_into.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode values from one or more variables into a new variable — recode_into","text":"","code":"recode_into(   ...,   data = NULL,   default = NA,   overwrite = TRUE,   preserve_na = FALSE,   verbose = TRUE )"},{"path":"https://easystats.github.io/datawizard/reference/recode_into.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode values from one or more variables into a new variable — recode_into","text":"... sequence two-sided formulas, left hand side (LHS) logical matching condition determines values match case. LHS formula also called \"recode pattern\" (e.g., messages). right hand side (RHS) indicates replacement value. data Optional, name data frame. can used avoid writing data name multiple times .... See 'Examples'. default Indicates default value chosen match formulas ... found. provided, NA used default value. overwrite Logical, TRUE (default) one recode pattern apply case, already recoded values overwritten subsequent recode patterns. FALSE, former recoded cases altered later recode patterns apply cases . warning message printed alert situations avoid unintentional recodings. preserve_na Logical, TRUE default NA, missing values original variable set back NA recoded variable (unless overwritten recode patterns). FALSE, missing values original variable recoded default. Setting preserve_na = TRUE prevents unintentional overwriting missing values default, means find valid values original data missing values. See 'Examples'. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_into.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode values from one or more variables into a new variable — recode_into","text":"vector recoded values.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_into.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode values from one or more variables into a new variable — recode_into","text":"","code":"x <- 1:30 recode_into(   x > 15 ~ \"a\",   x > 10 & x <= 15 ~ \"b\",   default = \"c\" ) #>  [1] \"c\" \"c\" \"c\" \"c\" \"c\" \"c\" \"c\" \"c\" \"c\" \"c\" \"b\" \"b\" \"b\" \"b\" \"b\" \"a\" \"a\" \"a\" \"a\" #> [20] \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\"  x <- 1:10 # default behaviour: second recode pattern \"x > 5\" overwrites # some of the formerly recoded cases from pattern \"x >= 3 & x <= 7\" recode_into(   x >= 3 & x <= 7 ~ 1,   x > 5 ~ 2,   default = 0,   verbose = FALSE ) #>  [1] 0 0 1 1 1 2 2 2 2 2  # setting \"overwrite = FALSE\" will not alter formerly recoded cases recode_into(   x >= 3 & x <= 7 ~ 1,   x > 5 ~ 2,   default = 0,   overwrite = FALSE,   verbose = FALSE ) #>  [1] 0 0 1 1 1 1 1 2 2 2  set.seed(123) d <- data.frame(   x = sample(1:5, 30, TRUE),   y = sample(letters[1:5], 30, TRUE),   stringsAsFactors = FALSE )  # from different variables into new vector recode_into(   d$x %in% 1:3 & d$y %in% c(\"a\", \"b\") ~ 1,   d$x > 3 ~ 2,   default = 0 ) #>  [1] 1 1 1 0 0 2 2 0 1 1 2 0 0 0 2 1 1 2 1 0 1 1 0 2 0 1 2 2 1 2  # no need to write name of data frame each time recode_into(   x %in% 1:3 & y %in% c(\"a\", \"b\") ~ 1,   x > 3 ~ 2,   data = d,   default = 0 ) #>  [1] 1 1 1 0 0 2 2 0 1 1 2 0 0 0 2 1 1 2 1 0 1 1 0 2 0 1 2 2 1 2  # handling of missing values d <- data.frame(   x = c(1, NA, 2, NA, 3, 4),   y = c(1, 11, 3, NA, 5, 6) ) # first NA in x is overwritten by valid value from y # we have no known value for second NA in x and y, # thus we get one NA in the result recode_into(   x <= 3 ~ 1,   y > 5 ~ 2,   data = d,   default = 0,   preserve_na = TRUE ) #> [1]  1  2  1 NA  1  2 # first NA in x is overwritten by valid value from y # default value is used for second NA recode_into(   x <= 3 ~ 1,   y > 5 ~ 2,   data = d,   default = 0,   preserve_na = FALSE ) #> Missing values in original variable are overwritten by default value. If #>   you want to preserve missing values, set `preserve_na = TRUE`. #> [1] 1 2 1 0 1 2"},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode old values of variables into new values — recode_values","title":"Recode old values of variables into new values — recode_values","text":"functions recodes old values new values can used recode numeric character vectors, factors.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode old values of variables into new values — recode_values","text":"","code":"recode_values(x, ...)  # S3 method for class 'numeric' recode_values(   x,   recode = NULL,   default = NULL,   preserve_na = TRUE,   verbose = TRUE,   ... )  # S3 method for class 'data.frame' recode_values(   x,   select = NULL,   exclude = NULL,   recode = NULL,   default = NULL,   preserve_na = TRUE,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode old values of variables into new values — recode_values","text":"x data frame, numeric character vector, factor. ... used. recode list named vectors, indicate recode pairs. names list-elements (.e. left-hand side) represent new values, values list-elements indicate original (old) values replaced. recoding numeric vectors, element names surrounded backticks. example, recode=list(`0`=1) recode 1 0 numeric vector. See also 'Examples' 'Details'. default Defines default value values match recode-pairs. Note , preserve_na=FALSE, missing values (NA) also captured default argument, thus also recoded specified value. See 'Examples' 'Details'. preserve_na Logical, TRUE, NA (missing values) preserved. overrides arguments, including default. Hence, preserve_na=TRUE, default longer convert NA specified default value. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode old values of variables into new values — recode_values","text":"x, old values replaced new values.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Recode old values of variables into new values — recode_values","text":"section describes pattern recode arguments, also provides shortcuts, particular recoding numeric values. Single values Single values either need wrapped backticks (case numeric values) \"\" (character factor levels). Example: recode=list(`0`=1,`1`=2) recode 1 0, 2 1. factors character vectors, example : recode=list(x=\"\",y=\"b\") (recode \"\" \"x\" \"b\" \"y\"). Multiple values Multiple values recoded new value can separated comma. Example: recode=list(`1`=c(1,4),`2`=c(2,3)) recode values 1 4 1, 2 3 2. also possible define  old values character string, like:  recode=list(`1`=\"1,4\",`2`=\"2,3\") factors character vectors, example : recode=list(x=c(\"\",\"b\"),y=c(\"c\",\"d\")). Value range Numeric value ranges can defined using :. Example: recode=list(`1`=1:3,`2`=4:6) recode values 1 3 1, 4 6 2. min max placeholder use minimum maximum value (numeric) variable. Useful, e.g., recoding ranges values. Example: recode=list(`1`=\"min:10\",`2`=\"11:max\"). default values default argument defines default value values match recode-pairs. example, recode=list(`1`=c(1,2),`2`=c(3,4)), default=9 recode values 1 2 1, 3 4 2, values 9. preserve_na set FALSE, NA (missing values) also recoded specified default value. Reversing rescaling See reverse() rescale().","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Recode old values of variables into new values — recode_values","text":"can use options(data_recode_pattern = \"old=new\") switch behaviour recode-argument, .e. recode-pairs now following pattern old values = new values, e.g. getOption(\"data_recode_pattern\") set \"old=new\", recode(`1`=0) recode 1 0. default recode(`1`=0) recode 0 1.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Recode old values of variables into new values — recode_values","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode old values of variables into new values — recode_values","text":"","code":"# numeric ---------- set.seed(123) x <- sample(c(1:4, NA), 15, TRUE) table(x, useNA = \"always\") #> x #>    1    2    3    4 <NA>  #>    2    3    6    2    2   out <- recode_values(x, list(`0` = 1, `1` = 2:3, `2` = 4)) out #>  [1]  1  1  1  1  1 NA  2  0  1  1 NA  1  1  0  2 table(out, useNA = \"always\") #> out #>    0    1    2 <NA>  #>    2    9    2    2   # to recode NA values, set preserve_na to FALSE out <- recode_values(   x,   list(`0` = 1, `1` = 2:3, `2` = 4, `9` = NA),   preserve_na = FALSE ) out #>  [1] 1 1 1 1 1 9 2 0 1 1 9 1 1 0 2 table(out, useNA = \"always\") #> out #>    0    1    2    9 <NA>  #>    2    9    2    2    0   # preserve na ---------- out <- recode_values(x, list(`0` = 1, `1` = 2:3), default = 77) out #>  [1]  1  1  1  1  1 NA 77  0  1  1 NA  1  1  0 77 table(out, useNA = \"always\") #> out #>    0    1   77 <NA>  #>    2    9    2    2   # recode na into default ---------- out <- recode_values(   x,   list(`0` = 1, `1` = 2:3),   default = 77,   preserve_na = FALSE ) out #>  [1]  1  1  1  1  1 77 77  0  1  1 77  1  1  0 77 table(out, useNA = \"always\") #> out #>    0    1   77 <NA>  #>    2    9    4    0    # factors (character vectors are similar) ---------- set.seed(123) x <- as.factor(sample(c(\"a\", \"b\", \"c\"), 15, TRUE)) table(x) #> x #> a b c  #> 2 7 6   out <- recode_values(x, list(x = \"a\", y = c(\"b\", \"c\"))) out #>  [1] y y y y y y y y y x y y x y y #> Levels: x y table(out) #> out #>  x  y  #>  2 13   out <- recode_values(x, list(x = \"a\", y = \"b\", z = \"c\")) out #>  [1] z z z y z y y y z x y y x y z #> Levels: x y z table(out) #> out #> x y z  #> 2 7 6   out <- recode_values(x, list(y = \"b,c\"), default = 77) # same as # recode_values(x, list(y = c(\"b\", \"c\")), default = 77) out #>  [1] y  y  y  y  y  y  y  y  y  77 y  y  77 y  y  #> Levels: 77 y table(out) #> out #> 77  y  #>  2 13    # data frames ---------- set.seed(123) d <- data.frame(   x = sample(c(1:4, NA), 12, TRUE),   y = as.factor(sample(c(\"a\", \"b\", \"c\"), 12, TRUE)),   stringsAsFactors = FALSE )  recode_values(   d,   recode = list(`0` = 1, `1` = 2:3, `2` = 4, x = \"a\", y = c(\"b\", \"c\")),   append = TRUE ) #>     x y x_r y_r #> 1   3 c   1   y #> 2   3 a   1   x #> 3   2 a   1   x #> 4   2 a   1   x #> 5   3 a   1   x #> 6  NA c  NA   y #> 7   4 b   2   y #> 8   1 c   0   y #> 9   2 b   1   y #> 10  3 a   1   x #> 11 NA b  NA   y #> 12  3 c   1   y   # switch recode pattern to \"old=new\" ---------- options(data_recode_pattern = \"old=new\")  # numeric set.seed(123) x <- sample(c(1:4, NA), 15, TRUE) table(x, useNA = \"always\") #> x #>    1    2    3    4 <NA>  #>    2    3    6    2    2   out <- recode_values(x, list(`1` = 0, `2:3` = 1, `4` = 2)) table(out, useNA = \"always\") #> out #>    0    1    2 <NA>  #>    2    9    2    2   # factors (character vectors are similar) set.seed(123) x <- as.factor(sample(c(\"a\", \"b\", \"c\"), 15, TRUE)) table(x) #> x #> a b c  #> 2 7 6   out <- recode_values(x, list(a = \"x\", `b, c` = \"y\")) table(out) #> out #>  x  y  #>  2 13   # reset options options(data_recode_pattern = NULL)"},{"path":"https://easystats.github.io/datawizard/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. insight display, print_html, print_md","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":null,"dir":"Reference","previous_headings":"","what":"Return or remove variables or observations that are completely missing — remove_empty","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"functions check rows columns data frame completely contain missing values, .e. observations variables completely missing values, either (1) returns indices; (2) removes data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"","code":"empty_columns(x)  empty_rows(x)  remove_empty_columns(x)  remove_empty_rows(x)  remove_empty(x)"},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"x data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"empty_columns() empty_rows(), numeric (named) vector row column indices variables completely missing values. remove_empty_columns() remove_empty_rows(), data frame \"empty\" columns rows removed, respectively. remove_empty(), empty rows columns removed.","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"character vectors, empty string values (.e. \"\") also considered missing value. Thus, character vector contains NA \"\", considered empty variable removed. applies observations (rows) contain NA \"\".","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"","code":"tmp <- data.frame(   a = c(1, 2, 3, NA, 5),   b = c(1, NA, 3, NA, 5),   c = c(NA, NA, NA, NA, NA),   d = c(1, NA, 3, NA, 5) )  tmp #>    a  b  c  d #> 1  1  1 NA  1 #> 2  2 NA NA NA #> 3  3  3 NA  3 #> 4 NA NA NA NA #> 5  5  5 NA  5  # indices of empty columns or rows empty_columns(tmp) #> c  #> 3  empty_rows(tmp) #> [1] 4  # remove empty columns or rows remove_empty_columns(tmp) #>    a  b  d #> 1  1  1  1 #> 2  2 NA NA #> 3  3  3  3 #> 4 NA NA NA #> 5  5  5  5 remove_empty_rows(tmp) #>   a  b  c  d #> 1 1  1 NA  1 #> 2 2 NA NA NA #> 3 3  3 NA  3 #> 5 5  5 NA  5  # remove empty columns and rows remove_empty(tmp) #>   a  b  d #> 1 1  1  1 #> 2 2 NA NA #> 3 3  3  3 #> 5 5  5  5  # also remove \"empty\" character vectors tmp <- data.frame(   a = c(1, 2, 3, NA, 5),   b = c(1, NA, 3, NA, 5),   c = c(\"\", \"\", \"\", \"\", \"\"),   stringsAsFactors = FALSE ) empty_columns(tmp) #> c  #> 3"},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert infinite or NaN values into NA — replace_nan_inf","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"Replaces infinite (Inf -Inf) NaN values NA.","code":""},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"","code":"replace_nan_inf(x, ...)"},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"x vector dataframe ... Currently used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"Data Inf, -Inf, NaN converted NA.","code":""},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"","code":"# a vector x <- c(1, 2, NA, 3, NaN, 4, NA, 5, Inf, -Inf, 6, 7) replace_nan_inf(x) #>  [1]  1  2 NA  3 NA  4 NA  5 NA NA  6  7  # a data frame df <- data.frame(   x = c(1, NA, 5, Inf, 2, NA),   y = c(3, NaN, 4, -Inf, 6, 7),   stringsAsFactors = FALSE ) replace_nan_inf(df) #>    x  y #> 1  1  3 #> 2 NA NA #> 3  5  4 #> 4 NA NA #> 5  2  6 #> 6 NA  7"},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale Variables to a New Range — rescale","title":"Rescale Variables to a New Range — rescale","text":"Rescale variables new range. Can also used reverse-score variables (change keying/scoring direction), expand range.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale Variables to a New Range — rescale","text":"","code":"rescale(x, ...)  change_scale(x, ...)  # S3 method for class 'numeric' rescale(   x,   to = c(0, 100),   multiply = NULL,   add = NULL,   range = NULL,   verbose = TRUE,   ... )  # S3 method for class 'data.frame' rescale(   x,   select = NULL,   exclude = NULL,   to = c(0, 100),   multiply = NULL,   add = NULL,   range = NULL,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale Variables to a New Range — rescale","text":"x (grouped) data frame, numeric vector factor. ... Arguments passed methods. Numeric vector length 2 giving new range variable rescaling. reverse-score variable, range given maximum value first. See examples. multiply NULL, ignored multiply used, giving factor actual range x expanded. example, vector ranges 5 15 multiply = 1.1, current range 10 expanded factor 1.1, giving new range 11. Thus, rescaled vector range 4.5 15.5. add vector length 1 2. NULL, ignored add used, giving amount minimum maximum actual range x expanded. example, vector ranges 5 15 add = 1, range expanded 4 16. add length 2, first value used lower bound second value upper bound. range Initial (old) range values. NULL, take range input vector (range(x)). verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale Variables to a New Range — rescale","text":"rescaled object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Rescale Variables to a New Range — rescale","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale Variables to a New Range — rescale","text":"","code":"rescale(c(0, 1, 5, -5, -2)) #> [1]  50  60 100   0  30 #> (original range = -5 to 5) #>  rescale(c(0, 1, 5, -5, -2), to = c(-5, 5)) #> [1]  0  1  5 -5 -2 #> (original range = -5 to 5) #>  rescale(c(1, 2, 3, 4, 5), to = c(-2, 2)) #> [1] -2 -1  0  1  2 #> (original range = 1 to 5) #>   # Specify the \"theoretical\" range of the input vector rescale(c(1, 3, 4), to = c(0, 40), range = c(0, 4)) #> [1] 10 30 40 #> (original range = 0 to 4) #>   # Reverse-score a variable rescale(c(1, 2, 3, 4, 5), to = c(5, 1)) #> [1] 5 4 3 2 1 #> (original range = 1 to 5) #>  rescale(c(1, 2, 3, 4, 5), to = c(2, -2)) #> [1]  2  1  0 -1 -2 #> (original range = 1 to 5) #>   # Data frames head(rescale(iris, to = c(0, 1))) #> Variables of class `factor` can't be rescaled and remain unchanged. #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1   0.22222222   0.6250000   0.06779661  0.04166667  setosa #> 2   0.16666667   0.4166667   0.06779661  0.04166667  setosa #> 3   0.11111111   0.5000000   0.05084746  0.04166667  setosa #> 4   0.08333333   0.4583333   0.08474576  0.04166667  setosa #> 5   0.19444444   0.6666667   0.06779661  0.04166667  setosa #> 6   0.30555556   0.7916667   0.11864407  0.12500000  setosa head(rescale(iris, to = c(0, 1), select = \"Sepal.Length\")) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1   0.22222222         3.5          1.4         0.2  setosa #> 2   0.16666667         3.0          1.4         0.2  setosa #> 3   0.11111111         3.2          1.3         0.2  setosa #> 4   0.08333333         3.1          1.5         0.2  setosa #> 5   0.19444444         3.6          1.4         0.2  setosa #> 6   0.30555556         3.9          1.7         0.4  setosa  # One can specify a list of ranges head(rescale(iris, to = list(   \"Sepal.Length\" = c(0, 1),   \"Petal.Length\" = c(-1, 0) ))) #> Variables of class `factor` can't be rescaled and remain unchanged. #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1   0.22222222         3.5   -0.9322034         0.2  setosa #> 2   0.16666667         3.0   -0.9322034         0.2  setosa #> 3   0.11111111         3.2   -0.9491525         0.2  setosa #> 4   0.08333333         3.1   -0.9152542         0.2  setosa #> 5   0.19444444         3.6   -0.9322034         0.2  setosa #> 6   0.30555556         3.9   -0.8813559         0.4  setosa  # \"expand\" ranges by a factor or a given value x <- 5:15 x #>  [1]  5  6  7  8  9 10 11 12 13 14 15 # both will expand the range by 10% rescale(x, multiply = 1.1) #>  [1]  4.5  5.6  6.7  7.8  8.9 10.0 11.1 12.2 13.3 14.4 15.5 #> (original range = 5 to 15) #>  rescale(x, add = 0.5) #>  [1]  4.5  5.6  6.7  7.8  8.9 10.0 11.1 12.2 13.3 14.4 15.5 #> (original range = 5 to 15) #>   # expand range by different values rescale(x, add = c(1, 3)) #>  [1]  4.0  5.4  6.8  8.2  9.6 11.0 12.4 13.8 15.2 16.6 18.0 #> (original range = 5 to 15) #>   # Specify list of multipliers d <- data.frame(x = 5:15, y = 5:15) rescale(d, multiply = list(x = 1.1, y = 0.5)) #>       x    y #> 1   4.5  7.5 #> 2   5.6  8.0 #> 3   6.7  8.5 #> 4   7.8  9.0 #> 5   8.9  9.5 #> 6  10.0 10.0 #> 7  11.1 10.5 #> 8  12.2 11.0 #> 9  13.3 11.5 #> 10 14.4 12.0 #> 11 15.5 12.5"},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale design weights for multilevel analysis — rescale_weights","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"functions fit multilevel mixed effects models allow user specify frequency weights, design (.e., sampling probability) weights, used analyzing complex samples (e.g., probability samples). rescale_weights() implements two algorithms, one proposed Asparouhov (2006) Carle (2009), rescale design weights survey data account grouping structure multilevel models, one based design effect proposed Kish (1965), rescale weights design effect account additional sampling error introduced weighting.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"","code":"rescale_weights(   data,   probability_weights = NULL,   by = NULL,   nest = FALSE,   method = \"carle\" )"},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"data data frame. probability_weights Variable indicating probability (design sampling) weights survey data (level-1-weight), provided character string formula. Variable names (character vector, formula), indicating grouping structure (strata) survey data (level-2-cluster variable). also possible create weights multiple group variables; cases, created weighting variable suffixed name group variable. argument required method = \"carle\", optional method = \"kish\". nest Logical, TRUE indicates least two group variables, groups \"nested\", .e. groups now combination group level variables . argument used method = \"kish\". method String, indicating rescale-method used rescaling weights. Can either \"carle\" (default) \"kish\". See 'Details'. method = \"carle\", argument required.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"data, including new weighting variable(s). method = \"carle\", new columns rescaled_weights_a rescaled_weights_b returned, method = \"kish\", returned data contains column rescaled_weights. represent rescaled design weights use multilevel models (use variables weights argument).","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"method = \"carle\" Rescaling based two methods: rescaled_weights_a, sample weights probability_weights adjusted factor represents proportion group size divided sum sampling weights within group. adjustment factor rescaled_weights_b sum sample weights within group divided sum squared sample weights within group (see Carle (2009), Appendix B). words, rescaled_weights_a \"scales weights new weights sum cluster sample size\" rescaled_weights_b \"scales weights new weights sum effective cluster size\". Regarding choice scaling methods B, Carle suggests \"analysts wish discuss point estimates report results based weighting method . analysts interested residual -group variance, method B may generally provide least biased estimates\". general, recommended fit non-weighted model weighted models scaling methods comparing models, see whether \"inferential decisions converge\", gain confidence results. Though bias scaled weights decreases increasing group size, method preferred insufficient low group size concern. group ID probably PSU may used random effects (e.g. nested design, group PSU varying intercepts), depending survey design mimicked. method = \"kish\" Rescaling based scaling sample weights mean value 1, means sum weights equals sample size. Next, design effect (Kish 1965) calculated, mean squared weights divided squared mean weights. scaled sample weights divided design effect. method appropriate weights based additional variables beyond grouping variables model (e.g., demographic characteristics), may also useful contexts. tests real-world survey-data suggest , comparison Carle-method, Kish-method comes closer estimates regular survey-design using survey package. Note tests representative recommended check results standard survey-design.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"Asparouhov T. (2006). General Multi-Level Modeling Sampling Weights. Communications Statistics - Theory Methods 35: 439-460 Carle .C. (2009). Fitting multilevel models complex survey data design weights: Recommendations. BMC Medical Research Methodology 9(49): 1-13 Kish, L. (1965) Survey Sampling. London: Wiley.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"","code":"data(nhanes_sample) head(rescale_weights(nhanes_sample, \"WTINT2YR\", \"SDMVSTRA\")) #>   total  age RIAGENDR RIDRETH1 SDMVPSU SDMVSTRA WTINT2YR rescaled_weights_a #> 1     1 2.20        1        3       2       31 97593.68          1.5733612 #> 2     7 2.08        2        3       1       29 39599.36          0.6231745 #> 3     3 1.48        2        1       2       42 26619.83          0.8976966 #> 4     4 1.32        2        4       2       33 34998.53          0.7083628 #> 5     1 2.00        2        1       1       41 14746.45          0.4217782 #> 6     6 2.20        2        4       1       38 28232.10          0.6877550 #>   rescaled_weights_b #> 1          1.2005159 #> 2          0.5246593 #> 3          0.5439111 #> 4          0.5498944 #> 5          0.3119698 #> 6          0.5155503  # also works with multiple group-variables head(rescale_weights(nhanes_sample, \"WTINT2YR\", c(\"SDMVSTRA\", \"SDMVPSU\"))) #>   total  age RIAGENDR RIDRETH1 SDMVPSU SDMVSTRA WTINT2YR pweight_a_SDMVSTRA #> 1     1 2.20        1        3       2       31 97593.68          1.5733612 #> 2     7 2.08        2        3       1       29 39599.36          0.6231745 #> 3     3 1.48        2        1       2       42 26619.83          0.8976966 #> 4     4 1.32        2        4       2       33 34998.53          0.7083628 #> 5     1 2.00        2        1       1       41 14746.45          0.4217782 #> 6     6 2.20        2        4       1       38 28232.10          0.6877550 #>   pweight_b_SDMVSTRA pweight_a_SDMVPSU pweight_b_SDMVPSU #> 1          1.2005159         1.8458164         1.3699952 #> 2          0.5246593         0.8217570         0.5780808 #> 3          0.5439111         0.5034683         0.3736824 #> 4          0.5498944         0.6619369         0.4913004 #> 5          0.3119698         0.3060151         0.2152722 #> 6          0.5155503         0.5858662         0.4121388  # or nested structures. x <- rescale_weights(   data = nhanes_sample,   probability_weights = \"WTINT2YR\",   by = c(\"SDMVSTRA\", \"SDMVPSU\"),   nest = TRUE ) head(x) #>   total  age RIAGENDR RIDRETH1 SDMVPSU SDMVSTRA WTINT2YR rescaled_weights_a #> 1     1 2.20        1        3       2       31 97593.68          1.6532834 #> 2     7 2.08        2        3       1       29 39599.36          0.5492655 #> 3     3 1.48        2        1       2       42 26619.83          0.8341084 #> 4     4 1.32        2        4       2       33 34998.53          0.7937824 #> 5     1 2.00        2        1       1       41 14746.45          0.4285939 #> 6     6 2.20        2        4       1       38 28232.10          0.6215579 #>   rescaled_weights_b #> 1          1.3583967 #> 2          0.4875798 #> 3          0.5891700 #> 4          0.5941006 #> 5          0.3068214 #> 6          0.4759935  # \\donttest{ # compare different methods, using multilevel-Poisson regression  d <- rescale_weights(nhanes_sample, \"WTINT2YR\", \"SDMVSTRA\") result1 <- lme4::glmer(   total ~ factor(RIAGENDR) + log(age) + factor(RIDRETH1) + (1 | SDMVPSU),   family = poisson(),   data = d,   weights = rescaled_weights_a ) result2 <- lme4::glmer(   total ~ factor(RIAGENDR) + log(age) + factor(RIDRETH1) + (1 | SDMVPSU),   family = poisson(),   data = d,   weights = rescaled_weights_b )  d <- rescale_weights(   nhanes_sample,   \"WTINT2YR\",   method = \"kish\" ) result3 <- lme4::glmer(   total ~ factor(RIAGENDR) + log(age) + factor(RIDRETH1) + (1 | SDMVPSU),   family = poisson(),   data = d,   weights = rescaled_weights ) d <- rescale_weights(   nhanes_sample,   \"WTINT2YR\",   \"SDMVSTRA\",   method = \"kish\" ) result4 <- lme4::glmer(   total ~ factor(RIAGENDR) + log(age) + factor(RIDRETH1) + (1 | SDMVPSU),   family = poisson(),   data = d,   weights = rescaled_weights ) parameters::compare_parameters(   list(result1, result2, result3, result4),   exponentiate = TRUE,   column_names = c(\"Carle (A)\", \"Carle (B)\", \"Kish\", \"Kish (grouped)\") ) #> Number of weighted observations differs from number of unweighted #>   observations. #> Parameter    |            Carle (A) |            Carle (B) #> ---------------------------------------------------------- #> (Intercept)  | 12.20 (10.52, 14.14) | 11.95 (10.27, 13.92) #> RIAGENDR [2] |  0.41 ( 0.40,  0.42) |  0.42 ( 0.40,  0.43) #> age [log]    |  1.69 ( 1.63,  1.75) |  1.66 ( 1.60,  1.73) #> RIDRETH1 [2] |  0.90 ( 0.84,  0.97) |  0.90 ( 0.83,  0.98) #> RIDRETH1 [3] |  1.19 ( 1.14,  1.24) |  1.21 ( 1.16,  1.27) #> RIDRETH1 [4] |  2.16 ( 2.07,  2.26) |  2.16 ( 2.06,  2.28) #> RIDRETH1 [5] |  1.01 ( 0.95,  1.07) |  1.05 ( 0.97,  1.12) #> ---------------------------------------------------------- #> Observations |                 2617 |                 1965 #>  #> Parameter    |                Kish |       Kish (grouped) #> --------------------------------------------------------- #> (Intercept)  | 11.72 (9.89, 13.87) | 11.95 (10.27, 13.92) #> RIAGENDR [2] |  0.42 (0.41,  0.43) |  0.42 ( 0.40,  0.43) #> age [log]    |  1.66 (1.59,  1.73) |  1.66 ( 1.60,  1.73) #> RIDRETH1 [2] |  0.98 (0.90,  1.07) |  0.90 ( 0.83,  0.98) #> RIDRETH1 [3] |  1.23 (1.17,  1.29) |  1.21 ( 1.16,  1.27) #> RIDRETH1 [4] |  2.11 (1.99,  2.23) |  2.16 ( 2.06,  2.28) #> RIDRETH1 [5] |  1.09 (1.01,  1.18) |  1.05 ( 0.97,  1.12) #> --------------------------------------------------------- #> Observations |                1903 |                 1965 # }"},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape CI between wide/long formats — reshape_ci","title":"Reshape CI between wide/long formats — reshape_ci","text":"Reshape CI wide/long formats.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape CI between wide/long formats — reshape_ci","text":"","code":"reshape_ci(x, ci_type = \"CI\")"},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape CI between wide/long formats — reshape_ci","text":"x data frame containing columns named CI_low CI_high (similar, see ci_type). ci_type String indicating \"type\" (.e. prefix) interval columns. Per easystats convention, confidence credible intervals named CI_low CI_high, related ci_type \"CI\". column names intervals differ, ci_type can used indicate name, e.g. ci_type = \"SI\" can used support intervals, column names data frame SI_low SI_high.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape CI between wide/long formats — reshape_ci","text":"data frame columns corresponding confidence intervals reshaped either wide long format.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape CI between wide/long formats — reshape_ci","text":"","code":"x <- data.frame(   Parameter = c(\"Term 1\", \"Term 2\", \"Term 1\", \"Term 2\"),   CI = c(.8, .8, .9, .9),   CI_low = c(.2, .3, .1, .15),   CI_high = c(.5, .6, .8, .85),   stringsAsFactors = FALSE )  reshape_ci(x) #>   Parameter CI_low_0.8 CI_high_0.8 CI_low_0.9 CI_high_0.9 #> 1    Term 1        0.2         0.5       0.10        0.80 #> 2    Term 2        0.3         0.6       0.15        0.85 reshape_ci(reshape_ci(x)) #>   Parameter  CI CI_low CI_high #> 1    Term 1 0.8   0.20    0.50 #> 2    Term 1 0.9   0.10    0.80 #> 3    Term 2 0.8   0.30    0.60 #> 4    Term 2 0.9   0.15    0.85"},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse-Score Variables — reverse","title":"Reverse-Score Variables — reverse","text":"Reverse-score variables (change keying/scoring direction).","code":""},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse-Score Variables — reverse","text":"","code":"reverse(x, ...)  reverse_scale(x, ...)  # S3 method for class 'numeric' reverse(x, range = NULL, verbose = TRUE, ...)  # S3 method for class 'data.frame' reverse(   x,   select = NULL,   exclude = NULL,   range = NULL,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse-Score Variables — reverse","text":"x (grouped) data frame, numeric vector factor. ... Arguments passed methods. range Range values used reference reversing scale. numeric variables, can NULL numeric vector length two, indicating lowest highest value reference range. NULL, take range input vector (range(x)). factors, range can NULL, numeric vector length two, (numeric) vector least length factor levels (.e. must equal larger nlevels(x)). Note providing range factors usually makes sense factor levels numeric, characters. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse-Score Variables — reverse","text":"reverse-scored object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Reverse-Score Variables — reverse","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reverse-Score Variables — reverse","text":"","code":"reverse(c(1, 2, 3, 4, 5)) #> [1] 5 4 3 2 1 reverse(c(-2, -1, 0, 2, 1)) #> [1]  2  1  0 -2 -1  # Specify the \"theoretical\" range of the input vector reverse(c(1, 3, 4), range = c(0, 4)) #> [1] 3 1 0  # Factor variables reverse(factor(c(1, 2, 3, 4, 5))) #> [1] 5 4 3 2 1 #> Levels: 1 2 3 4 5 reverse(factor(c(1, 2, 3, 4, 5)), range = 0:10) #> [1] 9 8 7 6 5 #> Levels: 0 1 2 3 4 5 6 7 8 9 10  # Data frames head(reverse(iris)) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species #> 1          7.1         2.9          6.5         2.4 virginica #> 2          7.3         3.4          6.5         2.4 virginica #> 3          7.5         3.2          6.6         2.4 virginica #> 4          7.6         3.3          6.4         2.4 virginica #> 5          7.2         2.8          6.5         2.4 virginica #> 6          6.8         2.5          6.2         2.2 virginica head(reverse(iris, select = \"Sepal.Length\")) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          7.1         3.5          1.4         0.2  setosa #> 2          7.3         3.0          1.4         0.2  setosa #> 3          7.5         3.2          1.3         0.2  setosa #> 4          7.6         3.1          1.5         0.2  setosa #> 5          7.2         3.6          1.4         0.2  setosa #> 6          6.8         3.9          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/reference/row_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Count specific values row-wise — row_count","title":"Count specific values row-wise — row_count","text":"row_count() mimics base R's rowSums(), sums specific value indicated count. Hence, similar rowSums(x == count, na.rm = TRUE), offers options, including strict comparisons. Comparisons using == coerce values atomic vectors, thus 2 == 2 \"2\" == 2 TRUE. row_count(), also possible make \"type safe\" comparisons using allow_coercion argument, \"2\" == 2 true.","code":""},{"path":"https://easystats.github.io/datawizard/reference/row_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count specific values row-wise — row_count","text":"","code":"row_count(   data,   select = NULL,   exclude = NULL,   count = NULL,   allow_coercion = TRUE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE )"},{"path":"https://easystats.github.io/datawizard/reference/row_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count specific values row-wise — row_count","text":"data data frame least two columns, number specific values counted row-wise. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. count value row sum computed. May numeric value, character string (factors character vectors), NA Inf. allow_coercion Logical. FALSE, count matches values class (.e. count = 2, value \"2\" counted vice versa). default, allow_coercion = TRUE, count = 2 also matches \"2\". order count factor levels data, use count = factor(\"level\"). See 'Examples'. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/row_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count specific values row-wise — row_count","text":"vector row-wise counts values specified count.","code":""},{"path":"https://easystats.github.io/datawizard/reference/row_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count specific values row-wise — row_count","text":"","code":"dat <- data.frame(   c1 = c(1, 2, NA, 4),   c2 = c(NA, 2, NA, 5),   c3 = c(NA, 4, NA, NA),   c4 = c(2, 3, 7, 8) )  # count all 4s per row row_count(dat, count = 4) #> [1] 0 1 0 1 # count all missing values per row row_count(dat, count = NA) #> [1] 2 0 3 1  dat <- data.frame(   c1 = c(\"1\", \"2\", NA, \"3\"),   c2 = c(NA, \"2\", NA, \"3\"),   c3 = c(NA, 4, NA, NA),   c4 = c(2, 3, 7, Inf) ) # count all 2s and \"2\"s per row row_count(dat, count = 2) #> [1] 1 2 0 0 # only count 2s, but not \"2\"s row_count(dat, count = 2, allow_coercion = FALSE) #> [1] 1 0 0 0  dat <- data.frame(   c1 = factor(c(\"1\", \"2\", NA, \"3\")),   c2 = c(\"2\", \"1\", NA, \"3\"),   c3 = c(NA, 4, NA, NA),   c4 = c(2, 3, 7, Inf) ) # find only character \"2\"s row_count(dat, count = \"2\", allow_coercion = FALSE) #> [1] 1 0 0 0 # find only factor level \"2\"s row_count(dat, count = factor(\"2\"), allow_coercion = FALSE) #> [1] 0 1 0 0"},{"path":"https://easystats.github.io/datawizard/reference/row_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Row means or sums (optionally with minimum amount of valid values) — row_means","title":"Row means or sums (optionally with minimum amount of valid values) — row_means","text":"function similar SPSS MEAN.n SUM.n function computes row means row sums data frame matrix least min_valid values row valid (NA).","code":""},{"path":"https://easystats.github.io/datawizard/reference/row_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row means or sums (optionally with minimum amount of valid values) — row_means","text":"","code":"row_means(   data,   select = NULL,   exclude = NULL,   min_valid = NULL,   digits = NULL,   ignore_case = FALSE,   regex = FALSE,   remove_na = FALSE,   verbose = TRUE )  row_sums(   data,   select = NULL,   exclude = NULL,   min_valid = NULL,   digits = NULL,   ignore_case = FALSE,   regex = FALSE,   remove_na = FALSE,   verbose = TRUE )"},{"path":"https://easystats.github.io/datawizard/reference/row_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row means or sums (optionally with minimum amount of valid values) — row_means","text":"data data frame least two columns, row means row sums applied. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. min_valid Optional, numeric value length 1. May either numeric value indicates amount valid values per row calculate row mean row sum; value 0 1, indicating proportion valid values per row calculate row mean row sum (see 'Details'). NULL (default), cases considered. row's sum valid values less min_valid, NA returned. digits Numeric value indicating number decimal places used rounding mean values. Negative values allowed (see 'Details'). default, digits = NULL rounding used. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. remove_na Logical, TRUE (default), removes missing (NA) values calculating row means row sums. applies min_valid specified. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/row_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row means or sums (optionally with minimum amount of valid values) — row_means","text":"vector row means (row_means()) row sums (row_sums()) rows least n valid values.","code":""},{"path":"https://easystats.github.io/datawizard/reference/row_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Row means or sums (optionally with minimum amount of valid values) — row_means","text":"Rounding negative number digits means rounding power ten, example row_means(df, 3, digits = -2) rounds nearest hundred. min_valid, NULL, min_valid must numeric value 0 ncol(data). row data frame least min_valid non-missing values, row mean row sum returned. min_valid non-integer value 0 1, min_valid considered indicate proportion required non-missing values per row. E.g., min_valid = 0.75, row must least ncol(data) * min_valid non-missing values row mean row sum calculated. See 'Examples'.","code":""},{"path":"https://easystats.github.io/datawizard/reference/row_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row means or sums (optionally with minimum amount of valid values) — row_means","text":"","code":"dat <- data.frame(   c1 = c(1, 2, NA, 4),   c2 = c(NA, 2, NA, 5),   c3 = c(NA, 4, NA, NA),   c4 = c(2, 3, 7, 8) )  # default, all means are shown, if no NA values are present row_means(dat) #> [1]   NA 2.75   NA   NA  # remove all NA before computing row means row_means(dat, remove_na = TRUE) #> [1] 1.500000 2.750000 7.000000 5.666667  # needs at least 4 non-missing values per row row_means(dat, min_valid = 4) # 1 valid return value #> [1]   NA 2.75   NA   NA row_sums(dat, min_valid = 4) # 1 valid return value #> [1] NA 11 NA NA  # needs at least 3 non-missing values per row row_means(dat, min_valid = 3) # 2 valid return values #> [1]       NA 2.750000       NA 5.666667  # needs at least 2 non-missing values per row row_means(dat, min_valid = 2) #> [1] 1.500000 2.750000       NA 5.666667  # needs at least 1 non-missing value per row, for two selected variables row_means(dat, select = c(\"c1\", \"c3\"), min_valid = 1) #> [1]  1  3 NA  4  # needs at least 50% of non-missing values per row row_means(dat, min_valid = 0.5) # 3 valid return values #> [1] 1.500000 2.750000       NA 5.666667 row_sums(dat, min_valid = 0.5) #> [1]  3 11 NA 17  # needs at least 75% of non-missing values per row row_means(dat, min_valid = 0.75) # 2 valid return values #> [1]       NA 2.750000       NA 5.666667"},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for working with row names or row ids — rownames_as_column","title":"Tools for working with row names or row ids — rownames_as_column","text":"Tools working row names row ids","code":""},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for working with row names or row ids — rownames_as_column","text":"","code":"rownames_as_column(x, var = \"rowname\")  column_as_rownames(x, var = \"rowname\")  rowid_as_column(x, var = \"rowid\")"},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for working with row names or row ids — rownames_as_column","text":"x data frame. var Name column use row names/ids. column_as_rownames(), argument can variable name column number. rownames_as_column() rowid_as_column(), column name must already exist data.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for working with row names or row ids — rownames_as_column","text":"data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tools for working with row names or row ids — rownames_as_column","text":"similar tibble's functions column_to_rownames(), rownames_to_column() rowid_to_column(). Note behavior rowid_as_column() different grouped dataframe: instead making rowid unique across full dataframe, creates rowid per group. Therefore, can several rows rowid belong different groups. familiar dplyr, similar following:","code":"data |>   group_by(grp) |>   mutate(id = row_number()) |>   ungroup()"},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools for working with row names or row ids — rownames_as_column","text":"","code":"# Convert between row names and column -------------------------------- test <- rownames_as_column(mtcars, var = \"car\") test #>                    car  mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> 1            Mazda RX4 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> 2        Mazda RX4 Wag 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> 3           Datsun 710 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> 4       Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> 5    Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> 6              Valiant 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> 7           Duster 360 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> 8            Merc 240D 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> 9             Merc 230 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> 10            Merc 280 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> 11           Merc 280C 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> 12          Merc 450SE 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> 13          Merc 450SL 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> 14         Merc 450SLC 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> 15  Cadillac Fleetwood 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> 16 Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> 17   Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> 18            Fiat 128 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> 19         Honda Civic 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> 20      Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> 21       Toyota Corona 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> 22    Dodge Challenger 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> 23         AMC Javelin 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> 24          Camaro Z28 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> 25    Pontiac Firebird 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> 26           Fiat X1-9 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> 27       Porsche 914-2 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> 28        Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> 29      Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> 30        Ferrari Dino 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> 31       Maserati Bora 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> 32          Volvo 142E 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 head(column_as_rownames(test, var = \"car\")) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1  test_data <- head(iris)  rowid_as_column(test_data) #>   rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1     1          5.1         3.5          1.4         0.2  setosa #> 2     2          4.9         3.0          1.4         0.2  setosa #> 3     3          4.7         3.2          1.3         0.2  setosa #> 4     4          4.6         3.1          1.5         0.2  setosa #> 5     5          5.0         3.6          1.4         0.2  setosa #> 6     6          5.4         3.9          1.7         0.4  setosa rowid_as_column(test_data, var = \"my_id\") #>   my_id Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1     1          5.1         3.5          1.4         0.2  setosa #> 2     2          4.9         3.0          1.4         0.2  setosa #> 3     3          4.7         3.2          1.3         0.2  setosa #> 4     4          4.6         3.1          1.5         0.2  setosa #> 5     5          5.0         3.6          1.4         0.2  setosa #> 6     6          5.4         3.9          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Skewness and (Excess) Kurtosis — skewness","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"Compute Skewness (Excess) Kurtosis","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"","code":"skewness(x, ...)  # S3 method for class 'numeric' skewness(   x,   remove_na = TRUE,   type = \"2\",   iterations = NULL,   verbose = TRUE,   ... )  kurtosis(x, ...)  # S3 method for class 'numeric' kurtosis(   x,   remove_na = TRUE,   type = \"2\",   iterations = NULL,   verbose = TRUE,   ... )  # S3 method for class 'parameters_kurtosis' print(x, digits = 3, test = FALSE, ...)  # S3 method for class 'parameters_skewness' print(x, digits = 3, test = FALSE, ...)  # S3 method for class 'parameters_skewness' summary(object, test = FALSE, ...)  # S3 method for class 'parameters_kurtosis' summary(object, test = FALSE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"x numeric vector data.frame. ... Arguments passed methods. remove_na Logical. NA values removed computing (TRUE) (FALSE, default)? type Type algorithm computing skewness. May one 1 (\"1\", \"\" \"classic\"), 2 (\"2\", \"II\" \"SPSS\" \"SAS\") 3 ( \"3\", \"III\" \"Minitab\"). See 'Details'. iterations number bootstrap replicates computing standard errors. NULL (default), parametric standard errors computed. verbose Toggle warnings messages. digits Number decimal places. test Logical, TRUE, tests skewness kurtosis significantly different zero. object object returned skewness() kurtosis().","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"Values skewness kurtosis.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"skewness","dir":"Reference","previous_headings":"","what":"Skewness","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"Symmetric distributions skewness around zero, negative skewness values indicates \"left-skewed\" distribution, positive skewness values indicates \"right-skewed\" distribution. Examples relationship skewness distributions : Normal distribution (symmetric distribution) skewness 0 Half-normal distribution skewness just 1 Exponential distribution skewness 2 Lognormal distribution can skewness positive value, depending parameters (https://en.wikipedia.org/wiki/Skewness)","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"types-of-skewness","dir":"Reference","previous_headings":"","what":"Types of Skewness","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"skewness() supports three different methods estimating skewness, discussed Joanes Gill (1988): Type \"1\" \"classical\" method, g1 = (sum((x - mean(x))^3) / n) / (sum((x - mean(x))^2) / n)^1.5 Type \"2\" first calculates type-1 skewness, adjusts result: G1 = g1 * sqrt(n * (n - 1)) / (n - 2). SAS SPSS usually return. Type \"3\" first calculates type-1 skewness, adjusts result: b1 = g1 * ((1 - 1 / n))^1.5. Minitab usually returns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"kurtosis","dir":"Reference","previous_headings":"","what":"Kurtosis","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"kurtosis measure \"tailedness\" distribution. distribution kurtosis values zero called \"mesokurtic\". kurtosis value larger zero indicates \"leptokurtic\" distribution fatter tails. kurtosis value zero indicates \"platykurtic\" distribution thinner tails (https://en.wikipedia.org/wiki/Kurtosis).","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"types-of-kurtosis","dir":"Reference","previous_headings":"","what":"Types of Kurtosis","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"kurtosis() supports three different methods estimating kurtosis, discussed Joanes Gill (1988): Type \"1\" \"classical\" method, g2 = n * sum((x - mean(x))^4) / (sum((x - mean(x))^2)^2) - 3. Type \"2\" first calculates type-1 kurtosis, adjusts result: G2 = ((n + 1) * g2 + 6) * (n - 1)/((n - 2) * (n - 3)). SAS SPSS usually return Type \"3\" first calculates type-1 kurtosis, adjusts result: b2 = (g2 + 3) * (1 - 1 / n)^2 - 3. Minitab usually returns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"standard-errors","dir":"Reference","previous_headings":"","what":"Standard Errors","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"recommended compute empirical (bootstrapped) standard errors (via iterations argument) relying analytic standard errors (Wright & Herrington, 2011).","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"D. N. Joanes C. . Gill (1998). Comparing measures sample skewness kurtosis. Statistician, 47, 183–189. Wright, D. B., & Herrington, J. . (2011). Problematic standard errors confidence intervals skewness kurtosis. Behavior research methods, 43(1), 8-17.","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"","code":"skewness(rnorm(1000)) #> Skewness |    SE #> ---------------- #>    0.093 | 0.077 kurtosis(rnorm(1000)) #> Kurtosis |    SE #> ---------------- #>   -0.112 | 0.154"},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":null,"dir":"Reference","previous_headings":"","what":"Shift numeric value range — slide","title":"Shift numeric value range — slide","text":"functions shifts value range numeric variable, new range starts given value.","code":""},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shift numeric value range — slide","text":"","code":"slide(x, ...)  # S3 method for class 'numeric' slide(x, lowest = 0, ...)  # S3 method for class 'data.frame' slide(   x,   select = NULL,   exclude = NULL,   lowest = 0,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shift numeric value range — slide","text":"x data frame numeric vector. ... used. lowest Numeric, indicating lowest (minimum) value converting factors character vectors numeric values. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shift numeric value range — slide","text":"x, range numeric variables starts new value.","code":""},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Shift numeric value range — slide","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shift numeric value range — slide","text":"","code":"# numeric head(mtcars$gear) #> [1] 4 4 4 3 3 3 head(slide(mtcars$gear)) #> [1] 1 1 1 0 0 0 head(slide(mtcars$gear, lowest = 10)) #> [1] 11 11 11 10 10 10  # data frame sapply(slide(mtcars, lowest = 1), min) #>  mpg  cyl disp   hp drat   wt qsec   vs   am gear carb  #>    1    1    1    1    1    1    1    1    1    1    1  sapply(mtcars, min) #>    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb  #> 10.400  4.000 71.100 52.000  2.760  1.513 14.500  0.000  0.000  3.000  1.000"},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantify the smoothness of a vector — smoothness","title":"Quantify the smoothness of a vector — smoothness","text":"Quantify smoothness vector","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantify the smoothness of a vector — smoothness","text":"","code":"smoothness(x, method = \"cor\", lag = 1, iterations = NULL, ...)"},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantify the smoothness of a vector — smoothness","text":"x Numeric vector (similar time series). method Can \"diff\" (standard deviation standardized differences) \"cor\" (default, lag-one autocorrelation). lag integer indicating lag use. less 1, interpreted expressed percentage length vector. iterations number bootstrap replicates computing standard errors. NULL (default), parametric standard errors computed. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantify the smoothness of a vector — smoothness","text":"Value smoothness.","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantify the smoothness of a vector — smoothness","text":"https://stats.stackexchange.com/questions/24607/--measure-smoothness---time-series--r","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantify the smoothness of a vector — smoothness","text":"","code":"x <- (-10:10)^3 + rnorm(21, 0, 100) plot(x)  smoothness(x, method = \"cor\") #> [1] 0.9198875 #> attr(,\"class\") #> [1] \"parameters_smoothness\" \"numeric\"               smoothness(x, method = \"diff\") #> [1] 1.563718 #> attr(,\"class\") #> [1] \"parameters_smoothness\" \"numeric\""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-fit a model with standardized data — standardize.default","title":"Re-fit a model with standardized data — standardize.default","text":"Performs standardization data (z-scoring) using standardize() re-fits model standardized data.  Standardization done completely refitting model standardized data. Hence, approach equal standardizing variables fitting model return new model object. method particularly recommended complex models include interactions transformations (e.g., polynomial spline terms). robust (default FALSE) argument enables robust standardization data, based median MAD instead mean SD.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Re-fit a model with standardized data — standardize.default","text":"","code":"# Default S3 method standardize(   x,   robust = FALSE,   two_sd = FALSE,   weights = TRUE,   verbose = TRUE,   include_response = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-fit a model with standardized data — standardize.default","text":"x statistical model. robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). weights TRUE (default), weighted-standardization carried . verbose Toggle warnings messages . include_response TRUE (default), response value also standardized. FALSE, predictors standardized. Note GLMs models non-linear link functions, response value standardized, make re-fitting model work. model contains stats::offset(), offset variable(s) standardized response standardized. two_sd = TRUE, offsets standardized one-sd (similar response). (mediate models, include_response refers outcome y model; m model's response always standardized possible). ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Re-fit a model with standardized data — standardize.default","text":"statistical model fitted standardized data","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"generalized-linear-models","dir":"Reference","previous_headings":"","what":"Generalized Linear Models","title":"Re-fit a model with standardized data — standardize.default","text":"Standardization generalized linear models (GLM, GLMM, etc) done respect predictors (outcome remains -, unstandardized) - maintaining interpretability coefficients (e.g., binomial model: exponent standardized parameter change 1 SD predictor, etc.)","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"dealing-with-factors","dir":"Reference","previous_headings":"","what":"Dealing with Factors","title":"Re-fit a model with standardized data — standardize.default","text":"standardize(model) standardize_parameters(model, method = \"refit\") standardize categorical predictors (.e. factors) / dummy-variables, may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize_parameters(model, method = \"basic\") obtain post-hoc standardized parameters, standardize data standardize(data, force = TRUE) fitting model.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"transformed-variables","dir":"Reference","previous_headings":"","what":"Transformed Variables","title":"Re-fit a model with standardized data — standardize.default","text":"model's formula contains transformations (e.g. y ~ exp(X)) transformation effectively takes place standardization (e.g., exp(scale(X))). Since transformations undefined none positive values, log() sqrt(), relevel variables shifted (post standardization) Z - min(Z) + 1 Z - min(Z) (respectively).","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Re-fit a model with standardized data — standardize.default","text":"","code":"model <- lm(Infant.Mortality ~ Education * Fertility, data = swiss) coef(standardize(model)) #>         (Intercept)           Education           Fertility Education:Fertility  #>          0.06386069          0.47482848          0.63270919          0.09829777"},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardization (Z-scoring) — standardize","title":"Standardization (Z-scoring) — standardize","text":"Performs standardization data (z-scoring), .e., centering scaling, data expressed terms standard deviation (.e., mean = 0, SD = 1) Median Absolute Deviance (median = 0, MAD = 1). applied statistical model, function extracts dataset, standardizes , refits model standardized version dataset. normalize() function can also used scale numeric variables within 0 - 1 range.  model standardization, see standardize.default().","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardization (Z-scoring) — standardize","text":"","code":"standardize(x, ...)  standardise(x, ...)  # S3 method for class 'numeric' standardize(   x,   robust = FALSE,   two_sd = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   scale = NULL,   verbose = TRUE,   ... )  # S3 method for class 'factor' standardize(   x,   robust = FALSE,   two_sd = FALSE,   weights = NULL,   force = FALSE,   verbose = TRUE,   ... )  # S3 method for class 'data.frame' standardize(   x,   select = NULL,   exclude = NULL,   robust = FALSE,   two_sd = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   scale = NULL,   remove_na = c(\"none\", \"selected\", \"all\"),   force = FALSE,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  unstandardize(x, ...)  unstandardise(x, ...)  # S3 method for class 'numeric' unstandardize(   x,   center = NULL,   scale = NULL,   reference = NULL,   robust = FALSE,   two_sd = FALSE,   ... )  # S3 method for class 'data.frame' unstandardize(   x,   center = NULL,   scale = NULL,   reference = NULL,   robust = FALSE,   two_sd = FALSE,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardization (Z-scoring) — standardize","text":"x (grouped) data frame, vector statistical model (unstandardize() model). ... Arguments passed methods. robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). weights Can NULL (weighting), : model: TRUE (default), weighted-standardization carried . data.frames: numeric vector weights, character name column data.frame contains weights. numeric vectors: numeric vector weights. reference data frame variable centrality deviation computed instead input variable. Useful standardizing subset new data according another data frame. center, scale standardize():  Numeric values, can used alternative reference define reference centrality deviation. scale center length 1, recycled match length selected variables standardization. Else, center scale must length number selected variables. Values center scale matched selected variables provided order, unless named vector given. case, names matched names selected variables. unstandardize(): center scale correspond center (mean / median) scale (SD / MAD) original non-standardized data (data frames, named, column order correspond numeric column). However, one can also directly provide original data reference, center scale computed (according robust two_sd). Alternatively, input contains attributes center scale (output standardize()), take rest arguments absent. verbose Toggle warnings messages . force Logical, TRUE, forces recoding factors character vectors well. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. remove_na missing values (NA) treated: \"none\" (default): column's standardization done separately, ignoring NAs. Else, rows NA columns selected select / exclude (\"selected\") columns (\"\") dropped standardization, resulting data frame include cases. append Logical string. TRUE, standardized variables get new column names (suffix \"_z\") appended (column bind) x, thus returning original standardized variables. FALSE, original variables x overwritten standardized versions. character value, standardized variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardization (Z-scoring) — standardize","text":"standardized object (either standardize data frame statistical model fitted standardized data).","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Standardization (Z-scoring) — standardize","text":"x vector data frame remove_na = \"none\"), missing values preserved, return value length / number rows original input.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Standardization (Z-scoring) — standardize","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardization (Z-scoring) — standardize","text":"","code":"d <- iris[1:4, ]  # vectors standardise(d$Petal.Length) #> [1]  0.000000  0.000000 -1.224745  1.224745 #> (center: 1.4, scale = 0.082) #>   # Data frames # overwrite standardise(d, select = c(\"Sepal.Length\", \"Sepal.Width\")) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1    1.2402159   1.3887301          1.4         0.2  setosa #> 2    0.3382407  -0.9258201          1.4         0.2  setosa #> 3   -0.5637345   0.0000000          1.3         0.2  setosa #> 4   -1.0147221  -0.4629100          1.5         0.2  setosa  # append standardise(d, select = c(\"Sepal.Length\", \"Sepal.Width\"), append = TRUE) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Length_z #> 1          5.1         3.5          1.4         0.2  setosa      1.2402159 #> 2          4.9         3.0          1.4         0.2  setosa      0.3382407 #> 3          4.7         3.2          1.3         0.2  setosa     -0.5637345 #> 4          4.6         3.1          1.5         0.2  setosa     -1.0147221 #>   Sepal.Width_z #> 1     1.3887301 #> 2    -0.9258201 #> 3     0.0000000 #> 4    -0.4629100  # append, suffix standardise(d, select = c(\"Sepal.Length\", \"Sepal.Width\"), append = \"_std\") #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Length_std #> 1          5.1         3.5          1.4         0.2  setosa        1.2402159 #> 2          4.9         3.0          1.4         0.2  setosa        0.3382407 #> 3          4.7         3.2          1.3         0.2  setosa       -0.5637345 #> 4          4.6         3.1          1.5         0.2  setosa       -1.0147221 #>   Sepal.Width_std #> 1       1.3887301 #> 2      -0.9258201 #> 3       0.0000000 #> 4      -0.4629100  # standardizing with reference center and scale d <- data.frame(   a = c(-2, -1, 0, 1, 2),   b = c(3, 4, 5, 6, 7) )  # default standardization, based on mean and sd of each variable standardize(d) # means are 0 and 5, sd ~ 1.581139 #>            a          b #> 1 -1.2649111 -1.2649111 #> 2 -0.6324555 -0.6324555 #> 3  0.0000000  0.0000000 #> 4  0.6324555  0.6324555 #> 5  1.2649111  1.2649111  # standardization, based on mean and sd set to the same values standardize(d, center = c(0, 5), scale = c(1.581, 1.581)) #>            a          b #> 1 -1.2650221 -1.2650221 #> 2 -0.6325111 -0.6325111 #> 3  0.0000000  0.0000000 #> 4  0.6325111  0.6325111 #> 5  1.2650221  1.2650221  # standardization, mean and sd for each variable newly defined standardize(d, center = c(3, 4), scale = c(2, 4)) #>      a     b #> 1 -2.5 -0.25 #> 2 -2.0  0.00 #> 3 -1.5  0.25 #> 4 -1.0  0.50 #> 5 -0.5  0.75  # standardization, taking same mean and sd for each variable standardize(d, center = 1, scale = 3) #>            a         b #> 1 -1.0000000 0.6666667 #> 2 -0.6666667 1.0000000 #> 3 -0.3333333 1.3333333 #> 4  0.0000000 1.6666667 #> 5  0.3333333 2.0000000"},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenient text formatting functionalities — text_format","title":"Convenient text formatting functionalities — text_format","text":"Convenience functions manipulate format text.","code":""},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenient text formatting functionalities — text_format","text":"","code":"text_format(   text,   sep = \", \",   last = \" and \",   width = NULL,   enclose = NULL,   ... )  text_fullstop(text)  text_lastchar(text, n = 1)  text_concatenate(text, sep = \", \", last = \" and \", enclose = NULL)  text_paste(text, text2 = NULL, sep = \", \", enclose = NULL, ...)  text_remove(text, pattern = \"\", ...)  text_wrap(text, width = NULL, ...)"},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenient text formatting functionalities — text_format","text":"text, text2 character string. sep Separator. last Last separator. width Positive integer giving target column width wrapping lines output. Can \"auto\", case select 90\\ default width. enclose Character used wrap elements text, can , e.g., enclosed quotes backticks. NULL (default), text elements enclosed. ... arguments passed functions. n number characters find. pattern Regex pattern remove text.","code":""},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenient text formatting functionalities — text_format","text":"character string.","code":""},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenient text formatting functionalities — text_format","text":"","code":"# Add full stop if missing text_fullstop(c(\"something\", \"something else.\")) #> [1] \"something.\"      \"something else.\"  # Find last characters text_lastchar(c(\"ABC\", \"DEF\"), n = 2) #>  ABC  DEF  #> \"BC\" \"EF\"   # Smart concatenation text_concatenate(c(\"First\", \"Second\", \"Last\")) #> [1] \"First, Second and Last\" text_concatenate(c(\"First\", \"Second\", \"Last\"), last = \" or \", enclose = \"`\") #> [1] \"`First`, `Second` or `Last`\"  # Remove parts of string text_remove(c(\"one!\", \"two\", \"three!\"), \"!\") #> [1] \"one\"   \"two\"   \"three\"  # Wrap text long_text <- paste(rep(\"abc \", 100), collapse = \"\") cat(text_wrap(long_text, width = 50)) #>  abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc  # Paste with optional separator text_paste(c(\"A\", \"\", \"B\"), c(\"42\", \"42\", \"42\")) #> [1] \"A, 42\" \"42\"    \"B, 42\""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data to factors — to_factor","title":"Convert data to factors — to_factor","text":"Convert data factors","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data to factors — to_factor","text":"","code":"to_factor(x, ...)  # S3 method for class 'numeric' to_factor(x, labels_to_levels = TRUE, verbose = TRUE, ...)  # S3 method for class 'data.frame' to_factor(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   append = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data to factors — to_factor","text":"x data frame vector. ... Arguments passed methods. labels_to_levels Logical, TRUE, value labels used factor levels x converted factor. Else, factor levels based values x (.e. using .factor()). verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data to factors — to_factor","text":"factor, data frame factors.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert data to factors — to_factor","text":"Convert variables data factors. data labelled, value labels used factor levels. counterpart convert variables numeric to_numeric().","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Convert data to factors — to_factor","text":"Factors ignored returned . want use value labels levels factors, use labels_to_levels() instead.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Convert data to factors — to_factor","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data to factors — to_factor","text":"","code":"str(to_factor(iris)) #> 'data.frame':\t150 obs. of  5 variables: #>  $ Sepal.Length: Factor w/ 35 levels \"4.3\",\"4.4\",\"4.5\",..: 9 7 5 4 8 12 4 8 2 7 ... #>  $ Sepal.Width : Factor w/ 23 levels \"2\",\"2.2\",\"2.3\",..: 15 10 12 11 16 19 14 14 9 11 ... #>  $ Petal.Length: Factor w/ 43 levels \"1\",\"1.1\",\"1.2\",..: 5 5 4 6 5 8 5 6 5 6 ... #>  $ Petal.Width : Factor w/ 22 levels \"0.1\",\"0.2\",\"0.3\",..: 2 2 2 2 2 4 3 2 2 1 ... #>  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...  # use labels as levels data(efc) str(efc$c172code) #>  num [1:100] 2 2 1 2 2 2 2 2 NA 2 ... #>  - attr(*, \"label\")= chr \"carer's level of education\" #>  - attr(*, \"labels\")= Named num [1:3] 1 2 3 #>   ..- attr(*, \"names\")= chr [1:3] \"low level of education\" \"intermediate level of education\" \"high level of education\" head(to_factor(efc$c172code)) #> [1] intermediate level of education intermediate level of education #> [3] low level of education          intermediate level of education #> [5] intermediate level of education intermediate level of education #> 3 Levels: low level of education ... high level of education"},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data to numeric — to_numeric","title":"Convert data to numeric — to_numeric","text":"Convert data numeric converting characters factors factors either numeric levels dummy variables. \"counterpart\" convert variables factors to_factor().","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data to numeric — to_numeric","text":"","code":"to_numeric(x, ...)  # S3 method for class 'data.frame' to_numeric(   x,   select = NULL,   exclude = NULL,   dummy_factors = FALSE,   preserve_levels = FALSE,   lowest = NULL,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data to numeric — to_numeric","text":"x data frame, factor vector. ... Arguments passed methods. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), character vector variable names including ranges specified via : (e.g., c(\"col1:col3\", \"col5\")), functions, like data_select() data_rename(), select can named character vector. case, names used rename columns output data frame. See 'Details' related functions see option applies. formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(), ends_with(), contains(), range using :, regex(). starts_with(), ends_with(),  contains() accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). regex() can used define regular expression patterns. function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(), -.numeric -(Sepal.Width:Petal.Length). Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. extract_column_names(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. dummy_factors Transform factors dummy factors (factor levels different columns filled binary 0-1 value). preserve_levels Logical, applies x factor. TRUE, x numeric factor levels, converted related numeric values. possible, converted numeric values start 1 number levels. lowest Numeric, indicating lowest (minimum) value converting factors character vectors numeric values. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains() select = regex(), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data to numeric — to_numeric","text":"data frame numeric variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Convert data to numeric — to_numeric","text":"factors converted multiple \"binary\" dummies, .e. factor level converted separate column filled binary 0-1 value, set dummy_factors = TRUE. want preserve original factor levels (case represent numeric values), use preserve_levels = TRUE.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"selection-of-variables-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - select argument","title":"Convert data to numeric — to_numeric","text":"functions select argument complete input data frame returned, even select selects range variables. However, to_numeric(), factors might converted dummies, thus, number variables returned data frame longer match input data frame. Hence, select used, variables (dummies) specified select returned. Use append=TRUE also include original variables returned data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data to numeric — to_numeric","text":"","code":"to_numeric(head(ToothGrowth)) #>    len supp dose #> 1  4.2    2  0.5 #> 2 11.5    2  0.5 #> 3  7.3    2  0.5 #> 4  5.8    2  0.5 #> 5  6.4    2  0.5 #> 6 10.0    2  0.5 to_numeric(head(ToothGrowth), dummy_factors = TRUE) #>    len supp.OJ supp.VC dose #> 1  4.2       0       1  0.5 #> 2 11.5       0       1  0.5 #> 3  7.3       0       1  0.5 #> 4  5.8       0       1  0.5 #> 5  6.4       0       1  0.5 #> 6 10.0       0       1  0.5  # factors x <- as.factor(mtcars$gear) to_numeric(x) #>  [1] 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 3 3 3 3 3 2 to_numeric(x, preserve_levels = TRUE) #>  [1] 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4 # same as: coerce_to_numeric(x) #>  [1] 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4"},{"path":"https://easystats.github.io/datawizard/reference/visualisation_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare objects for visualisation — visualisation_recipe","title":"Prepare objects for visualisation — visualisation_recipe","text":"function prepares objects visualisation returning list layers data geoms can easily plotted using instance ggplot2. see package installed, call visualization_recipe() can replaced plot(), internally call former plot using ggplot. resulting plot can customized ad-hoc (adding ggplot's geoms, theme specifications), via arguments visualisation_recipe() control aesthetic parameters. See specific documentation page object's class: modelbased: https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html correlation: https://easystats.github.io/correlation/reference/visualisation_recipe.easycormatrix.html","code":""},{"path":"https://easystats.github.io/datawizard/reference/visualisation_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare objects for visualisation — visualisation_recipe","text":"","code":"visualisation_recipe(x, ...)"},{"path":"https://easystats.github.io/datawizard/reference/visualisation_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare objects for visualisation — visualisation_recipe","text":"x easystats object. ... arguments passed functions.","code":""},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted Mean, Median, SD, and MAD — weighted_mean","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"Weighted Mean, Median, SD, MAD","code":""},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"","code":"weighted_mean(x, weights = NULL, remove_na = TRUE, verbose = TRUE, ...)  weighted_median(x, weights = NULL, remove_na = TRUE, verbose = TRUE, ...)  weighted_sd(x, weights = NULL, remove_na = TRUE, verbose = TRUE, ...)  weighted_mad(   x,   weights = NULL,   constant = 1.4826,   remove_na = TRUE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"x object containing values whose weighted mean     computed. weights numerical vector weights length x giving weights use elements x. weights = NULL, x passed non-weighted function. remove_na Logical, TRUE (default), removes missing (NA) infinite values x weights. verbose Show warning weights negative? ... arguments passed methods. constant scale factor.","code":""},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"","code":"## GPA from Siegel 1994 x <- c(3.7, 3.3, 3.5, 2.8) wt <- c(5, 5, 4, 1) / 15  weighted_mean(x, wt) #> [1] 3.453333 weighted_median(x, wt) #> [1] 3.5  weighted_sd(x, wt) #> [1] 0.2852935 weighted_mad(x, wt) #> [1] 0.29652"},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Winsorize data — winsorize","title":"Winsorize data — winsorize","text":"Winsorize data","code":""},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Winsorize data — winsorize","text":"","code":"winsorize(data, ...)  # S3 method for class 'numeric' winsorize(   data,   threshold = 0.2,   method = \"percentile\",   robust = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Winsorize data — winsorize","text":"data data frame vector. ... Currently used. threshold amount winsorization, depends value method: method = \"percentile\": amount winsorize tail. value threshold must 0 0.5 length 1. method = \"zscore\": number SD/MAD-deviations mean/median (see robust). value threshold must greater 0 length 1. method = \"raw\": vector length 2 lower upper bound winsorization. method One \"percentile\" (default), \"zscore\", \"raw\". robust Logical, TRUE, winsorizing \"zscore\" method done via median median absolute deviation (MAD); FALSE, via mean standard deviation. verbose used anymore since datawizard 0.6.6.","code":""},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Winsorize data — winsorize","text":"data frame winsorized columns winsorized vector.","code":""},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Winsorize data — winsorize","text":"Winsorizing winsorization transformation statistics limiting extreme values statistical data reduce effect possibly spurious outliers. distribution many statistics can heavily influenced outliers. typical strategy set outliers (values beyond certain threshold) specified percentile data; example, 90% winsorization see data 5th percentile set 5th percentile, data 95th percentile set 95th percentile. Winsorized estimators usually robust outliers standard forms.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Winsorize data — winsorize","text":"","code":"hist(iris$Sepal.Length, main = \"Original data\")   hist(winsorize(iris$Sepal.Length, threshold = 0.2),   xlim = c(4, 8), main = \"Percentile Winsorization\" )   hist(winsorize(iris$Sepal.Length, threshold = 1.5, method = \"zscore\"),   xlim = c(4, 8), main = \"Mean (+/- SD) Winsorization\" )   hist(winsorize(iris$Sepal.Length, threshold = 1.5, method = \"zscore\", robust = TRUE),   xlim = c(4, 8), main = \"Median (+/- MAD) Winsorization\" )   hist(winsorize(iris$Sepal.Length, threshold = c(5, 7.5), method = \"raw\"),   xlim = c(4, 8), main = \"Raw Thresholds\" )   # Also works on a data frame: winsorize(iris, threshold = 0.2) #>     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species #> 1            5.1         3.4          1.5         0.2     setosa #> 2            5.0         3.0          1.5         0.2     setosa #> 3            5.0         3.2          1.5         0.2     setosa #> 4            5.0         3.1          1.5         0.2     setosa #> 5            5.0         3.4          1.5         0.2     setosa #> 6            5.4         3.4          1.7         0.4     setosa #> 7            5.0         3.4          1.5         0.3     setosa #> 8            5.0         3.4          1.5         0.2     setosa #> 9            5.0         2.9          1.5         0.2     setosa #> 10           5.0         3.1          1.5         0.2     setosa #> 11           5.4         3.4          1.5         0.2     setosa #> 12           5.0         3.4          1.6         0.2     setosa #> 13           5.0         3.0          1.5         0.2     setosa #> 14           5.0         3.0          1.5         0.2     setosa #> 15           5.8         3.4          1.5         0.2     setosa #> 16           5.7         3.4          1.5         0.4     setosa #> 17           5.4         3.4          1.5         0.4     setosa #> 18           5.1         3.4          1.5         0.3     setosa #> 19           5.7         3.4          1.7         0.3     setosa #> 20           5.1         3.4          1.5         0.3     setosa #> 21           5.4         3.4          1.7         0.2     setosa #> 22           5.1         3.4          1.5         0.4     setosa #> 23           5.0         3.4          1.5         0.2     setosa #> 24           5.1         3.3          1.7         0.5     setosa #> 25           5.0         3.4          1.9         0.2     setosa #> 26           5.0         3.0          1.6         0.2     setosa #> 27           5.0         3.4          1.6         0.4     setosa #> 28           5.2         3.4          1.5         0.2     setosa #> 29           5.2         3.4          1.5         0.2     setosa #> 30           5.0         3.2          1.6         0.2     setosa #> 31           5.0         3.1          1.6         0.2     setosa #> 32           5.4         3.4          1.5         0.4     setosa #> 33           5.2         3.4          1.5         0.2     setosa #> 34           5.5         3.4          1.5         0.2     setosa #> 35           5.0         3.1          1.5         0.2     setosa #> 36           5.0         3.2          1.5         0.2     setosa #> 37           5.5         3.4          1.5         0.2     setosa #> 38           5.0         3.4          1.5         0.2     setosa #> 39           5.0         3.0          1.5         0.2     setosa #> 40           5.1         3.4          1.5         0.2     setosa #> 41           5.0         3.4          1.5         0.3     setosa #> 42           5.0         2.7          1.5         0.3     setosa #> 43           5.0         3.2          1.5         0.2     setosa #> 44           5.0         3.4          1.6         0.6     setosa #> 45           5.1         3.4          1.9         0.4     setosa #> 46           5.0         3.0          1.5         0.3     setosa #> 47           5.1         3.4          1.6         0.2     setosa #> 48           5.0         3.2          1.5         0.2     setosa #> 49           5.3         3.4          1.5         0.2     setosa #> 50           5.0         3.3          1.5         0.2     setosa #> 51           6.5         3.2          4.7         1.4 versicolor #> 52           6.4         3.2          4.5         1.5 versicolor #> 53           6.5         3.1          4.9         1.5 versicolor #> 54           5.5         2.7          4.0         1.3 versicolor #> 55           6.5         2.8          4.6         1.5 versicolor #> 56           5.7         2.8          4.5         1.3 versicolor #> 57           6.3         3.3          4.7         1.6 versicolor #> 58           5.0         2.7          3.3         1.0 versicolor #> 59           6.5         2.9          4.6         1.3 versicolor #> 60           5.2         2.7          3.9         1.4 versicolor #> 61           5.0         2.7          3.5         1.0 versicolor #> 62           5.9         3.0          4.2         1.5 versicolor #> 63           6.0         2.7          4.0         1.0 versicolor #> 64           6.1         2.9          4.7         1.4 versicolor #> 65           5.6         2.9          3.6         1.3 versicolor #> 66           6.5         3.1          4.4         1.4 versicolor #> 67           5.6         3.0          4.5         1.5 versicolor #> 68           5.8         2.7          4.1         1.0 versicolor #> 69           6.2         2.7          4.5         1.5 versicolor #> 70           5.6         2.7          3.9         1.1 versicolor #> 71           5.9         3.2          4.8         1.8 versicolor #> 72           6.1         2.8          4.0         1.3 versicolor #> 73           6.3         2.7          4.9         1.5 versicolor #> 74           6.1         2.8          4.7         1.2 versicolor #> 75           6.4         2.9          4.3         1.3 versicolor #> 76           6.5         3.0          4.4         1.4 versicolor #> 77           6.5         2.8          4.8         1.4 versicolor #> 78           6.5         3.0          5.0         1.7 versicolor #> 79           6.0         2.9          4.5         1.5 versicolor #> 80           5.7         2.7          3.5         1.0 versicolor #> 81           5.5         2.7          3.8         1.1 versicolor #> 82           5.5         2.7          3.7         1.0 versicolor #> 83           5.8         2.7          3.9         1.2 versicolor #> 84           6.0         2.7          5.1         1.6 versicolor #> 85           5.4         3.0          4.5         1.5 versicolor #> 86           6.0         3.4          4.5         1.6 versicolor #> 87           6.5         3.1          4.7         1.5 versicolor #> 88           6.3         2.7          4.4         1.3 versicolor #> 89           5.6         3.0          4.1         1.3 versicolor #> 90           5.5         2.7          4.0         1.3 versicolor #> 91           5.5         2.7          4.4         1.2 versicolor #> 92           6.1         3.0          4.6         1.4 versicolor #> 93           5.8         2.7          4.0         1.2 versicolor #> 94           5.0         2.7          3.3         1.0 versicolor #> 95           5.6         2.7          4.2         1.3 versicolor #> 96           5.7         3.0          4.2         1.2 versicolor #> 97           5.7         2.9          4.2         1.3 versicolor #> 98           6.2         2.9          4.3         1.3 versicolor #> 99           5.1         2.7          3.0         1.1 versicolor #> 100          5.7         2.8          4.1         1.3 versicolor #> 101          6.3         3.3          5.3         1.9  virginica #> 102          5.8         2.7          5.1         1.9  virginica #> 103          6.5         3.0          5.3         1.9  virginica #> 104          6.3         2.9          5.3         1.8  virginica #> 105          6.5         3.0          5.3         1.9  virginica #> 106          6.5         3.0          5.3         1.9  virginica #> 107          5.0         2.7          4.5         1.7  virginica #> 108          6.5         2.9          5.3         1.8  virginica #> 109          6.5         2.7          5.3         1.8  virginica #> 110          6.5         3.4          5.3         1.9  virginica #> 111          6.5         3.2          5.1         1.9  virginica #> 112          6.4         2.7          5.3         1.9  virginica #> 113          6.5         3.0          5.3         1.9  virginica #> 114          5.7         2.7          5.0         1.9  virginica #> 115          5.8         2.8          5.1         1.9  virginica #> 116          6.4         3.2          5.3         1.9  virginica #> 117          6.5         3.0          5.3         1.8  virginica #> 118          6.5         3.4          5.3         1.9  virginica #> 119          6.5         2.7          5.3         1.9  virginica #> 120          6.0         2.7          5.0         1.5  virginica #> 121          6.5         3.2          5.3         1.9  virginica #> 122          5.6         2.8          4.9         1.9  virginica #> 123          6.5         2.8          5.3         1.9  virginica #> 124          6.3         2.7          4.9         1.8  virginica #> 125          6.5         3.3          5.3         1.9  virginica #> 126          6.5         3.2          5.3         1.8  virginica #> 127          6.2         2.8          4.8         1.8  virginica #> 128          6.1         3.0          4.9         1.8  virginica #> 129          6.4         2.8          5.3         1.9  virginica #> 130          6.5         3.0          5.3         1.6  virginica #> 131          6.5         2.8          5.3         1.9  virginica #> 132          6.5         3.4          5.3         1.9  virginica #> 133          6.4         2.8          5.3         1.9  virginica #> 134          6.3         2.8          5.1         1.5  virginica #> 135          6.1         2.7          5.3         1.4  virginica #> 136          6.5         3.0          5.3         1.9  virginica #> 137          6.3         3.4          5.3         1.9  virginica #> 138          6.4         3.1          5.3         1.8  virginica #> 139          6.0         3.0          4.8         1.8  virginica #> 140          6.5         3.1          5.3         1.9  virginica #> 141          6.5         3.1          5.3         1.9  virginica #> 142          6.5         3.1          5.1         1.9  virginica #> 143          5.8         2.7          5.1         1.9  virginica #> 144          6.5         3.2          5.3         1.9  virginica #> 145          6.5         3.3          5.3         1.9  virginica #> 146          6.5         3.0          5.2         1.9  virginica #> 147          6.3         2.7          5.0         1.9  virginica #> 148          6.5         3.0          5.2         1.9  virginica #> 149          6.2         3.4          5.3         1.9  virginica #> 150          5.9         3.0          5.1         1.8  virginica"},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-120","dir":"Changelog","previous_headings":"","what":"datawizard 1.2.0","title":"datawizard 1.2.0","text":"CRAN release: 2025-07-17 BREAKING CHANGES drop_na data_match() safe, pattern, verbose data_rename() CHANGES data_read() data_write() now support .parquet file format, via nanoparquet package (#625). data_tabulate() gets display() method (#627). data_tabulate() gets .table() method coerce frequency contingency table (list ) table() object(s). can useful statistical analysis, e.g. combination chisq.test() (#629). print() method data_tabulate() now appears documentation, making big_mark argument visible (#627). BUG FIXES Fixed issue printing cross tables using data_tabulate(= ...), caused recent changes insight::export_table(). Fixed another issue printing cross tables using data_tabulate(= ...), one variable selected select (#630). Fixed typo documentation data_match().","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-110","dir":"Changelog","previous_headings":"","what":"datawizard 1.1.0","title":"datawizard 1.1.0","text":"CRAN release: 2025-05-09 BREAKING CHANGES data_read() now also returns Bayesian models packages brms rstanarm original model objects, longer coerces data frames (#606). output format describe_distribution() grouped data changed. , printed one table per group combination. Now, prints single table group columns start (#610). output format describe_distribution() confidence intervals requested changed. Now, centrality measure confidence interval calculated (#617). data_modify() now always uses values vector modified newly created variable, longer tries detect whether character value possibly contains expression. allow expression provided string (character vectors), use helper-function as_expr(). literal expressions strings wrapped as_expr() evaluated expressions, everything else treated vector values new variables (#605). CHANGES display() now re-exported package insight. data_read() data_write() now rely base-R functions files type .rds, .rda .rdata. Thus, package rio longer required installed file types (#607). data_codebook() gives informative warning column names matched selection pattern (#601). data_to_long() now errors columns selected reshape exist data, avoid nonsensical results missed (#602). New argument describe_distribution() (#604). describe_distribution() now gives informative errors column names input data frame conflict column output table (#612). methods parameters_distribution objects now defined datawizard (previously parameters) (#613). BUG FIXES Fixed bug data_to_wide(), new column names names_from ignored column contained one unique value. Fixed bug describe_distribution() group combinations didn’t appear data (#609). Fixed bug describe_distribution() one value centrality argument specified (#617). Fixed bug describe_distribution() setting verbose = FALSE didn’t hide warnings (#617). Fixed warning data_summary() variable name another object global environment (#585).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-102","dir":"Changelog","previous_headings":"","what":"datawizard 1.0.2","title":"datawizard 1.0.2","text":"CRAN release: 2025-03-24 BUG FIXES Fixed failing R CMD check ATLAS, noLD, OpenBLAS due small numerical differences (#592).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-101","dir":"Changelog","previous_headings":"","what":"datawizard 1.0.1","title":"datawizard 1.0.1","text":"CRAN release: 2025-03-07 BUG FIXES Fixed issue data_arrange() data frames one column. Formerly, data frame coerced vector, now data frame class preserved. Fixed issue R-devel (4.5.0) due change grep() handles logical arguments missing values (#588).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-100","dir":"Changelog","previous_headings":"","what":"datawizard 1.0.0","title":"datawizard 1.0.0","text":"CRAN release: 2025-01-10 BREAKING CHANGES DEPRECATIONS datawizard now requires R >= 4.0 (#515). Argument drop_na data_match() deprecated now. Please use remove_na instead (#556). data_rename() (#567): argument pattern deprecated. Use select instead. argument safe deprecated. function now errors select contains unknown column names. replacement NULL, error now thrown (previously, column indices used new names). select (previously pattern) named vector, elements must named, e.g. c(length = \"Sepal.Length\", \"Sepal.Width\") errors. Order arguments probability_weights rescale_weights() changed, method = \"kish\", argument optional (#575). name rescaled weights variables rescale_weights() renamed. pweights_a pweights_b now named rescaled_weights_a rescaled_weights_b (#575). print() methods data_tabulate() multiple sub-tables (.e. length > 1) revised. Now, integrated table instead multiple tables returned. Furthermore, print_html() work, also fixed now (#577). demean() (degroup()) gets append argument defaults TRUE, append centered variables original data frame, instead returning de- group-meaned variables . Use append = FALSE previous default behaviour (.e. returning newly created variables) (#579). CHANGES rescale_weights() gets method argument, choose method rescale weights. Options \"carle\" (default) \"kish\" (#575). select argument, available different functions select variables, can now also character vector quoted variable names, including colon indicate range several variables (e.g. \"cyl:gear\") (#551). New function row_sums(), calculate row sums (optionally minimum amount valid values), complement row_means() (#552). New function row_count(), count specific values row-wise (#553). data_read() longer shows warning forthcoming breaking changes upstream packages reading .RData files (#557). data_modify() now recognizes n(), example create index data groups 1:n() (#535). replacement argument data_rename() now supports glue-styled tokens (#563). data_summary() also accepts results bayestestR::ci() summary function (#483). ranktransform() new argument zeros determine zeros handled sign = TRUE (#573). BUG FIXES describe_distribution() longer errors sample sparse compute CIs. Instead, warns user returns NA (#550). data_read() preserves variable types importing files rds rdata format (#558).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0130","dir":"Changelog","previous_headings":"","what":"datawizard 0.13.0","title":"datawizard 0.13.0","text":"CRAN release: 2024-10-05 BREAKING CHANGES data_rename() now errors replacement argument contains NA values empty strings (#539). Removed deprecated functions get_columns(), data_find(), format_text() (#546). Removed deprecated arguments group na.rm multiple functions. Use remove_na instead (#546). default value argument dummy_factors to_numeric() changed TRUE FALSE (#544). CHANGES pattern argument data_rename() can also named vector. case, names used values replacement argument (.e. pattern can character vector using <new name> = \"<old name>\"). categorize() gains new breaks argument, decide whether breaks inclusive exclusive (#548). labels argument categorize() gets two new options, \"range\" \"observed\", use range categorized values labels (.e. factor levels) (#548). Minor additions reshape_ci() work forthcoming changes bayestestR package.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0123","dir":"Changelog","previous_headings":"","what":"datawizard 0.12.3","title":"datawizard 0.12.3","text":"CRAN release: 2024-09-02 CHANGES demean() (degroup()) now also work nested designs, argument nested = TRUE specifies one variable (#533). Vignettes longer provided package, now available website. one “Overview” vignette available package, contains links vignettes website. CRAN errors occurring building vignettes macOS couldn’t determine cause multiple patch releases (#534).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0122","dir":"Changelog","previous_headings":"","what":"datawizard 0.12.2","title":"datawizard 0.12.2","text":"CRAN release: 2024-07-21 Remove htmltools Suggests attempt fixing error CRAN checks due failures build vignette (#528).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0121","dir":"Changelog","previous_headings":"","what":"datawizard 0.12.1","title":"datawizard 0.12.1","text":"CRAN release: 2024-07-15 patch release fix one error CRAN checks occurring missing package namespace one vignettes.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0120","dir":"Changelog","previous_headings":"","what":"datawizard 0.12.0","title":"datawizard 0.12.0","text":"CRAN release: 2024-07-11 BREAKING CHANGES argument include_na data_tabulate() data_summary() renamed remove_na. Consequently, mimic former behaviour, FALSE TRUE need switched (.e. remove_na = TRUE equivalent former include_na = FALSE). Class names objects returned data_tabulate() changed datawizard_table datawizard_crosstable (resp. plural forms, *_tables), provide clearer consistent naming scheme. CHANGES data_select() can directly rename selected variables named vector provided select, e.g. data_select(mtcars, c(new1 = \"mpg\", new2 = \"cyl\")). data_tabulate() gains .data.frame() method, return frequency table data frame. structure returned object nested data frame, first column contains name variable frequencies calculated, second column contains frequency table. demean() (degroup()) now also work cross-classified designs, generally, data multiple grouping cluster variables (.e. can now specify one variable).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0110","dir":"Changelog","previous_headings":"","what":"datawizard 0.11.0","title":"datawizard 0.11.0","text":"CRAN release: 2024-06-05 BREAKING CHANGES Arguments named group group_by deprecated removed future release. Please use instead. affects following functions datawizard (#502). data_partition() demean() degroup() means_by_group() rescale_weights() Following aliases deprecated removed future release (#504): get_columns(), use data_select() instead. data_find() find_columns(), use extract_column_names() instead. format_text(), use text_format() instead. CHANGES recode_into() relaxed regarding checking type NA values. recode numeric variable, one recode values NA, longer need use NA_real_ numeric NA values. Improved documentation functions. BUG FIXES data_to_long() work data frame columns attributes (like labelled data).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0100","dir":"Changelog","previous_headings":"","what":"datawizard 0.10.0","title":"datawizard 0.10.0","text":"CRAN release: 2024-03-26 BREAKING CHANGES following arguments deprecated 0.5.0 now removed: data_to_wide(): colnames_from, rows_from, sep data_to_long(): colnames_to data_partition(): training_proportion NEW FUNCTIONS data_summary(), compute summary statistics (grouped) data frames. data_replicate(), expand data frame replicating rows based another variable contains counts replications per row. CHANGES data_modify() gets three new arguments, ., ..modify, modify variables specific positions based logical conditions. data_tabulate() revised gets several new arguments: weights argument, compute weighted frequency tables. include_na allows include omit missing values table. Furthermore, argument added, compute crosstables (#479, #481).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-091","dir":"Changelog","previous_headings":"","what":"datawizard 0.9.1","title":"datawizard 0.9.1","text":"CRAN release: 2023-12-21 CHANGES rescale() gains multiply add arguments, expand ranges given factor value. to_factor() to_numeric() now support class haven_labelled. BUG FIXES to_numeric() now correctly deals inversed factor levels preserve_levels = TRUE. to_numeric() inversed order value labels dummy_factors = FALSE. convert_to_na() now preserves attributes factors drop_levels = TRUE.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-090","dir":"Changelog","previous_headings":"","what":"datawizard 0.9.0","title":"datawizard 0.9.0","text":"CRAN release: 2023-09-15 NEW FUNCTIONS row_means(), compute row means, optionally rows least min_valid non-missing values. contr.deviation() sum-deviation contrast coding factors. means_by_group(), compute mean values variables, grouped levels specified factors. data_seek(), seek variables data frame, based column names, variables labels, value labels factor levels. Searching labels works “labelled” data, .e. variables label labels attribute. CHANGES recode_into() gains overwrite argument skip overwriting already recoded cases multiple recode patterns apply case. recode_into() gains preserve_na argument preserve NA values recoding. data_read() now passes encoding argument data.table::fread(). allows read files non-ASCII characters. datawizard moves GPL-3 license MIT license. unnormalize() unstandardize() now work grouped data (#415). unnormalize() now errors instead emitting warning doesn’t necessary info (#415). BUG FIXES Fixed issue labels_to_levels() values labels sorted order values sequentially numbered. Fixed issues data_write() writing labelled data SPSS format vectors different type value labels. Fixed issues data_write() writing labelled data SPSS format character vectors missing value labels, existing variable labels. Fixed issue recode_into() probably wrong case number printed warning several recode patterns match one case. Fixed issue recode_into() original data contained NA values NA included recode pattern. Fixed issue data_filter() functions containing = (e.g. naming arguments, like grepl(pattern, x = )) mistakenly seen faulty syntax. Fixed issue empty_column() strings invalid multibyte strings. data frames files, empty_column() data_read() longer fails.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-080","dir":"Changelog","previous_headings":"","what":"datawizard 0.8.0","title":"datawizard 0.8.0","text":"CRAN release: 2023-06-16 BREAKING CHANGES following re-exported functions insight now removed: object_has_names(), object_has_rownames(), is_empty_object(), compact_list(), compact_character(). Argument na.rm renamed remove_na throughout datawizard functions. na.rm kept backward compatibility, deprecated later removed future updates. way expressions defined data_filter() revised. filter argument replaced ..., allowing separate multiple expression comma (combined &). Furthermore, expressions can now also defined strings, provided character vectors, allow string-friendly programming. CHANGES Weighted-functions (weighted_sd(), weighted_mean(), …) gain remove_na argument, remove keep missing infinite values. default, remove_na = TRUE, .e. missing infinite values removed default. reverse_scale(), normalize() rescale() gain append argument (similar data frame methods transformation functions), append recoded variables input data frame instead overwriting existing variables. NEW FUNCTIONS rowid_as_column() complement rownames_as_column() (mimic tibble::rowid_to_column()). Note behavior different tibble::rowid_to_column() grouped data. See Details section docs. data_unite(), merge values multiple variables one new variable. data_separate(), counterpart data_unite(), separate single variable multiple new variables. data_modify(), create new variables, modify remove existing variables data frame. MINOR CHANGES to_numeric() variables type Date, POSIXct POSIXlt now includes class name warning message. Added print() method center(), standardize(), normalize() rescale(). BUG FIXES standardize_parameters() now works package namespace model formula (#401). data_merge() longer yields warning tibbles join = \"bind\". center() standardize() work grouped data frames (class grouped_df) force = TRUE. data.frame method describe_distribution() returns NULL instead error valid variable passed (example factor variable include_factors = FALSE) (#421).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-071","dir":"Changelog","previous_headings":"","what":"datawizard 0.7.1","title":"datawizard 0.7.1","text":"CRAN release: 2023-04-03 BREAKING CHANGES add_labs() renamed assign_labels(). Since add_labs() existed days, alias backwards compatibility. NEW FUNCTIONS labels_to_levels(), use value labels factors levels. MINOR CHANGES data_read() now checks imported object actually data frame (coercible data frame), , longer errors, gives informative warning type object imported. BUG FIXES Fix test CRAN check Mac OS arm64","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-070","dir":"Changelog","previous_headings":"","what":"datawizard 0.7.0","title":"datawizard 0.7.0","text":"CRAN release: 2023-03-22 BREAKING CHANGES selection patterns, expressions like -var1:var3 exclude variables var1 var3 longer accepted. correct expression -(var1:var3). 2 reasons: consistent behavior numerics (-1:2 accepted -(1:2) ); consistent dplyr::select(), throws warning uses first variable first expression. NEW FUNCTIONS recode_into(), similar dplyr::case_when(), recode values one variables new variable. mean_sd() median_mad() summarizing vectors mean (median) range one SD (MAD) . data_write() counterpart data_read(), write data frames CSV, SPSS, SAS, Stata files many file types. One advantage existing functions write data packages labelled (numeric) data can converted factors (values labels used factor levels) even text formats like CSV similar. allows exporting “labelled” data file formats, . add_labs(), manually add value variable labels attributes variables. attributes stored \"label\" \"labels\" attributes, similar labelled class haven package. MINOR CHANGES data_rename() gets verbose argument. winsorize() now errors threshold incorrect (previously, provided warning returned unchanged data). argument verbose now useless kept backward compatibility. documentation now contains details valid values threshold (#357). functions arguments select /exclude, now one warning per misspelled variable. previous behavior one warning. Fixed inconsistent behaviour standardize() one arguments center scale provided (#365). unstandardize() replace_nan_inf() now work select helpers (#376). Added informative warning error messages reverse(). Furthermore, docs now describe range argument clearly (#380). unnormalize() errors unexpected inputs (#383). BUG FIXES empty_columns() (therefore remove_empty_columns()) now correctly detects columns containing NA_character_ (#349). Select helpers now work custom functions argument called select (#356). Fix unexpected warning convert_na_to() select list (#352). Fixed issue correct labelling numeric variables nine unique values associated value labels.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-065","dir":"Changelog","previous_headings":"","what":"datawizard 0.6.5","title":"datawizard 0.6.5","text":"CRAN release: 2022-12-14 MAJOR CHANGES Etienne Bacher new maintainer. MINOR CHANGES standardize(), center(), normalize() rescale() can used model formulas, similar base::scale(). data_codebook() now includes proportion category/value, addition counts. Furthermore, data contains tagged NA values, included frequency table. BUG FIXES center(x) now works correctly x single value either reference center specified (#324). Fixed issue data_codebook(), failed labelled vectors values labels sorted order.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-064","dir":"Changelog","previous_headings":"","what":"datawizard 0.6.4","title":"datawizard 0.6.4","text":"CRAN release: 2022-11-19 NEW FUNCTIONS data_codebook(): generate codebooks data frames. New functions deal duplicates: data_duplicated() (keep duplicates, including first occurrence) data_unique() (returns data, excluding duplicates except one instance , based selected method). MINOR CHANGES .data.frame methods now preserve custom attributes. include_bounds argument normalize() can now also numeric value, defining limit upper lower bound (.e. distance 1 0). data_filter() now works grouped data. BUG FIXES data_read() longer prints message empty columns data actually empty columns. data_to_wide() now drops columns id_cols (specified), names_from, values_from. behaviour observed tidyr::pivot_wider().","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-063","dir":"Changelog","previous_headings":"","what":"datawizard 0.6.3","title":"datawizard 0.6.3","text":"CRAN release: 2022-10-22 MAJOR CHANGES new publication datawizard package: https://joss.theoj.org/papers/10.21105/joss.04684 Fixes failing tests due changes R-devel. data_to_long() data_to_wide() significant performance improvements, sometimes high ten-fold speedup. MINOR CHANGES column names misspelled, functions now suggest existing columns possibly meant. Miscellaneous performance gains. convert_to_na() now requires argument na class ‘Date’ convert specific dates NA. example, convert_to_na(x, na = \"2022-10-17\") must changed convert_to_na(x, na = .Date(\"2022-10-17\")). BUG FIXES data_to_long() data_to_wide() now correctly keep date format.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-062","dir":"Changelog","previous_headings":"","what":"datawizard 0.6.2","title":"datawizard 0.6.2","text":"CRAN release: 2022-10-04 BREAKING CHANGES Methods grouped data frames (.grouped_df) longer support dplyr::group_by() dplyr version 0.8.0. empty_columns() remove_empty_columns() now also remove columns contain empty characters. Likewise, empty_rows() remove_empty_rows() remove observations completely missing empty character values. MINOR CHANGES data_read() gains convert_factors argument, turn automatic conversion numeric variables factors. BUG FIXES data_arrange() now works data frames grouped using data_group() (#274).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-061","dir":"Changelog","previous_headings":"","what":"datawizard 0.6.1","title":"datawizard 0.6.1","text":"CRAN release: 2022-09-25 Updates tests upcoming changes tidyselect package (#267).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-060","dir":"Changelog","previous_headings":"","what":"datawizard 0.6.0","title":"datawizard 0.6.0","text":"CRAN release: 2022-09-15 BREAKING CHANGES minimum needed R version bumped 3.6. Following deprecated functions removed: data_cut(), data_recode(), data_shift(), data_reverse(), data_rescale(), data_to_factor(), data_to_numeric() New text_format() alias introduced format_text(), latter removed next release. New recode_values() alias introduced change_code(), latter removed next release. data_merge() now errors columns specified datasets. Using negative values arguments select exclude now removes columns selection/exclusion. previous behavior start selection/exclusion end dataset, inconsistent use “-” selecting possibilities. NEW FUNCTIONS data_peek(): peek values type variables data frame. coef_var(): compute coefficient variation. CHANGES data_filter() give informative messages malformed syntax filter argument. now possible use curly brackets pass variable names data_filter(), like following example. See examples section documentation data_filter(). regex argument added functions use select-helpers already argument. Select helpers starts_with(), ends_with(), contains() now accept several patterns, e.g starts_with(\"Sep\", \"Petal\"). Arguments select exclude present functions improved work loops custom functions. example, following code now works: now vignette summarizing various ways select exclude variables datawizard functions.","code":"foo <- function(data) {   i <- \"Sep\"   find_columns(data, select = starts_with(i)) } foo(iris)  for (i in c(\"Sepal\", \"Sp\")) {   head(iris) |>     find_columns(select = starts_with(i)) |>     print() }"},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-051","dir":"Changelog","previous_headings":"","what":"datawizard 0.5.1","title":"datawizard 0.5.1","text":"CRAN release: 2022-08-17 Fixes failing tests due poorman update.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-050","dir":"Changelog","previous_headings":"","what":"datawizard 0.5.0","title":"datawizard 0.5.0","text":"CRAN release: 2022-08-07 MAJOR CHANGES Following statistical transformation functions renamed data_*() prefix, since work exclusively data frames, typically first used vectors, therefore misleading names: data_cut() -> categorize() data_recode() -> change_code() data_shift() -> slide() data_reverse() -> reverse() data_rescale() -> rescale() data_to_factor() -> to_factor() data_to_numeric() -> to_numeric() Note functions also .data.frame() methods still work data frames well. Former function names still available aliases, deprecated removed future release. Bumps needed minimum R version 3.5. Removed deprecated function data_findcols(). Please use replacement, data_find(). Removed alias extract() data_extract() function since collided tidyr::extract(). Argument training_proportion data_partition() deprecated. Please use proportion now. Given continued significant contributions package, Etienne Bacher (@etiennebacher) now included author. unstandardise() now works center(x) unnormalize() now works change_scale(x) reshape_wider() now follows consistently tidyr::pivot_wider() syntax. Arguments colnames_from, sep, rows_from deprecated replaced names_from, names_sep, id_cols respectively. reshape_wider() also gains argument names_glue (#182, #198). Similarly, reshape_longer() now follows consistently tidyr::pivot_longer() syntax. Argument colnames_to deprecated replaced names_to. reshape_longer() also gains new arguments: names_prefix, names_sep, names_pattern, values_drop_na (#189). CHANGES text formatting helpers (like text_concatenate()) gain enclose argument, wrap text elements surrounding characters. winsorize now accepts “raw” “zscore” methods (addition “percentile”). Additionally, robust set TRUE together method = \"zscore\", winsorizes via median median absolute deviation (MAD); else via mean standard deviation. (@rempsyc, #177, #49, #47). convert_na_to now accepts numeric replacements character vectors single replacement multiple vector classes. (@rempsyc, #214). data_partition() now allows create multiple partitions data, returning multiple training remaining test set. Functions like center(), normalize() standardize() longer fail data contains infinite values (Inf). NEW FUNCTIONS row_to_colnames() colnames_to_row() move row column names, column names row (@etiennebacher, #169). data_arrange() sort rows dataframe according values selected columns. BUG FIXES Fixed wrong column names data_to_wide() (#173).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-041","dir":"Changelog","previous_headings":"","what":"datawizard 0.4.1","title":"datawizard 0.4.1","text":"CRAN release: 2022-05-16 BREAKING Added standardize.default() method (moved package effectsize), consistent default-method now package generic. standardize.default() behaves exactly like effectsize particularly works regression model objects. effectsize now re-exports standardize() datawizard. NEW FUNCTIONS data_shift() shift value range numeric variables. data_recode() recode old new values. data_to_factor() counterpart data_to_numeric(). data_tabulate() create frequency tables variables. data_read() read (import) data files (text, foreign statistical packages). unnormalize() counterpart normalize(). function works variables normalized normalize(). data_group() data_ungroup() create grouped data frames, remove grouping information grouped data frames. CHANGES data_find() added alias find_colums(), consistent name patterns datawizard functions. data_findcols() removed future update usage discouraged. select argument (thus, also exclude argument) now also accepts functions testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3). Arguments select exclude now allow negation select-helpers, like -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Many functions now get .default method, capture unsupported classes. now yields message returns original input, hence, .data.frame methods won’t stop due error. filter argument data_filter() can also numeric vector, indicate row indices rows returned. convert_to_na() gets methods variables class logical Date. convert_to_na() factors (data frames) gains drop_levels argument, drop unused levels replaced NA. data_to_numeric() gains two arguments, preserve_levels lowest, give better control conversion factors. BUG FIXES logicals passed center() standardize() force = TRUE, properly converted numeric variables.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-040","dir":"Changelog","previous_headings":"","what":"datawizard 0.4.0","title":"datawizard 0.4.0","text":"CRAN release: 2022-03-30 MAJOR CHANGES data_match() now returns filtered data default. Old behavior (returning rows indices) can set setting return_indices = TRUE. following functions now re-exported insight package: object_has_names(), object_has_rownames(), is_empty_object(), compact_list(), compact_character() data_findcols() become deprecated future updates. Please use new replacements find_columns() get_columns(). vignette Analysing Longitudinal Panel Data now moved parameters package. NEW FUNCTIONS convert rownames column, vice versa: rownames_as_column() column_as_rownames() (@etiennebacher, #80). find_columns() get_columns() find column names retrieve subsets data frames, based various select-methods (including select-helpers). function supersede data_findcols() future. data_filter() complement data_match(), works logical expressions filtering rows data frames. computing weighted centrality measures dispersion: weighted_mean(), weighted_median(), weighted_sd() weighted_mad(). replace NA vectors dataframes: convert_na_to() (@etiennebacher, #111). MINOR CHANGES select argument several functions (like data_remove(), reshape_longer(), data_extract()) now allows use select-helpers selecting variables based specific patterns. data_extract() gains new arguments allow type-safe return values, .e. always return vector data frame. Thus, data_extract() can now used select multiple variables pull single variable data frames. data_match() gains match argument, indicate logical operation matching results combined. Improved support labelled data many functions, .e. returned data frame preserve value variable label attributes, possible applicable. describe_distribution() now works lists (@etiennebacher, #105). data_rename() doesn’t use pattern anymore rename columns replacement provided (@etiennebacher, #103). data_rename() now adds suffix duplicated names replacement (@etiennebacher, #103). BUG FIXES data_to_numeric() produced wrong results factors dummy_factors = TRUE factor contained missing values. data_match() produced wrong results data contained missing values. Fixed CRAN check issues data_extract() one variable extracted data frame.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-030","dir":"Changelog","previous_headings":"","what":"datawizard 0.3.0","title":"datawizard 0.3.0","text":"CRAN release: 2022-03-02 NEW FUNCTIONS find remove empty rows columns data frame: empty_rows(), empty_columns(), remove_empty_rows(), remove_empty_columns(), remove_empty. check names: object_has_names() object_has_rownames(). rotate data frames: data_rotate(). reverse score variables: data_reverse(). merge/join multiple data frames: data_merge() (alias data_join()). cut (recode) data groups: data_cut(). replace specific values NAs: convert_to_na(). replace Inf NaN values NAs: replace_nan_inf(). Arguments cols, data_relocate() can now also numeric values, indicating position destination column.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-023","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.3","title":"datawizard 0.2.3","text":"CRAN release: 2022-01-26 New functions: work lists: is_empty_object() compact_list() work strings: compact_character()","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-022","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.2","title":"datawizard 0.2.2","text":"CRAN release: 2022-01-04 New function data_extract() (alias extract()) pull single variables data frame, possibly naming value row names data frame. reshape_ci() gains ci_type argument, reshape data frames CI-columns prefixes \"CI\". standardize() center() gain arguments center scale, define references centrality deviation used centering standardizing variables. center() gains arguments force reference, similar standardize(). functionality append argument center() standardize() revised. made suffix argument redundant, thus removed. Fixed issue standardize(). Fixed issue data_findcols().","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-021","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.1","title":"datawizard 0.2.1","text":"CRAN release: 2021-10-04 Exports plot method visualisation_recipe() objects see package. centre(), standardise(), unstandardise() exported aliases center(), standardize(), unstandardize(), respectively.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0201","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.0.1","title":"datawizard 0.2.0.1","text":"CRAN release: 2021-09-02 mainly maintenance release addresses issues conflicting namespaces.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-020","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.0","title":"datawizard 0.2.0","text":"CRAN release: 2021-08-17 New function: visualisation_recipe(). following function now moved performance package: check_multimodal(). Minor updates documentation, including new vignette demean().","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-010","dir":"Changelog","previous_headings":"","what":"datawizard 0.1.0","title":"datawizard 0.1.0","text":"CRAN release: 2021-06-18 First release.","code":""}]
