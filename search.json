[{"path":[]},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement patilindrajeet.science@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/datawizard/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to datawizard","title":"Contributing to datawizard","text":"outlines propose change datawizard.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to datawizard","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. want fix typos documentation, please edit related .R file R/ folder. edit .Rd file man/.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"filing-an-issue","dir":"","previous_headings":"","what":"Filing an issue","title":"Contributing to datawizard","text":"easiest way propose change new feature file issue. ’ve found bug, may also create associated issue. possible, try illustrate proposal bug minimal reproducible example.","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to datawizard","text":"Please create Git branch pull request (PR). contributed code roughly follow R style guide, particular easystats convention code-style. datawizard uses roxygen2, Markdown syntax, documentation. datawizard uses testthat. Adding tests PR makes easier merge PR code base. PR user-visible change, may add bullet top NEWS.md describing changes made. may optionally add GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://easystats.github.io/datawizard/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to datawizard","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://easystats.github.io/datawizard/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with {datawizard}","title":"Getting help with {datawizard}","text":"Thanks using datawizard. filing issue, places explore pieces put together make process smooth possible. Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! resource used tidyverse team. Armed reprex, next step figure ask: ’s question: start StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed. Thanks help!","code":""},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Data Standardization","text":"make sense data effects, scientists might want standardize (Z-score) variables. makes data unitless, expressed terms deviation index centrality (e.g., mean median). However, aside benefits, standardization also comes challenges issues, scientist aware .","code":""},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"methods-of-standardization","dir":"Articles","previous_headings":"Introduction","what":"Methods of Standardization","title":"Data Standardization","text":"datawizard package offers two methods standardization via standardize() function: Normal standardization: center around mean, SD units (default). Robust standardization: center around median, MAD (median absolute deviation) units (robust = TRUE). Let’s look following example: can see different methods give different central variation values: standardize() can also used standardize full data frame - numeric variable standardized separately: Weighted standardization also supported via weights argument, factors can also standardized (’re kind thing) setting force = TRUE, converts factors treatment-coded dummy variables standardizing.","code":"library(datawizard) library(effectsize) # for data  # let's have a look at what the data look like data(\"hardlyworking\", package = \"effectsize\") head(hardlyworking) #>     salary xtra_hours n_comps age seniority #> 1 19744.65   4.161812       1  32         3 #> 2 11301.95   1.621868       0  34         3 #> 3 20635.62   1.190859       3  33         5 #> 4 23047.16   7.190997       1  35         3 #> 5 27342.15  11.261399       0  33         4 #> 6 25656.63   3.633346       2  30         5 # let's use both methods of standardization hardlyworking$xtra_hours_z <- standardize(hardlyworking$xtra_hours) hardlyworking$xtra_hours_zr <- standardize(hardlyworking$xtra_hours, robust = TRUE) library(dplyr)  hardlyworking %>%   select(starts_with(\"xtra_hours\")) %>%   data_to_long() %>%   group_by(Name) %>%   summarise(     mean = mean(Value),     sd = sd(Value),     median = median(Value),     mad = mad(Value)   ) hardlyworking_z <- standardize(hardlyworking) hardlyworking_z %>%   select(-xtra_hours_z, -xtra_hours_zr) %>%   data_to_long() %>%   group_by(Name) %>%   summarise(     mean = mean(Value),     sd = sd(Value),     median = median(Value),     mad = mad(Value)   )"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"variable-wise-vs--participant-wise","dir":"Articles","previous_headings":"Introduction","what":"Variable-wise vs. Participant-wise","title":"Data Standardization","text":"Standardization important step extra caution required repeated-measures designs, three ways standardizing data: Variable-wise: common method. simple scaling column. Participant-wise: Variables standardized “within” participant, .e., participant, participant’s mean SD. Full: Participant-wise first re-standardizing variable-wise. Unfortunately, method used often explicitly stated. issue methods can generate important discrepancies (can turn contribute reproducibility crisis). Let’s investigate 3 methods.","code":""},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"the-data","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"The Data","title":"Data Standardization","text":"take emotion dataset participants exposed negative pictures rate emotions (valence) amount memories associated picture (autobiographical link). One make hypothesis young participants context war violence, negative pictures (mutilations) less related memories less negative pictures (involving example car crashes sick people). words, expect positive relationship valence (high values corresponding less negativity) autobiographical link. Let’s look data, averaged participants: can see means SDs, lot variability participants means individual within-participant SD.","code":"# Download the 'emotion' dataset load(url(\"https://raw.githubusercontent.com/neuropsychology/psycho.R/master/data/emotion.rda\"))  # Discard neutral pictures (keep only negative) emotion <- emotion %>% filter(Emotion_Condition == \"Negative\")  # Summary emotion %>%   drop_na(Subjective_Valence, Autobiographical_Link) %>%   group_by(Participant_ID) %>%   summarise(     n_Trials = n(),     Valence_Mean = mean(Subjective_Valence),     Valence_SD = sd(Subjective_Valence)   ) #> # A tibble: 19 × 4 #> # Groups:   Participant_ID [19] #>    Participant_ID n_Trials Valence_Mean Valence_SD #>    <fct>             <int>        <dbl>      <dbl> #>  1 10S                  24       -58.1       42.6  #>  2 11S                  24       -73.2       37.0  #>  3 12S                  24       -57.5       26.6  #>  4 13S                  24       -63.2       23.7  #>  5 14S                  24       -56.6       26.5  #>  6 15S                  24       -60.6       33.7  #>  7 16S                  24       -46.1       24.9  #>  8 17S                  24        -1.54       4.98 #>  9 18S                  24       -67.2       35.0  #> 10 19S                  24       -59.6       33.2  #> 11 1S                   24       -53.0       42.9  #> 12 2S                   23       -43.0       39.2  #> 13 3S                   24       -64.3       34.4  #> 14 4S                   24       -81.6       27.6  #> 15 5S                   24       -58.1       25.3  #> 16 6S                   24       -74.7       29.2  #> 17 7S                   24       -62.3       39.7  #> 18 8S                   24       -56.9       32.7  #> 19 9S                   24       -31.5       52.7"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"effect-of-standardization","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Effect of Standardization","title":"Data Standardization","text":"create three data frames standardized three techniques. Let’s see three standardization techniques affected Valence variable.","code":"Z_VariableWise <- emotion %>%   standardize()  Z_ParticipantWise <- emotion %>%   group_by(Participant_ID) %>%   standardize()  Z_Full <- emotion %>%   group_by(Participant_ID) %>%   standardize() %>%   ungroup() %>%   standardize()"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"across-participants","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Across Participants","title":"Data Standardization","text":"can calculate mean SD Valence across participants: means SD appear fairly similar (0 1)…  marginal distributions…","code":"# Create a convenient function to print summarise_Subjective_Valence <- function(data) {   df_name <- deparse(substitute(data))   data %>%     ungroup() %>%     summarise(       DF = df_name,       Mean = mean(Subjective_Valence),       SD = sd(Subjective_Valence)     ) } # Check the results rbind(   summarise_Subjective_Valence(Z_VariableWise),   summarise_Subjective_Valence(Z_ParticipantWise),   summarise_Subjective_Valence(Z_Full) ) library(see) library(ggplot2)  ggplot() +   geom_density(aes(Z_VariableWise$Subjective_Valence,     color = \"Z_VariableWise\"   ), size = 1) +   geom_density(aes(Z_ParticipantWise$Subjective_Valence,     color = \"Z_ParticipantWise\"   ), size = 1) +   geom_density(aes(Z_Full$Subjective_Valence,     color = \"Z_Full\"   ), size = 1) +   see::theme_modern() +   labs(color = \"\")"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"at-the-participant-level","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"At the Participant Level","title":"Data Standardization","text":"However, can also look happens participant level. Let’s look first 5 participants: Seems like full participant-wise standardization give similar results, different ones variable-wise standardization.","code":"# Create convenient function print_participants <- function(data) {   df_name <- deparse(substitute(data))   data %>%     group_by(Participant_ID) %>%     summarise(       DF = df_name,       Mean = mean(Subjective_Valence),       SD = sd(Subjective_Valence)     ) %>%     head(5) %>%     select(DF, everything()) }  # Check the results rbind(   print_participants(Z_VariableWise),   print_participants(Z_ParticipantWise),   print_participants(Z_Full) )"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"compare","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Compare","title":"Data Standardization","text":"Let’s correlation variable-wise participant-wise methods.  three standardization methods roughly present characteristics general level (mean 0 SD 1) similar distribution, values exactly ! Let’s now answer original question investigating linear relationship valence autobiographical link. can running mixed-effects model participants entered random effects. can extract parameters interest model, find: can see, variable-wise standardization affects coefficient (expected, changes unit), test statistic statistical significance. However, using participant-wise standardization affect coefficient significance. method better justified, choice depends specific case, context, data goal.","code":"r <- cor.test(   Z_VariableWise$Subjective_Valence,   Z_ParticipantWise$Subjective_Valence )  data.frame(   Original = emotion$Subjective_Valence,   VariableWise = Z_VariableWise$Subjective_Valence,   ParticipantWise = Z_ParticipantWise$Subjective_Valence ) %>%   ggplot(aes(x = VariableWise, y = ParticipantWise, colour = Original)) +   geom_point(alpha = 0.75, shape = 16) +   geom_smooth(method = \"lm\", color = \"black\") +   scale_color_distiller(palette = 1) +   ggtitle(paste0(\"r = \", round(r$estimate, 2))) +   see::theme_modern() library(lme4) m_raw <- lmer(   formula = Subjective_Valence ~ Autobiographical_Link + (1 | Participant_ID),   data = emotion ) m_VariableWise <- update(m_raw, data = Z_VariableWise) m_ParticipantWise <- update(m_raw, data = Z_ParticipantWise) m_Full <- update(m_raw, data = Z_Full) # Convenient function get_par <- function(model) {   mod_name <- deparse(substitute(model))   parameters::model_parameters(model) %>%     mutate(Model = mod_name) %>%     select(-Parameter) %>%     select(Model, everything()) %>%     .[-1, ] }  # Run the model on all datasets rbind(   get_par(m_raw),   get_par(m_VariableWise),   get_par(m_ParticipantWise),   get_par(m_Full) ) #> # Fixed Effects #>  #> Model             | Coefficient |   SE |        95% CI | t(451) |     p #> ----------------------------------------------------------------------- #> m_raw             |        0.09 | 0.07 | [-0.04, 0.22] |   1.36 | 0.174 #> m_VariableWise    |        0.07 | 0.05 | [-0.03, 0.17] |   1.36 | 0.174 #> m_ParticipantWise |        0.08 | 0.05 | [-0.01, 0.17] |   1.75 | 0.080 #> m_Full            |        0.08 | 0.05 | [-0.01, 0.17] |   1.75 | 0.080 #>  #> # Random Effects: Participant_ID #>  #> Model             | Coefficient #> ------------------------------- #> m_raw             |       16.49 #> m_VariableWise    |        0.45 #> m_ParticipantWise |        0.00 #> m_Full            |        0.00 #>  #> # Random Effects: Residual #>  #> Model             | Coefficient #> ------------------------------- #> m_raw             |       33.56 #> m_VariableWise    |        0.91 #> m_ParticipantWise |        0.98 #> m_Full            |        1.00"},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"conclusion","dir":"Articles","previous_headings":"Introduction > Variable-wise vs. Participant-wise","what":"Conclusion","title":"Data Standardization","text":"Standardization can useful cases justified. Variable Participant-wise standardization methods appear produce similar data. Variable Participant-wise standardization can lead different results. chosen method can strongly influence results therefore explicitly stated justified enhance reproducibility results. showed yet another way sneakily tweaking data can change results. prevent use bad practice, can highlight importance open data, open analysis/scripts, preregistration.","code":""},{"path":"https://easystats.github.io/datawizard/articles/standardize_data.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See also","title":"Data Standardization","text":"datawizard::demean(): https://easystats.github.io/datawizard/reference/demean.html standardize_parameters(method = \"pseudo\") mixed-effects models https://easystats.github.io/parameters/articles/model_parameters_standardized.html","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Coming from 'tidyverse'","text":"datawizard package aims make basic data wrangling easier base R. data wrangling workflow supports similar one supported tidyverse package combination dplyr tidyr. However, one main features dependencies: {stats} {utils} (included base R) insight, core package easystats ecosystem. package grew organically simultaneously satisfy “0 non-base hard dependency” principle easystats data wrangling needs constituent packages ecosystem. One drawback genesis features tidyverse packages supported since features necessary easystats ecosystem implemented. missing features (summarize pipe operator %>%) made available dependency-free packages, {poorman}. also important note datawizard designed avoid namespace collisions tidyverse packages. article, see go basic data wrangling steps datawizard. also compare tidyverse syntax achieving . way, decide make switch, can easily find translations . vignette largely inspired dplyr’s Getting started vignette.","code":"library(dplyr) library(tidyr) library(datawizard)"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"workhorses","dir":"Articles","previous_headings":"","what":"Workhorses","title":"Coming from 'tidyverse'","text":"look tidyverse equivalents, can first look datawizard’s key functions data wrangling: Note functions datawizard strict equivalent dplyr tidyr (e.g data_rotate()), won’t discuss next section.","code":""},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"equivalence-with-dplyr-tidyr","dir":"Articles","previous_headings":"","what":"Equivalence with {dplyr} / {tidyr}","title":"Coming from 'tidyverse'","text":"look individually, let’s first look summary table equivalence.","code":""},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"filtering","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Filtering","title":"Coming from 'tidyverse'","text":"data_filter() wrapper around subset(). Therefore, want several filtering conditions, need use &. Separating conditions comma (dplyr::filter()) work; apply first condition.","code":"# ---------- datawizard ----------- starwars %>%   data_filter(skin_color == \"light\" &     eye_color == \"brown\") # ---------- tidyverse ----------- starwars %>%   filter(     skin_color == \"light\",     eye_color == \"brown\"   ) ## # A tibble: 7 × 14 ##   name         height  mass hair_…¹ skin_…² eye_c…³ birth…⁴ sex   gender homew…⁵ ##   <chr>         <int> <dbl> <chr>   <chr>   <chr>     <dbl> <chr> <chr>  <chr>   ## 1 Leia Organa     150    49 brown   light   brown        19 fema… femin… Aldera… ## 2 Biggs Darkl…    183    84 black   light   brown        24 male  mascu… Tatooi… ## 3 Cordé           157    NA brown   light   brown        NA fema… femin… Naboo   ## 4 Dormé           165    NA brown   light   brown        NA fema… femin… Naboo   ## 5 Raymus Anti…    188    79 brown   light   brown        NA male  mascu… Aldera… ## 6 Poe Dameron      NA    NA brown   light   brown        NA male  mascu… NA      ## 7 Padmé Amida…    165    45 brown   light   brown        46 fema… femin… Naboo   ## # … with 4 more variables: species <chr>, films <list>, vehicles <list>, ## #   starships <list>, and abbreviated variable names ¹​hair_color, ²​skin_color, ## #   ³​eye_color, ⁴​birth_year, ⁵​homeworld"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"selecting","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Selecting","title":"Coming from 'tidyverse'","text":"data_select() equivalent dplyr::select(). main difference two functions data_select() uses two arguments (select exclude) requires quoted column names want select several variables, dplyr::select() accepts unquoted column names. can find list select helpers ?data_select.","code":"# ---------- datawizard ----------- starwars %>%   data_select(select = c(\"hair_color\", \"skin_color\", \"eye_color\")) # ---------- tidyverse ----------- starwars %>%   select(hair_color, skin_color, eye_color) ## # A tibble: 6 × 3 ##   hair_color  skin_color  eye_color ## * <chr>       <chr>       <chr>     ## 1 blond       fair        blue      ## 2 NA          gold        yellow    ## 3 NA          white, blue red       ## 4 none        white       yellow    ## 5 brown       light       brown     ## 6 brown, grey light       blue # ---------- datawizard ----------- starwars %>%   data_select(select = -ends_with(\"color\")) # ---------- tidyverse ----------- starwars %>%   select(-ends_with(\"color\")) ## # A tibble: 6 × 11 ##   name   height  mass birth…¹ sex   gender homew…² species films vehic…³ stars…⁴ ## * <chr>   <int> <dbl>   <dbl> <chr> <chr>  <chr>   <chr>   <lis> <list>  <list>  ## 1 Luke …    172    77    19   male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## 2 C-3PO     167    75   112   none  mascu… Tatooi… Droid   <chr> <chr>   <chr>   ## 3 R2-D2      96    32    33   none  mascu… Naboo   Droid   <chr> <chr>   <chr>   ## 4 Darth…    202   136    41.9 male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## 5 Leia …    150    49    19   fema… femin… Aldera… Human   <chr> <chr>   <chr>   ## 6 Owen …    178   120    52   male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## # … with abbreviated variable names ¹​birth_year, ²​homeworld, ³​vehicles, ## #   ⁴​starships # ---------- datawizard ----------- starwars %>%   data_select(select = -hair_color:eye_color) # ---------- tidyverse ----------- starwars %>%   select(!(hair_color:eye_color)) ## # A tibble: 6 × 11 ##   name   height  mass birth…¹ sex   gender homew…² species films vehic…³ stars…⁴ ## * <chr>   <int> <dbl>   <dbl> <chr> <chr>  <chr>   <chr>   <lis> <list>  <list>  ## 1 Luke …    172    77    19   male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## 2 C-3PO     167    75   112   none  mascu… Tatooi… Droid   <chr> <chr>   <chr>   ## 3 R2-D2      96    32    33   none  mascu… Naboo   Droid   <chr> <chr>   <chr>   ## 4 Darth…    202   136    41.9 male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## 5 Leia …    150    49    19   fema… femin… Aldera… Human   <chr> <chr>   <chr>   ## 6 Owen …    178   120    52   male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## # … with abbreviated variable names ¹​birth_year, ²​homeworld, ³​vehicles, ## #   ⁴​starships # ---------- datawizard ----------- starwars %>%   data_select(exclude = regex(\"color$\")) # ---------- tidyverse ----------- starwars %>%   select(-contains(\"color$\")) ## # A tibble: 6 × 11 ##   name   height  mass birth…¹ sex   gender homew…² species films vehic…³ stars…⁴ ## * <chr>   <int> <dbl>   <dbl> <chr> <chr>  <chr>   <chr>   <lis> <list>  <list>  ## 1 Luke …    172    77    19   male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## 2 C-3PO     167    75   112   none  mascu… Tatooi… Droid   <chr> <chr>   <chr>   ## 3 R2-D2      96    32    33   none  mascu… Naboo   Droid   <chr> <chr>   <chr>   ## 4 Darth…    202   136    41.9 male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## 5 Leia …    150    49    19   fema… femin… Aldera… Human   <chr> <chr>   <chr>   ## 6 Owen …    178   120    52   male  mascu… Tatooi… Human   <chr> <chr>   <chr>   ## # … with abbreviated variable names ¹​birth_year, ²​homeworld, ³​vehicles, ## #   ⁴​starships # ---------- datawizard ----------- starwars %>%   data_select(select = is.numeric) # ---------- tidyverse ----------- starwars %>%   select(where(is.numeric)) ## # A tibble: 6 × 3 ##   height  mass birth_year ## *  <int> <dbl>      <dbl> ## 1    172    77       19   ## 2    167    75      112   ## 3     96    32       33   ## 4    202   136       41.9 ## 5    150    49       19   ## 6    178   120       52"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"sorting","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Sorting","title":"Coming from 'tidyverse'","text":"data_arrange() equivalent dplyr::arrange(). takes two arguments: data frame, vector column names used sort rows. Note contrary functions datawizard, possible use select helpers starts_with() data_arrange(). can also sort variables descending order putting \"-\" front name, like :","code":"# ---------- datawizard ----------- starwars %>%   data_arrange(c(\"hair_color\", \"height\")) # ---------- tidyverse ----------- starwars %>%   arrange(hair_color, height) ## # A tibble: 6 × 14 ##   name         height  mass hair_…¹ skin_…² eye_c…³ birth…⁴ sex   gender homew…⁵ ##   <chr>         <int> <dbl> <chr>   <chr>   <chr>     <dbl> <chr> <chr>  <chr>   ## 1 Luke Skywal…    172    77 blond   fair    blue       19   male  mascu… Tatooi… ## 2 Leia Organa     150    49 brown   light   brown      19   fema… femin… Aldera… ## 3 Owen Lars       178   120 brown,… light   blue       52   male  mascu… Tatooi… ## 4 Darth Vader     202   136 none    white   yellow     41.9 male  mascu… Tatooi… ## 5 R2-D2            96    32 NA      white,… red        33   none  mascu… Naboo   ## 6 C-3PO           167    75 NA      gold    yellow    112   none  mascu… Tatooi… ## # … with 4 more variables: species <chr>, films <list>, vehicles <list>, ## #   starships <list>, and abbreviated variable names ¹​hair_color, ²​skin_color, ## #   ³​eye_color, ⁴​birth_year, ⁵​homeworld # ---------- datawizard ----------- starwars %>%   data_arrange(c(\"-hair_color\", \"-height\")) # ---------- tidyverse ----------- starwars %>%   arrange(desc(hair_color), -height) ## # A tibble: 6 × 14 ##   name         height  mass hair_…¹ skin_…² eye_c…³ birth…⁴ sex   gender homew…⁵ ##   <chr>         <int> <dbl> <chr>   <chr>   <chr>     <dbl> <chr> <chr>  <chr>   ## 1 Darth Vader     202   136 none    white   yellow     41.9 male  mascu… Tatooi… ## 2 Owen Lars       178   120 brown,… light   blue       52   male  mascu… Tatooi… ## 3 Leia Organa     150    49 brown   light   brown      19   fema… femin… Aldera… ## 4 Luke Skywal…    172    77 blond   fair    blue       19   male  mascu… Tatooi… ## 5 C-3PO           167    75 NA      gold    yellow    112   none  mascu… Tatooi… ## 6 R2-D2            96    32 NA      white,… red        33   none  mascu… Naboo   ## # … with 4 more variables: species <chr>, films <list>, vehicles <list>, ## #   starships <list>, and abbreviated variable names ¹​hair_color, ²​skin_color, ## #   ³​eye_color, ⁴​birth_year, ⁵​homeworld"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"extracting","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Extracting","title":"Coming from 'tidyverse'","text":"Although mostly work data frames, sometimes useful extract single column vector. can done data_extract(), reproduces behavior dplyr::pull(): can also specify several variables select. case, data_extract() equivalent data_select():","code":"# ---------- datawizard ----------- starwars %>%   data_extract(gender) # ---------- tidyverse ----------- starwars %>%   pull(gender) ## [1] \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"feminine\"  \"masculine\" starwars %>%   data_extract(select = contains(\"color\")) ## # A tibble: 6 × 3 ##   hair_color  skin_color  eye_color ##   <chr>       <chr>       <chr>     ## 1 blond       fair        blue      ## 2 NA          gold        yellow    ## 3 NA          white, blue red       ## 4 none        white       yellow    ## 5 brown       light       brown     ## 6 brown, grey light       blue"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"renaming","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Renaming","title":"Coming from 'tidyverse'","text":"data_rename() equivalent dplyr::rename() syntax two different. dplyr::rename() takes new-old pairs column names, data_rename() requires vector column names rename, vector new names columns must length. way data_rename() designed makes easy apply modifications vector column names. example, can remove underscores use TitleCase following code: also possible add prefix suffix subset variables data_addprefix() data_addsuffix(). argument select accepts select helpers saw data_select():","code":"# ---------- datawizard ----------- starwars %>%   data_rename(     pattern = c(\"sex\", \"hair_color\"),     replacement = c(\"Sex\", \"Hair Color\")   ) # ---------- tidyverse ----------- starwars %>%   rename(     Sex = sex,     \"Hair Color\" = hair_color   ) ## # A tibble: 6 × 14 ##   name         height  mass Hair …¹ skin_…² eye_c…³ birth…⁴ Sex   gender homew…⁵ ##   <chr>         <int> <dbl> <chr>   <chr>   <chr>     <dbl> <chr> <chr>  <chr>   ## 1 Luke Skywal…    172    77 blond   fair    blue       19   male  mascu… Tatooi… ## 2 C-3PO           167    75 NA      gold    yellow    112   none  mascu… Tatooi… ## 3 R2-D2            96    32 NA      white,… red        33   none  mascu… Naboo   ## 4 Darth Vader     202   136 none    white   yellow     41.9 male  mascu… Tatooi… ## 5 Leia Organa     150    49 brown   light   brown      19   fema… femin… Aldera… ## 6 Owen Lars       178   120 brown,… light   blue       52   male  mascu… Tatooi… ## # … with 4 more variables: species <chr>, films <list>, vehicles <list>, ## #   starships <list>, and abbreviated variable names ¹​`Hair Color`, ## #   ²​skin_color, ³​eye_color, ⁴​birth_year, ⁵​homeworld to_rename <- names(starwars)  starwars %>%   data_rename(     pattern = to_rename,     replacement = tools::toTitleCase(gsub(\"_\", \" \", to_rename))   ) ## # A tibble: 6 × 14 ##   Name         Height  Mass Hair …¹ Skin …² Eye C…³ Birth…⁴ Sex   Gender Homew…⁵ ##   <chr>         <int> <dbl> <chr>   <chr>   <chr>     <dbl> <chr> <chr>  <chr>   ## 1 Luke Skywal…    172    77 blond   fair    blue       19   male  mascu… Tatooi… ## 2 C-3PO           167    75 NA      gold    yellow    112   none  mascu… Tatooi… ## 3 R2-D2            96    32 NA      white,… red        33   none  mascu… Naboo   ## 4 Darth Vader     202   136 none    white   yellow     41.9 male  mascu… Tatooi… ## 5 Leia Organa     150    49 brown   light   brown      19   fema… femin… Aldera… ## 6 Owen Lars       178   120 brown,… light   blue       52   male  mascu… Tatooi… ## # … with 4 more variables: Species <chr>, Films <list>, Vehicles <list>, ## #   Starships <list>, and abbreviated variable names ¹​`Hair Color`, ## #   ²​`Skin Color`, ³​`Eye Color`, ⁴​`Birth Year`, ⁵​Homeworld starwars %>%   data_addprefix(     pattern = \"OLD.\",     select = contains(\"color\")   ) %>%   data_addsuffix(     pattern = \".NEW\",     select = -contains(\"color\")   ) ## # A tibble: 6 × 14 ##   name.NEW       heigh…¹ mass.…² OLD.h…³ OLD.s…⁴ OLD.e…⁵ birth…⁶ sex.NEW gende…⁷ ##   <chr>            <int>   <dbl> <chr>   <chr>   <chr>     <dbl> <chr>   <chr>   ## 1 Luke Skywalker     172      77 blond   fair    blue       19   male    mascul… ## 2 C-3PO              167      75 NA      gold    yellow    112   none    mascul… ## 3 R2-D2               96      32 NA      white,… red        33   none    mascul… ## 4 Darth Vader        202     136 none    white   yellow     41.9 male    mascul… ## 5 Leia Organa        150      49 brown   light   brown      19   female  femini… ## 6 Owen Lars          178     120 brown,… light   blue       52   male    mascul… ## # … with 5 more variables: homeworld.NEW <chr>, species.NEW <chr>, ## #   films.NEW <list>, vehicles.NEW <list>, starships.NEW <list>, and ## #   abbreviated variable names ¹​height.NEW, ²​mass.NEW, ³​OLD.hair_color, ## #   ⁴​OLD.skin_color, ⁵​OLD.eye_color, ⁶​birth_year.NEW, ⁷​gender.NEW"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"relocating","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Relocating","title":"Coming from 'tidyverse'","text":"Sometimes, want relocate one small subset columns dataset. Rather typing many names data_select(), can use data_relocate(), equivalent dplyr::relocate(). Just like data_select(), can specify list variables want relocate select exclude. , arguments after1 specify selected columns relocated: addition column names, accept column indices. Finally, one can use = -1 relocate selected columns just last column, = -1 relocate last column.","code":"# ---------- datawizard ----------- starwars %>%   data_relocate(sex:homeworld, before = \"height\") # ---------- tidyverse ----------- starwars %>%   relocate(sex:homeworld, .before = height) ## # A tibble: 6 × 14 ##   name         sex   gender homew…¹ height  mass hair_…² skin_…³ eye_c…⁴ birth…⁵ ## * <chr>        <chr> <chr>  <chr>    <int> <dbl> <chr>   <chr>   <chr>     <dbl> ## 1 Luke Skywal… male  mascu… Tatooi…    172    77 blond   fair    blue       19   ## 2 C-3PO        none  mascu… Tatooi…    167    75 NA      gold    yellow    112   ## 3 R2-D2        none  mascu… Naboo       96    32 NA      white,… red        33   ## 4 Darth Vader  male  mascu… Tatooi…    202   136 none    white   yellow     41.9 ## 5 Leia Organa  fema… femin… Aldera…    150    49 brown   light   brown      19   ## 6 Owen Lars    male  mascu… Tatooi…    178   120 brown,… light   blue       52   ## # … with 4 more variables: species <chr>, films <list>, vehicles <list>, ## #   starships <list>, and abbreviated variable names ¹​homeworld, ²​hair_color, ## #   ³​skin_color, ⁴​eye_color, ⁵​birth_year # ---------- datawizard ----------- starwars %>%   data_relocate(sex:homeworld, after = -1) ## # A tibble: 6 × 14 ##   name        height  mass hair_…¹ skin_…² eye_c…³ birth…⁴ species films vehic…⁵ ## * <chr>        <int> <dbl> <chr>   <chr>   <chr>     <dbl> <chr>   <lis> <list>  ## 1 Luke Skywa…    172    77 blond   fair    blue       19   Human   <chr> <chr>   ## 2 C-3PO          167    75 NA      gold    yellow    112   Droid   <chr> <chr>   ## 3 R2-D2           96    32 NA      white,… red        33   Droid   <chr> <chr>   ## 4 Darth Vader    202   136 none    white   yellow     41.9 Human   <chr> <chr>   ## 5 Leia Organa    150    49 brown   light   brown      19   Human   <chr> <chr>   ## 6 Owen Lars      178   120 brown,… light   blue       52   Human   <chr> <chr>   ## # … with 4 more variables: starships <list>, sex <chr>, gender <chr>, ## #   homeworld <chr>, and abbreviated variable names ¹​hair_color, ²​skin_color, ## #   ³​eye_color, ⁴​birth_year, ⁵​vehicles"},{"path":[]},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"longer","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Reshaping","what":"Longer","title":"Coming from 'tidyverse'","text":"Reshaping data wide long long wide format can done data_to_long() data_to_wide(). functions designed match tidyr::pivot_longer() tidyr::pivot_wider() arguments, thing change function name. However, tidyr::pivot_longer() tidyr::pivot_wider() features available yet. use relig_income dataset, {tidyr} vignette. like reshape dataset 3 columns: religion, count, income. column “religion” doesn’t need change, exclude -religion. , remaining column corresponds income category. Therefore, want move column names single column called “income”. Finally, values corresponding columns reshaped single new column, called “count”. explore bit arguments data_to_long(), use another dataset: billboard dataset.","code":"relig_income ## # A tibble: 18 × 11 ##    religion      `<$10k` $10-2…¹ $20-3…² $30-4…³ $40-5…⁴ $50-7…⁵ $75-1…⁶ $100-…⁷ ##    <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> ##  1 Agnostic           27      34      60      81      76     137     122     109 ##  2 Atheist            12      27      37      52      35      70      73      59 ##  3 Buddhist           27      21      30      34      33      58      62      39 ##  4 Catholic          418     617     732     670     638    1116     949     792 ##  5 Don’t know/r…      15      14      15      11      10      35      21      17 ##  6 Evangelical …     575     869    1064     982     881    1486     949     723 ##  7 Hindu               1       9       7       9      11      34      47      48 ##  8 Historically…     228     244     236     238     197     223     131      81 ##  9 Jehovah's Wi…      20      27      24      24      21      30      15      11 ## 10 Jewish             19      19      25      25      30      95      69      87 ## 11 Mainline Prot     289     495     619     655     651    1107     939     753 ## 12 Mormon             29      40      48      51      56     112      85      49 ## 13 Muslim              6       7       9      10       9      23      16       8 ## 14 Orthodox           13      17      23      32      32      47      38      42 ## 15 Other Christ…       9       7      11      13      13      14      18      14 ## 16 Other Faiths       20      33      40      46      49      63      46      40 ## 17 Other World …       5       2       3       4       2       7       3       4 ## 18 Unaffiliated      217     299     374     365     341     528     407     321 ## # … with 2 more variables: `>150k` <dbl>, `Don't know/refused` <dbl>, and ## #   abbreviated variable names ¹​`$10-20k`, ²​`$20-30k`, ³​`$30-40k`, ⁴​`$40-50k`, ## #   ⁵​`$50-75k`, ⁶​`$75-100k`, ⁷​`$100-150k` # ---------- datawizard ----------- relig_income %>%   data_to_long(     -religion,     names_to = \"income\",     values_to = \"count\"   ) # ---------- tidyverse ----------- relig_income %>%   pivot_longer(     !religion,     names_to = \"income\",     values_to = \"count\"   ) ## # A tibble: 180 × 3 ##    religion income             count ##  * <chr>    <chr>              <dbl> ##  1 Agnostic <$10k                 27 ##  2 Agnostic $10-20k               34 ##  3 Agnostic $20-30k               60 ##  4 Agnostic $30-40k               81 ##  5 Agnostic $40-50k               76 ##  6 Agnostic $50-75k              137 ##  7 Agnostic $75-100k             122 ##  8 Agnostic $100-150k            109 ##  9 Agnostic >150k                 84 ## 10 Agnostic Don't know/refused    96 ## # … with 170 more rows billboard ## # A tibble: 317 × 79 ##    artist track date.ent…¹   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8   wk9 ##    <chr>  <chr> <date>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ##  1 2 Pac  Baby… 2000-02-26    87    82    72    77    87    94    99    NA    NA ##  2 2Ge+h… The … 2000-09-02    91    87    92    NA    NA    NA    NA    NA    NA ##  3 3 Doo… Kryp… 2000-04-08    81    70    68    67    66    57    54    53    51 ##  4 3 Doo… Loser 2000-10-21    76    76    72    69    67    65    55    59    62 ##  5 504 B… Wobb… 2000-04-15    57    34    25    17    17    31    36    49    53 ##  6 98^0   Give… 2000-08-19    51    39    34    26    26    19     2     2     3 ##  7 A*Tee… Danc… 2000-07-08    97    97    96    95   100    NA    NA    NA    NA ##  8 Aaliy… I Do… 2000-01-29    84    62    51    41    38    35    35    38    38 ##  9 Aaliy… Try … 2000-03-18    59    53    38    28    21    18    16    14    12 ## 10 Adams… Open… 2000-08-26    76    76    74    69    68    67    61    58    57 ## # … with 307 more rows, 67 more variables: wk10 <dbl>, wk11 <dbl>, wk12 <dbl>, ## #   wk13 <dbl>, wk14 <dbl>, wk15 <dbl>, wk16 <dbl>, wk17 <dbl>, wk18 <dbl>, ## #   wk19 <dbl>, wk20 <dbl>, wk21 <dbl>, wk22 <dbl>, wk23 <dbl>, wk24 <dbl>, ## #   wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>, wk30 <dbl>, ## #   wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>, wk35 <dbl>, wk36 <dbl>, ## #   wk37 <dbl>, wk38 <dbl>, wk39 <dbl>, wk40 <dbl>, wk41 <dbl>, wk42 <dbl>, ## #   wk43 <dbl>, wk44 <dbl>, wk45 <dbl>, wk46 <dbl>, wk47 <dbl>, wk48 <dbl>, … # ---------- datawizard ----------- billboard %>%   data_to_long(     cols = starts_with(\"wk\"),     names_to = \"week\",     values_to = \"rank\",     values_drop_na = TRUE   ) # ---------- tidyverse ----------- billboard %>%   pivot_longer(     cols = starts_with(\"wk\"),     names_to = \"week\",     values_to = \"rank\",     values_drop_na = TRUE   ) ## # A tibble: 5,307 × 5 ##    artist  track                   date.entered week   rank ##  * <chr>   <chr>                   <date>       <chr> <dbl> ##  1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87 ##  2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82 ##  3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72 ##  4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77 ##  5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87 ##  6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94 ##  7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99 ##  8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91 ##  9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87 ## 10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92 ## # … with 5,297 more rows"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"wider","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Reshaping","what":"Wider","title":"Coming from 'tidyverse'","text":", use example tidyr vignette show close data_to_wide() pivot_wider() :","code":"fish_encounters ## # A tibble: 114 × 3 ##    fish  station  seen ##    <fct> <fct>   <int> ##  1 4842  Release     1 ##  2 4842  I80_1       1 ##  3 4842  Lisbon      1 ##  4 4842  Rstr        1 ##  5 4842  Base_TD     1 ##  6 4842  BCE         1 ##  7 4842  BCW         1 ##  8 4842  BCE2        1 ##  9 4842  BCW2        1 ## 10 4842  MAE         1 ## # … with 104 more rows # ---------- datawizard ----------- fish_encounters %>%   data_to_wide(     names_from = \"station\",     values_from = \"seen\",     values_fill = 0   ) # ---------- tidyverse ----------- fish_encounters %>%   pivot_wider(     names_from = station,     values_from = seen,     values_fill = 0   ) ## # A tibble: 19 × 12 ##    fish  Release I80_1 Lisbon  Rstr Base_TD   BCE   BCW  BCE2  BCW2   MAE   MAW ##  * <fct>   <dbl> <dbl>  <dbl> <dbl>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ##  1 4842        1     1      1     1       1     1     1     1     1     1     1 ##  2 4843        1     1      1     1       1     1     1     1     1     1     1 ##  3 4844        1     1      1     1       1     1     1     1     1     1     1 ##  4 4845        1     1      1     1       1     0     0     0     0     0     0 ##  5 4847        1     1      1     0       0     0     0     0     0     0     0 ##  6 4848        1     1      1     1       0     0     0     0     0     0     0 ##  7 4849        1     1      0     0       0     0     0     0     0     0     0 ##  8 4850        1     1      0     1       1     1     1     0     0     0     0 ##  9 4851        1     1      0     0       0     0     0     0     0     0     0 ## 10 4854        1     1      0     0       0     0     0     0     0     0     0 ## 11 4855        1     1      1     1       1     0     0     0     0     0     0 ## 12 4857        1     1      1     1       1     1     1     1     1     0     0 ## 13 4858        1     1      1     1       1     1     1     1     1     1     1 ## 14 4859        1     1      1     1       1     0     0     0     0     0     0 ## 15 4861        1     1      1     1       1     1     1     1     1     1     1 ## 16 4862        1     1      1     1       1     1     1     1     1     0     0 ## 17 4863        1     1      0     0       0     0     0     0     0     0     0 ## 18 4864        1     1      0     0       0     0     0     0     0     0     0 ## 19 4865        1     1      1     0       0     0     0     0     0     0     0"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"joining","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr}","what":"Joining","title":"Coming from 'tidyverse'","text":"datawizard, joining datasets done data_join() (alias data_merge()). Contrary dplyr, unique function takes care types join, specified inside function argument join (default, join = \"left\"). , show perform four common joins: full, left, right inner. use datasets band_membersand band_instruments provided dplyr:","code":"band_members ## # A tibble: 3 × 2 ##   name  band    ##   <chr> <chr>   ## 1 Mick  Stones  ## 2 John  Beatles ## 3 Paul  Beatles band_instruments ## # A tibble: 3 × 2 ##   name  plays  ##   <chr> <chr>  ## 1 John  guitar ## 2 Paul  bass   ## 3 Keith guitar"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"full-join","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Joining","what":"Full join","title":"Coming from 'tidyverse'","text":"","code":"# ---------- datawizard ----------- band_members %>%   data_join(band_instruments, join = \"full\") # ---------- tidyverse ----------- band_members %>%   full_join(band_instruments) ## # A tibble: 4 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 Mick  Stones  NA     ## 2 John  Beatles guitar ## 3 Paul  Beatles bass   ## 4 Keith NA      guitar"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"left-and-right-joins","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Joining","what":"Left and right joins","title":"Coming from 'tidyverse'","text":"","code":"# ---------- datawizard ----------- band_members %>%   data_join(band_instruments, join = \"left\") # ---------- tidyverse ----------- band_members %>%   left_join(band_instruments) ## # A tibble: 3 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 Mick  Stones  NA     ## 2 John  Beatles guitar ## 3 Paul  Beatles bass # ---------- datawizard ----------- band_members %>%   data_join(band_instruments, join = \"right\") # ---------- tidyverse ----------- band_members %>%   right_join(band_instruments) ## # A tibble: 3 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 John  Beatles guitar ## 2 Paul  Beatles bass   ## 3 Keith NA      guitar"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"inner-join","dir":"Articles","previous_headings":"Equivalence with {dplyr} / {tidyr} > Joining","what":"Inner join","title":"Coming from 'tidyverse'","text":"","code":"# ---------- datawizard ----------- band_members %>%   data_join(band_instruments, join = \"inner\") # ---------- tidyverse ----------- band_members %>%   inner_join(band_instruments) ## # A tibble: 2 × 3 ##   name  band    plays  ## * <chr> <chr>   <chr>  ## 1 John  Beatles guitar ## 2 Paul  Beatles bass"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"other-useful-functions","dir":"Articles","previous_headings":"","what":"Other useful functions","title":"Coming from 'tidyverse'","text":"datawizard contains functions necessarily included dplyr tidyr. inspired package janitor.","code":""},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"work-with-rownames","dir":"Articles","previous_headings":"Other useful functions","what":"Work with rownames","title":"Coming from 'tidyverse'","text":"can convert column rownames move rownames new column rownames_as_column() column_as_rownames():","code":"mtcars <- head(mtcars) mtcars ##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb ## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 ## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 ## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 ## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 ## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 ## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 mtcars2 <- mtcars %>%   rownames_as_column(var = \"model\")  mtcars2 ##               model  mpg cyl disp  hp drat    wt  qsec vs am gear carb ## 1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 ## 2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 ## 3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 ## 4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 ## 5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 ## 6           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 mtcars2 %>%   column_as_rownames(var = \"model\") ##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb ## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 ## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 ## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 ## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 ## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 ## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":"https://easystats.github.io/datawizard/articles/tidyverse_translation.html","id":"work-with-column-names","dir":"Articles","previous_headings":"Other useful functions","what":"Work with column names","title":"Coming from 'tidyverse'","text":"dealing messy data, sometimes useful use row column names, vice versa. can done row_to_colnames() colnames_to_row().","code":"x <- data.frame(   X_1 = c(NA, \"Title\", 1:3),   X_2 = c(NA, \"Title2\", 4:6) ) x ##     X_1    X_2 ## 1  <NA>   <NA> ## 2 Title Title2 ## 3     1      4 ## 4     2      5 ## 5     3      6 x2 <- x %>%   row_to_colnames(row = 2) x2 ##   Title Title2 ## 1  <NA>   <NA> ## 3     1      4 ## 4     2      5 ## 5     3      6 x2 %>%   colnames_to_row() ##       x1     x2 ## 1  Title Title2 ## 11  <NA>   <NA> ## 3      1      4 ## 4      2      5 ## 5      3      6"},{"path":"https://easystats.github.io/datawizard/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Indrajeet Patil. Author, maintainer.            @patilindrajeets Dominique Makowski. Author.            @Dom_Makowski Daniel Lüdecke. Author.            @strengejacke Mattan S. Ben-Shachar. Author. Brenton M. Wiernik. Author.            @bmwiernik Etienne Bacher. Author. Rémi Thériault. Contributor.            @rempsyc","code":""},{"path":"https://easystats.github.io/datawizard/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Patil, Makowski, Ben-Shachar, Wiernik, Bacher, & Lüdecke (2022). datawizard: R Package Easy Data Preparation Statistical Transformations. CRAN. Available https://easystats.github.io/datawizard/","code":"@Article{,   title = {datawizard: An R Package for Easy Data Preparation and Statistical Transformations},   author = {Indrajeet Patil and Dominique Makowski and Mattan S. Ben-Shachar and Brenton M. Wiernik and Etienne Bacher and Daniel Lüdecke},   journal = {CRAN},   year = {2022},   note = {R package},   url = {https://easystats.github.io/datawizard/}, }"},{"path":"https://easystats.github.io/datawizard/index.html","id":"datawizard-easy-data-wrangling-and-statistical-transformations-","dir":"","previous_headings":"","what":"Easy Data Wrangling and Statistical Transformations","title":"Easy Data Wrangling and Statistical Transformations","text":"datawizard lightweight package easily manipulate, clean, transform, prepare data analysis. part easystats ecosystem, suite R packages deal entire statistical analysis, cleaning data reporting results. courses tutorials statistical modeling assume working clean tidy dataset. practice, however, major part statistical modeling preparing data–cleaning values, creating new columns, reshaping dataset, transforming variables. datawizard provides easy use tools perform common, critical, sometimes tedious data preparation tasks.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Easy Data Wrangling and Statistical Transformations","text":"cite package, run following command:","code":"citation(\"datawizard\")  To cite datawizard in publications use:    Patil, Makowski, Ben-Shachar, Wiernik, Bacher, & Lüdecke (2022).   datawizard: An R Package for Easy Data Preparation and Statistical   Transformations. CRAN. Available from   https://easystats.github.io/datawizard/  A BibTeX entry for LaTeX users is    @Article{,     title = {datawizard: An R Package for Easy Data Preparation and Statistical Transformations},     author = {Indrajeet Patil and Dominique Makowski and Mattan S. Ben-Shachar and Brenton M. Wiernik and Etienne Bacher and Daniel Lüdecke},     journal = {CRAN},     year = {2022},     note = {R package},     url = {https://easystats.github.io/datawizard/},   }"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/datawizard/index.html","id":"select-filter-and-remove-variables","dir":"","previous_headings":"Data wrangling","what":"Select, filter and remove variables","title":"Easy Data Wrangling and Statistical Transformations","text":"package provides helpers filter rows meeting certain conditions… … logical expressions: Finding columns data frame, retrieving data selected columns, can achieved using find_columns() get_columns(): also possible extract one variables: Due consistent API, removing variables just simple:","code":"data_match(mtcars, data.frame(vs = 0, am = 1)) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 data_filter(mtcars, vs == 0 & am == 1) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 # find column names matching a pattern find_columns(iris, starts_with(\"Sepal\")) #> [1] \"Sepal.Length\" \"Sepal.Width\"  # return data columns matching a pattern get_columns(iris, starts_with(\"Sepal\")) |> head() #>   Sepal.Length Sepal.Width #> 1          5.1         3.5 #> 2          4.9         3.0 #> 3          4.7         3.2 #> 4          4.6         3.1 #> 5          5.0         3.6 #> 6          5.4         3.9 # single variable data_extract(mtcars, \"gear\") #>  [1] 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4  # more variables head(data_extract(iris, ends_with(\"Width\"))) #>   Sepal.Width Petal.Width #> 1         3.5         0.2 #> 2         3.0         0.2 #> 3         3.2         0.2 #> 4         3.1         0.2 #> 5         3.6         0.2 #> 6         3.9         0.4 head(data_remove(iris, starts_with(\"Sepal\"))) #>   Petal.Length Petal.Width Species #> 1          1.4         0.2  setosa #> 2          1.4         0.2  setosa #> 3          1.3         0.2  setosa #> 4          1.5         0.2  setosa #> 5          1.4         0.2  setosa #> 6          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/index.html","id":"reorder-or-rename","dir":"","previous_headings":"Data wrangling","what":"Reorder or rename","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"head(data_relocate(iris, select = \"Species\", before = \"Sepal.Length\")) #>   Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1  setosa          5.1         3.5          1.4         0.2 #> 2  setosa          4.9         3.0          1.4         0.2 #> 3  setosa          4.7         3.2          1.3         0.2 #> 4  setosa          4.6         3.1          1.5         0.2 #> 5  setosa          5.0         3.6          1.4         0.2 #> 6  setosa          5.4         3.9          1.7         0.4 head(data_rename(iris, c(\"Sepal.Length\", \"Sepal.Width\"), c(\"length\", \"width\"))) #>   length width Petal.Length Petal.Width Species #> 1    5.1   3.5          1.4         0.2  setosa #> 2    4.9   3.0          1.4         0.2  setosa #> 3    4.7   3.2          1.3         0.2  setosa #> 4    4.6   3.1          1.5         0.2  setosa #> 5    5.0   3.6          1.4         0.2  setosa #> 6    5.4   3.9          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/index.html","id":"merge","dir":"","previous_headings":"Data wrangling","what":"Merge","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"x <- data.frame(a = 1:3, b = c(\"a\", \"b\", \"c\"), c = 5:7, id = 1:3) y <- data.frame(c = 6:8, d = c(\"f\", \"g\", \"h\"), e = 100:102, id = 2:4)  x #>   a b c id #> 1 1 a 5  1 #> 2 2 b 6  2 #> 3 3 c 7  3 y #>   c d   e id #> 1 6 f 100  2 #> 2 7 g 101  3 #> 3 8 h 102  4  data_merge(x, y, join = \"full\") #>    a    b c id    d   e #> 3  1    a 5  1 <NA>  NA #> 1  2    b 6  2    f 100 #> 2  3    c 7  3    g 101 #> 4 NA <NA> 8  4    h 102  data_merge(x, y, join = \"left\") #>   a b c id    d   e #> 3 1 a 5  1 <NA>  NA #> 1 2 b 6  2    f 100 #> 2 3 c 7  3    g 101  data_merge(x, y, join = \"right\") #>    a    b c id d   e #> 1  2    b 6  2 f 100 #> 2  3    c 7  3 g 101 #> 3 NA <NA> 8  4 h 102  data_merge(x, y, join = \"semi\", by = \"c\") #>   a b c id #> 2 2 b 6  2 #> 3 3 c 7  3  data_merge(x, y, join = \"anti\", by = \"c\") #>   a b c id #> 1 1 a 5  1  data_merge(x, y, join = \"inner\") #>   a b c id d   e #> 1 2 b 6  2 f 100 #> 2 3 c 7  3 g 101  data_merge(x, y, join = \"bind\") #>    a    b c id    d   e #> 1  1    a 5  1 <NA>  NA #> 2  2    b 6  2 <NA>  NA #> 3  3    c 7  3 <NA>  NA #> 4 NA <NA> 6  2    f 100 #> 5 NA <NA> 7  3    g 101 #> 6 NA <NA> 8  4    h 102"},{"path":"https://easystats.github.io/datawizard/index.html","id":"reshape","dir":"","previous_headings":"Data wrangling","what":"Reshape","title":"Easy Data Wrangling and Statistical Transformations","text":"common data wrangling task reshape data. Either go wide/Cartesian long/tidy format way","code":"wide_data <- data.frame(replicate(5, rnorm(10)))  head(data_to_long(wide_data)) #>   name       value #> 1   X1 -0.08281164 #> 2   X2 -1.12490028 #> 3   X3 -0.70632036 #> 4   X4 -0.70278946 #> 5   X5  0.07633326 #> 6   X1  1.93468099 long_data <- data_to_long(wide_data, rows_to = \"Row_ID\") # Save row number  data_to_wide(long_data,   names_from = \"name\",   values_from = \"value\",   id_cols = \"Row_ID\" ) #>    Row_ID          X1          X2          X3         X4          X5 #> 1       1 -0.08281164 -1.12490028 -0.70632036 -0.7027895  0.07633326 #> 2       2  1.93468099 -0.87430362  0.96687656  0.2998642 -0.23035595 #> 3       3 -2.05128979  0.04386162 -0.71016648  1.1494697  0.31746484 #> 4       4  0.27773897 -0.58397514 -0.05917365 -0.3016415 -1.59268440 #> 5       5 -1.52596060 -0.82329858 -0.23094342 -0.5473394 -0.18194062 #> 6       6 -0.26916362  0.11059280  0.69200045 -0.3854041  1.75614174 #> 7       7  1.23305388  0.36472778  1.35682290  0.2763720  0.11394932 #> 8       8  0.63360774  0.05370100  1.78872284  0.1518608 -0.29216508 #> 9       9  0.35271746  1.36867235  0.41071582 -0.4313808  1.75409316 #> 10     10 -0.56048248 -0.38045724 -2.18785470 -1.8705001  1.80958455"},{"path":"https://easystats.github.io/datawizard/index.html","id":"empty-rows-and-columns","dir":"","previous_headings":"Data wrangling","what":"Empty rows and columns","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"tmp <- data.frame(   a = c(1, 2, 3, NA, 5),   b = c(1, NA, 3, NA, 5),   c = c(NA, NA, NA, NA, NA),   d = c(1, NA, 3, NA, 5) )  tmp #>    a  b  c  d #> 1  1  1 NA  1 #> 2  2 NA NA NA #> 3  3  3 NA  3 #> 4 NA NA NA NA #> 5  5  5 NA  5  # indices of empty columns or rows empty_columns(tmp) #> c  #> 3 empty_rows(tmp) #> [1] 4  # remove empty columns or rows remove_empty_columns(tmp) #>    a  b  d #> 1  1  1  1 #> 2  2 NA NA #> 3  3  3  3 #> 4 NA NA NA #> 5  5  5  5 remove_empty_rows(tmp) #>   a  b  c  d #> 1 1  1 NA  1 #> 2 2 NA NA NA #> 3 3  3 NA  3 #> 5 5  5 NA  5  # remove empty columns and rows remove_empty(tmp) #>   a  b  d #> 1 1  1  1 #> 2 2 NA NA #> 3 3  3  3 #> 5 5  5  5"},{"path":"https://easystats.github.io/datawizard/index.html","id":"recode-or-cut-dataframe","dir":"","previous_headings":"Data wrangling","what":"Recode or cut dataframe","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"set.seed(123) x <- sample(1:10, size = 50, replace = TRUE)  table(x) #> x #>  1  2  3  4  5  6  7  8  9 10  #>  2  3  5  3  7  5  5  2 11  7  # cut into 3 groups, based on distribution (quantiles) table(categorize(x, split = \"quantile\", n_groups = 3)) #>  #>  1  2  3  #> 13 19 18"},{"path":"https://easystats.github.io/datawizard/index.html","id":"data-transformations","dir":"","previous_headings":"","what":"Data Transformations","title":"Easy Data Wrangling and Statistical Transformations","text":"packages also contains multiple functions help transform data.","code":""},{"path":"https://easystats.github.io/datawizard/index.html","id":"standardize","dir":"","previous_headings":"Data Transformations","what":"Standardize","title":"Easy Data Wrangling and Statistical Transformations","text":"example, standardize (z-score) data:","code":"# before summary(swiss) #>    Fertility      Agriculture     Examination      Education     #>  Min.   :35.00   Min.   : 1.20   Min.   : 3.00   Min.   : 1.00   #>  1st Qu.:64.70   1st Qu.:35.90   1st Qu.:12.00   1st Qu.: 6.00   #>  Median :70.40   Median :54.10   Median :16.00   Median : 8.00   #>  Mean   :70.14   Mean   :50.66   Mean   :16.49   Mean   :10.98   #>  3rd Qu.:78.45   3rd Qu.:67.65   3rd Qu.:22.00   3rd Qu.:12.00   #>  Max.   :92.50   Max.   :89.70   Max.   :37.00   Max.   :53.00   #>     Catholic       Infant.Mortality #>  Min.   :  2.150   Min.   :10.80    #>  1st Qu.:  5.195   1st Qu.:18.15    #>  Median : 15.140   Median :20.00    #>  Mean   : 41.144   Mean   :19.94    #>  3rd Qu.: 93.125   3rd Qu.:21.70    #>  Max.   :100.000   Max.   :26.60  # after summary(standardize(swiss)) #>    Fertility         Agriculture       Examination         Education       #>  Min.   :-2.81327   Min.   :-2.1778   Min.   :-1.69084   Min.   :-1.0378   #>  1st Qu.:-0.43569   1st Qu.:-0.6499   1st Qu.:-0.56273   1st Qu.:-0.5178   #>  Median : 0.02061   Median : 0.1515   Median :-0.06134   Median :-0.3098   #>  Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000   #>  3rd Qu.: 0.66504   3rd Qu.: 0.7481   3rd Qu.: 0.69074   3rd Qu.: 0.1062   #>  Max.   : 1.78978   Max.   : 1.7190   Max.   : 2.57094   Max.   : 4.3702   #>     Catholic       Infant.Mortality   #>  Min.   :-0.9350   Min.   :-3.13886   #>  1st Qu.:-0.8620   1st Qu.:-0.61543   #>  Median :-0.6235   Median : 0.01972   #>  Mean   : 0.0000   Mean   : 0.00000   #>  3rd Qu.: 1.2464   3rd Qu.: 0.60337   #>  Max.   : 1.4113   Max.   : 2.28566"},{"path":"https://easystats.github.io/datawizard/index.html","id":"winsorize","dir":"","previous_headings":"Data Transformations","what":"Winsorize","title":"Easy Data Wrangling and Statistical Transformations","text":"winsorize data:","code":"# before anscombe #>    x1 x2 x3 x4    y1   y2    y3    y4 #> 1  10 10 10  8  8.04 9.14  7.46  6.58 #> 2   8  8  8  8  6.95 8.14  6.77  5.76 #> 3  13 13 13  8  7.58 8.74 12.74  7.71 #> 4   9  9  9  8  8.81 8.77  7.11  8.84 #> 5  11 11 11  8  8.33 9.26  7.81  8.47 #> 6  14 14 14  8  9.96 8.10  8.84  7.04 #> 7   6  6  6  8  7.24 6.13  6.08  5.25 #> 8   4  4  4 19  4.26 3.10  5.39 12.50 #> 9  12 12 12  8 10.84 9.13  8.15  5.56 #> 10  7  7  7  8  4.82 7.26  6.42  7.91 #> 11  5  5  5  8  5.68 4.74  5.73  6.89  # after winsorize(anscombe) #>    x1 x2 x3 x4   y1   y2   y3   y4 #> 1  10 10 10  8 8.04 9.13 7.46 6.58 #> 2   8  8  8  8 6.95 8.14 6.77 5.76 #> 3  12 12 12  8 7.58 8.74 8.15 7.71 #> 4   9  9  9  8 8.81 8.77 7.11 8.47 #> 5  11 11 11  8 8.33 9.13 7.81 8.47 #> 6  12 12 12  8 8.81 8.10 8.15 7.04 #> 7   6  6  6  8 7.24 6.13 6.08 5.76 #> 8   6  6  6  8 5.68 6.13 6.08 8.47 #> 9  12 12 12  8 8.81 9.13 8.15 5.76 #> 10  7  7  7  8 5.68 7.26 6.42 7.91 #> 11  6  6  6  8 5.68 6.13 6.08 6.89"},{"path":"https://easystats.github.io/datawizard/index.html","id":"center","dir":"","previous_headings":"Data Transformations","what":"Center","title":"Easy Data Wrangling and Statistical Transformations","text":"grand-mean center data","code":"center(anscombe) #>    x1 x2 x3 x4          y1         y2    y3         y4 #> 1   1  1  1 -1  0.53909091  1.6390909 -0.04 -0.9209091 #> 2  -1 -1 -1 -1 -0.55090909  0.6390909 -0.73 -1.7409091 #> 3   4  4  4 -1  0.07909091  1.2390909  5.24  0.2090909 #> 4   0  0  0 -1  1.30909091  1.2690909 -0.39  1.3390909 #> 5   2  2  2 -1  0.82909091  1.7590909  0.31  0.9690909 #> 6   5  5  5 -1  2.45909091  0.5990909  1.34 -0.4609091 #> 7  -3 -3 -3 -1 -0.26090909 -1.3709091 -1.42 -2.2509091 #> 8  -5 -5 -5 10 -3.24090909 -4.4009091 -2.11  4.9990909 #> 9   3  3  3 -1  3.33909091  1.6290909  0.65 -1.9409091 #> 10 -2 -2 -2 -1 -2.68090909 -0.2409091 -1.08  0.4090909 #> 11 -4 -4 -4 -1 -1.82090909 -2.7609091 -1.77 -0.6109091"},{"path":"https://easystats.github.io/datawizard/index.html","id":"ranktransform","dir":"","previous_headings":"Data Transformations","what":"Ranktransform","title":"Easy Data Wrangling and Statistical Transformations","text":"rank-transform data:","code":"# before head(trees) #>   Girth Height Volume #> 1   8.3     70   10.3 #> 2   8.6     65   10.3 #> 3   8.8     63   10.2 #> 4  10.5     72   16.4 #> 5  10.7     81   18.8 #> 6  10.8     83   19.7  # after head(ranktransform(trees)) #>   Girth Height Volume #> 1     1    6.0    2.5 #> 2     2    3.0    2.5 #> 3     3    1.0    1.0 #> 4     4    8.5    5.0 #> 5     5   25.5    7.0 #> 6     6   28.0    9.0"},{"path":"https://easystats.github.io/datawizard/index.html","id":"rescale","dir":"","previous_headings":"Data Transformations","what":"Rescale","title":"Easy Data Wrangling and Statistical Transformations","text":"rescale numeric variable new range:","code":"change_scale(c(0, 1, 5, -5, -2)) #> [1]  50  60 100   0  30 #> attr(,\"min_value\") #> [1] -5 #> attr(,\"range_difference\") #> [1] 10 #> attr(,\"to_range\") #> [1]   0 100"},{"path":"https://easystats.github.io/datawizard/index.html","id":"rotate-or-transpose","dir":"","previous_headings":"Data Transformations","what":"Rotate or transpose","title":"Easy Data Wrangling and Statistical Transformations","text":"","code":"x <- mtcars[1:3, 1:4]  x #>                mpg cyl disp  hp #> Mazda RX4     21.0   6  160 110 #> Mazda RX4 Wag 21.0   6  160 110 #> Datsun 710    22.8   4  108  93  data_rotate(x) #>      Mazda RX4 Mazda RX4 Wag Datsun 710 #> mpg         21            21       22.8 #> cyl          6             6        4.0 #> disp       160           160      108.0 #> hp         110           110       93.0"},{"path":"https://easystats.github.io/datawizard/index.html","id":"data-properties","dir":"","previous_headings":"","what":"Data properties","title":"Easy Data Wrangling and Statistical Transformations","text":"datawizard provides way provide comprehensive descriptive summary variables dataframe: even just variable also additional data properties can computed using package.","code":"data(iris) describe_distribution(iris) #> Variable     | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |   n | n_Missing #> ---------------------------------------------------------------------------------------- #> Sepal.Length | 5.84 | 0.83 | 1.30 | [4.30, 7.90] |     0.31 |    -0.55 | 150 |         0 #> Sepal.Width  | 3.06 | 0.44 | 0.52 | [2.00, 4.40] |     0.32 |     0.23 | 150 |         0 #> Petal.Length | 3.76 | 1.77 | 3.52 | [1.00, 6.90] |    -0.27 |    -1.40 | 150 |         0 #> Petal.Width  | 1.20 | 0.76 | 1.50 | [0.10, 2.50] |    -0.10 |    -1.34 | 150 |         0 describe_distribution(mtcars$wt) #> Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing #> ------------------------------------------------------------------------ #> 3.22 | 0.98 | 1.19 | [1.51, 5.42] |     0.47 |     0.42 | 32 |         0 x <- (-10:10)^3 + rnorm(21, 0, 100) smoothness(x, method = \"diff\") #> [1] 1.791243 #> attr(,\"class\") #> [1] \"parameters_smoothness\" \"numeric\""},{"path":"https://easystats.github.io/datawizard/index.html","id":"function-design-and-pipe-workflow","dir":"","previous_headings":"","what":"Function design and pipe-workflow","title":"Easy Data Wrangling and Statistical Transformations","text":"design datawizard functions follows design principle makes easy user understand remember functions work: first argument data methods work data frames, two arguments following select exclude variables following arguments arguments related specific tasks functions important, functions accept data frames usually first argument, also return (modified) data frame . Thus, datawizard integrates smoothly “pipe-workflow”.","code":"iris |>   # all rows where Species is \"versicolor\" or \"virginica\"   data_filter(Species %in% c(\"versicolor\", \"virginica\")) |>   # select only columns with \".\" in names (i.e. drop Species)   get_columns(contains(\".\")) |>   # move columns that ends with \"Length\" to start of data frame   data_relocate(ends_with(\"Length\")) |>   # remove fourth column   data_remove(4) |>   head() #>    Sepal.Length Petal.Length Sepal.Width #> 51          7.0          4.7         3.2 #> 52          6.4          4.5         3.2 #> 53          6.9          4.9         3.1 #> 54          5.5          4.0         2.3 #> 55          6.5          4.6         2.8 #> 56          5.7          4.5         2.8"},{"path":"https://easystats.github.io/datawizard/index.html","id":"contributing-and-support","dir":"","previous_headings":"","what":"Contributing and Support","title":"Easy Data Wrangling and Statistical Transformations","text":"case want file issue contribute another way package, please follow guide. questions functionality, may either contact us via email also file issue.","code":""},{"path":"https://easystats.github.io/datawizard/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Easy Data Wrangling and Statistical Transformations","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust data for the effect of other variable(s) — adjust","title":"Adjust data for the effect of other variable(s) — adjust","text":"function can used adjust data effect variables present dataset. based underlying fitting regressions models, allowing quite flexibility, including factors random effects mixed models (multilevel partialization), continuous variables smooth terms general additive models (non-linear partialization) /fitting models Bayesian framework. values returned function residuals regression models. Note regular correlation two \"adjusted\" variables equivalent partial correlation .","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust data for the effect of other variable(s) — adjust","text":"","code":"adjust(   data,   effect = NULL,   select = NULL,   exclude = NULL,   multilevel = FALSE,   additive = FALSE,   bayesian = FALSE,   keep_intercept = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE )  data_adjust(   data,   effect = NULL,   select = NULL,   exclude = NULL,   multilevel = FALSE,   additive = FALSE,   bayesian = FALSE,   keep_intercept = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE )"},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust data for the effect of other variable(s) — adjust","text":"data data frame. effect Character vector column names adjusted (regressed ). NULL (default), variables selected. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. multilevel TRUE, factors included random factors. Else, FALSE (default), included fixed effects simple regression model. additive TRUE, continuous variables included smooth terms additive models. goal regress-potential non-linear effects. bayesian TRUE, models fitted Bayesian framework using rstanarm. keep_intercept FALSE (default), intercept model re-added. avoids centering around 0 happens default regressing another variable (see examples visual representation ). ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust data for the effect of other variable(s) — adjust","text":"data frame comparable data, adjusted variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/adjust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust data for the effect of other variable(s) — adjust","text":"","code":"adjusted_all <- adjust(attitude) head(adjusted_all) #>        rating complaints privileges    learning     raises   critical #> 1  -8.1102953  5.5583770 -15.848949 -2.75102306  0.5742664  15.605502 #> 2   1.6472337  0.0646564  -1.422592 -3.06207012 -1.5567655  -2.315781 #> 3   1.0605589 -7.5116953  11.174609  5.59808033  4.8603132   8.061801 #> 4  -0.2268416  3.8345277  -4.567441  0.03866933 -7.1185324  13.002574 #> 5   6.5462010 -1.2420122  -3.051098  0.87312095 -2.7131349   6.500353 #> 6 -10.9418499  5.2030745   2.664156 -1.24552098  4.1370346 -21.678382 #>      advance #> 1  2.8684130 #> 2  5.3937097 #> 3 -6.4236221 #> 4 -0.3951046 #> 5  2.1988621 #> 6 -3.1912418 adjusted_one <- adjust(attitude, effect = \"complaints\", select = \"rating\") head(adjusted_one) #>        rating complaints privileges learning raises critical advance #> 1  -9.8614202         51         30       39     61       92      45 #> 2   0.3286522         64         51       54     63       73      47 #> 3   3.8009933         70         68       69     76       86      48 #> 4  -0.9167380         63         45       47     54       84      35 #> 5   7.7641147         78         56       66     71       83      47 #> 6 -12.8798594         55         49       44     54       49      34 # \\donttest{ adjust(attitude, effect = \"complaints\", select = \"rating\", bayesian = TRUE) #>          rating complaints privileges learning raises critical advance #> 1   -9.94500639         51         30       39     61       92      45 #> 2    0.23707923         64         51       54     63       73      47 #> 3    3.70573413         70         68       69     76       86      48 #> 4   -1.00769659         63         45       47     54       84      35 #> 5    7.66394067         78         56       66     71       83      47 #> 6  -12.96590313         55         49       44     54       49      34 #> 7   -7.02859332         67         42       56     66       68      35 #> 8   -0.07038678         75         50       55     70       66      41 #> 9   -4.35695607         82         72       67     71       83      31 #> 10   6.50275178         61         45       47     62       80      41 #> 11   9.54454524         53         53       58     58       67      34 #> 12   7.25797596         60         47       39     59       74      41 #> 13   7.74752759         62         57       42     55       63      25 #> 14  -9.11218025         83         83       45     59       77      35 #> 15   4.41916485         77         54       72     79       77      46 #> 16  -1.39874953         90         50       72     60       54      36 #> 17  -4.62262861         85         64       69     79       79      63 #> 18   5.25797596         60         65       75     55       80      60 #> 19  -2.29426587         70         46       57     75       85      46 #> 20  -8.23157567         58         68       54     64       78      52 #> 21   5.36245962         40         33       34     43       64      33 #> 22   3.50275178         61         52       62     66       80      41 #> 23 -11.27336914         66         52       50     63       80      37 #> 24  -2.37186783         37         42       58     50       57      49 #> 25   7.78932106         54         42       48     66       75      33 #> 26  -6.58083515         77         66       63     88       76      72 #> 27   6.92961322         75         58       74     80       78      49 #> 28  -9.47635149         57         44       45     51       83      38 #> 29   6.37737139         85         71       71     77       74      55 #> 30   5.64304393         82         39       59     64       78      39 adjust(attitude, effect = \"complaints\", select = \"rating\", additive = TRUE) #>          rating complaints privileges learning raises critical advance #> 1   -9.86142016         51         30       39     61       92      45 #> 2    0.32865220         64         51       54     63       73      47 #> 3    3.80099328         70         68       69     76       86      48 #> 4   -0.91673799         63         45       47     54       84      35 #> 5    7.76411473         78         56       66     71       83      47 #> 6  -12.87985944         55         49       44     54       49      34 #> 7   -6.93517726         67         42       56     66       68      35 #> 8    0.02794419         75         50       55     70       66      41 #> 9   -4.25432454         82         72       67     71       83      31 #> 10   6.59248165         61         45       47     62       80      41 #> 11   9.62936020         53         53       58     58       67      34 #> 12   7.34709147         60         47       39     59       74      41 #> 13   7.83787183         62         57       42     55       63      25 #> 14  -9.00893436         83         83       45     59       77      35 #> 15   4.51872455         77         54       72     79       77      46 #> 16  -1.29120309         90         50       72     60       54      36 #> 17  -4.51815400         85         64       69     79       79      63 #> 18   5.34709147         60         65       75     55       80      60 #> 19  -2.19900672         70         46       57     75       85      46 #> 20  -8.14368889         58         68       54     64       78      52 #> 21   5.43928784         40         33       34     43       64      33 #> 22   3.59248165         61         52       62     66       80      41 #> 23 -11.18056744         66         52       50     63       80      37 #> 24  -2.29688270         37         42       58     50       57      49 #> 25   7.87475038         54         42       48     66       75      33 #> 26  -6.48127545         77         66       63     88       76      72 #> 27   7.02794419         75         58       74     80       78      49 #> 28  -9.38907907         57         44       45     51       83      38 #> 29   6.48184600         85         71       71     77       74      55 #> 30   5.74567546         82         39       59     64       78      39 attitude$complaints_LMH <- cut(attitude$complaints, 3) adjust(attitude, effect = \"complaints_LMH\", select = \"rating\", multilevel = TRUE) #>         rating complaints privileges learning raises critical advance #> 1   -9.9809282         51         30       39     61       92      45 #> 2    2.6250549         64         51       54     63       73      47 #> 3   10.6250549         70         68       69     76       86      48 #> 4    0.6250549         63         45       47     54       84      35 #> 5    5.6503521         78         56       66     71       83      47 #> 6  -17.3749451         55         49       44     54       49      34 #> 7   -2.3749451         67         42       56     66       68      35 #> 8   -4.3496479         75         50       55     70       66      41 #> 9   -3.3496479         82         72       67     71       83      31 #> 10   6.6250549         61         45       47     62       80      41 #> 11  11.0190718         53         53       58     58       67      34 #> 12   6.6250549         60         47       39     59       74      41 #> 13   8.6250549         62         57       42     55       63      25 #> 14  -7.3496479         83         83       45     59       77      35 #> 15   1.6503521         77         54       72     79       77      46 #> 16   5.6503521         90         50       72     60       54      36 #> 17  -1.3496479         85         64       69     79       79      63 #> 18   4.6250549         60         65       75     55       80      60 #> 19   4.6250549         70         46       57     75       85      46 #> 20 -10.3749451         58         68       54     64       78      52 #> 21  -2.9809282         40         33       34     43       64      33 #> 22   3.6250549         61         52       62     66       80      41 #> 23  -7.3749451         66         52       50     63       80      37 #> 24 -12.9809282         37         42       58     50       57      49 #> 25  10.0190718         54         42       48     66       75      33 #> 26  -9.3496479         77         66       63     88       76      72 #> 27   2.6503521         75         58       74     80       78      49 #> 28 -12.3749451         57         44       45     51       83      38 #> 29   9.6503521         85         71       71     77       74      55 #> 30   6.6503521         82         39       59     64       78      39 #>    complaints_LMH #> 1     (36.9,54.7] #> 2     (54.7,72.3] #> 3     (54.7,72.3] #> 4     (54.7,72.3] #> 5     (72.3,90.1] #> 6     (54.7,72.3] #> 7     (54.7,72.3] #> 8     (72.3,90.1] #> 9     (72.3,90.1] #> 10    (54.7,72.3] #> 11    (36.9,54.7] #> 12    (54.7,72.3] #> 13    (54.7,72.3] #> 14    (72.3,90.1] #> 15    (72.3,90.1] #> 16    (72.3,90.1] #> 17    (72.3,90.1] #> 18    (54.7,72.3] #> 19    (54.7,72.3] #> 20    (54.7,72.3] #> 21    (36.9,54.7] #> 22    (54.7,72.3] #> 23    (54.7,72.3] #> 24    (36.9,54.7] #> 25    (36.9,54.7] #> 26    (72.3,90.1] #> 27    (72.3,90.1] #> 28    (54.7,72.3] #> 29    (72.3,90.1] #> 30    (72.3,90.1] # }  if (require(\"bayestestR\")) {   # Generate data   data <- simulate_correlation(n = 100, r = 0.7)   data$V2 <- (5 * data$V2) + 20 # Add intercept    # Adjust   adjusted <- adjust(data, effect = \"V1\", select = \"V2\")   adjusted_icpt <- adjust(data, effect = \"V1\", select = \"V2\", keep_intercept = TRUE)    # Visualize   plot(data$V1, data$V2,     pch = 19, col = \"blue\",     ylim = c(min(adjusted$V2), max(data$V2)),     main = \"Original (blue), adjusted (green), and adjusted - intercept kept (red) data\"   )   abline(lm(V2 ~ V1, data = data), col = \"blue\")   points(adjusted$V1, adjusted$V2, pch = 19, col = \"green\")   abline(lm(V2 ~ V1, data = adjusted), col = \"green\")   points(adjusted_icpt$V1, adjusted_icpt$V2, pch = 19, col = \"red\")   abline(lm(V2 ~ V1, data = adjusted_icpt), col = \"red\") } #> Loading required package: bayestestR"},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode (or ","title":"Recode (or ","text":"functions divides range variables intervals recodes values inside intervals according related interval. basically wrapper around base R's cut(), providing simplified accessible way define interval breaks (cut-values).","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode (or ","text":"","code":"categorize(x, ...)  # S3 method for numeric categorize(   x,   split = \"median\",   n_groups = NULL,   range = NULL,   lowest = 1,   labels = NULL,   verbose = TRUE,   ... )  # S3 method for data.frame categorize(   x,   select = NULL,   exclude = NULL,   split = \"median\",   n_groups = NULL,   range = NULL,   lowest = 1,   labels = NULL,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode (or ","text":"x (grouped) data frame, numeric vector factor. ... used. split Character vector, indicating breaks split variables, numeric values values indicating breaks. character, may one \"median\", \"mean\", \"quantile\", \"equal_length\", \"equal_range\". \"median\" \"mean\" return dichotomous variables, split mean median, respectively. \"quantile\" \"equal_length\" split variable n_groups groups, group refers interval specific range values. Thus, length interval based number groups. \"equal_range\" also splits variable multiple groups, however, length interval given, number resulting groups (hence, number breaks) determined many intervals can generated, based full range variable. n_groups split \"quantile\" \"equal_length\", defines number requested groups (.e. resulting number levels values) recoded variable(s). \"quantile\" define intervals based distribution variable, \"equal_length\" tries divide range variable pieces equal length. range split = \"equal_range\", defines range values recoded new value. lowest Minimum value recoded variable(s). NULL (default), numeric variables, minimum original input preserved. factors, default minimum 1. split = \"equal_range\", default minimum always 1, unless specified otherwise lowest. labels Character vector value labels. NULL, categorize() returns factors instead numeric variables, labels used labelling factor levels. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode (or ","text":"x, recoded groups. default x numeric, unless labels specified. case, factor returned, factor levels (.e. recoded groups labelled accordingly.","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"splits-and-breaks-cut-off-values-","dir":"Reference","previous_headings":"","what":"Splits and breaks (cut-off values)","title":"Recode (or ","text":"Breaks general exclusive, means values indicate lower bound next group interval begin. Take simple example, numeric variable values 1 9. median 5, thus first interval ranges 1-4 recoded 1, 5-9 turn 2 (compare cbind(1:9, categorize(1:9))). variable, using split = \"quantile\" n_groups = 3 define breaks 3.67 6.33 (see quantile(1:9, probs = c(1/3, 2/3))), means values 1 3 belong first interval recoded 1 (next interval starts 3.67), 4 6 2 7 9 3.","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"recoding-into-groups-with-equal-size-or-range","dir":"Reference","previous_headings":"","what":"Recoding into groups with equal size or range","title":"Recode (or ","text":"split = \"equal_length\" split = \"equal_range\" try divide range x intervals similar () length. difference split = \"equal_length\" divide range x n_groups pieces thereby defining intervals used breaks (hence, equivalent cut(x, breaks = n_groups)),  split = \"equal_range\" cut x intervals length range, first interval defaults starts 1. lowest (starting) value interval can defined using lowest argument.","code":""},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Recode (or ","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/categorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode (or ","text":"","code":"set.seed(123) x <- sample(1:10, size = 50, replace = TRUE)  table(x) #> x #>  1  2  3  4  5  6  7  8  9 10  #>  2  3  5  3  7  5  5  2 11  7   # by default, at median table(categorize(x)) #>  #>  1  2  #> 25 25   # into 3 groups, based on distribution (quantiles) table(categorize(x, split = \"quantile\", n_groups = 3)) #>  #>  1  2  3  #> 13 19 18   # into 3 groups, user-defined break table(categorize(x, split = c(3, 5))) #>  #>  1  2  3  #>  5  8 37   set.seed(123) x <- sample(1:100, size = 500, replace = TRUE)  # into 5 groups, try to recode into intervals of similar length, # i.e. the range within groups is the same for all groups table(categorize(x, split = \"equal_length\", n_groups = 5)) #>  #>   1   2   3   4   5  #>  89 116  96  94 105   # into 5 groups, try to return same range within groups # i.e. 1-20, 21-40, 41-60, etc. Since the range of \"x\" is # 1-100, and we have a range of 20, this results into 5 # groups, and thus is for this particular case identical # to the previous result. table(categorize(x, split = \"equal_range\", range = 20)) #>  #>   1   2   3   4   5  #>  89 116  96  94 105   # return factor with value labels instead of numeric value set.seed(123) x <- sample(1:10, size = 30, replace = TRUE) categorize(x, \"equal_length\", n_groups = 3) #>  [1] 1 1 3 1 2 2 2 2 3 3 2 1 3 3 3 1 3 3 3 3 3 1 2 1 3 2 3 3 3 3 categorize(x, \"equal_length\", n_groups = 3, labels = c(\"low\", \"mid\", \"high\")) #>  [1] low  low  high low  mid  mid  mid  mid  high high mid  low  high high high #> [16] low  high high high high high low  mid  low  high mid  high high high high #> Levels: low mid high"},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":null,"dir":"Reference","previous_headings":"","what":"Centering (Grand-Mean Centering) — center","title":"Centering (Grand-Mean Centering) — center","text":"Performs grand-mean centering data.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Centering (Grand-Mean Centering) — center","text":"","code":"center(x, ...)  centre(x, ...)  # S3 method for numeric center(   x,   robust = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   verbose = TRUE,   ... )  # S3 method for data.frame center(   x,   select = NULL,   exclude = NULL,   robust = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   force = FALSE,   remove_na = c(\"none\", \"selected\", \"all\"),   append = FALSE,   ignore_case = FALSE,   verbose = TRUE,   regex = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Centering (Grand-Mean Centering) — center","text":"x (grouped) data frame, (numeric character) vector factor. ... Currently used. robust Logical, TRUE, centering done subtracting median variables. FALSE, variables centered subtracting mean. weights Can NULL (weighting), : data frames: numeric vector weights, character name column data.frame contains weights. numeric vectors: numeric vector weights. reference data frame variable centrality deviation computed instead input variable. Useful standardizing subset new data according another data frame. center Numeric value, can used alternative reference define reference centrality. center length 1, recycled match length selected variables centering. Else, center must length number selected variables. Values center matched selected variables provided order, unless named vector given. case, names matched names selected variables. verbose Toggle warnings messages. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. force Logical, TRUE, forces centering factors well. Factors converted numerical values, lowest level value 1 (unless factor numeric levels, converted corresponding numeric value). remove_na missing values (NA) treated: \"none\" (default): column's standardization done separately, ignoring NAs. Else, rows NA columns selected select / exclude (\"selected\") columns (\"\") dropped standardization, resulting data frame include cases. append Logical string. TRUE, centered variables get new column names (suffix \"_c\") appended (column bind) x, thus returning original centered variables. FALSE, original variables x overwritten centered versions. character value, centered variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Centering (Grand-Mean Centering) — center","text":"centered variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Centering (Grand-Mean Centering) — center","text":"Difference centering standardizing: Standardized variables computed subtracting mean variable dividing standard deviation, centering variables involves subtraction.","code":""},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Centering (Grand-Mean Centering) — center","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/center.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Centering (Grand-Mean Centering) — center","text":"","code":"data(iris)  # entire data frame or a vector head(iris$Sepal.Width) #> [1] 3.5 3.0 3.2 3.1 3.6 3.9 head(center(iris$Sepal.Width)) #> [1]  0.44266667 -0.05733333  0.14266667  0.04266667  0.54266667  0.84266667 head(center(iris)) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1   -0.7433333  0.44266667       -2.358  -0.9993333  setosa #> 2   -0.9433333 -0.05733333       -2.358  -0.9993333  setosa #> 3   -1.1433333  0.14266667       -2.458  -0.9993333  setosa #> 4   -1.2433333  0.04266667       -2.258  -0.9993333  setosa #> 5   -0.8433333  0.54266667       -2.358  -0.9993333  setosa #> 6   -0.4433333  0.84266667       -2.058  -0.7993333  setosa head(center(iris, force = TRUE)) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1   -0.7433333  0.44266667       -2.358  -0.9993333      -1 #> 2   -0.9433333 -0.05733333       -2.358  -0.9993333      -1 #> 3   -1.1433333  0.14266667       -2.458  -0.9993333      -1 #> 4   -1.2433333  0.04266667       -2.258  -0.9993333      -1 #> 5   -0.8433333  0.54266667       -2.358  -0.9993333      -1 #> 6   -0.4433333  0.84266667       -2.058  -0.7993333      -1  # only the selected columns from a data frame center(anscombe, select = c(\"x1\", \"x3\")) #>    x1 x2 x3 x4    y1   y2    y3    y4 #> 1   1 10  1  8  8.04 9.14  7.46  6.58 #> 2  -1  8 -1  8  6.95 8.14  6.77  5.76 #> 3   4 13  4  8  7.58 8.74 12.74  7.71 #> 4   0  9  0  8  8.81 8.77  7.11  8.84 #> 5   2 11  2  8  8.33 9.26  7.81  8.47 #> 6   5 14  5  8  9.96 8.10  8.84  7.04 #> 7  -3  6 -3  8  7.24 6.13  6.08  5.25 #> 8  -5  4 -5 19  4.26 3.10  5.39 12.50 #> 9   3 12  3  8 10.84 9.13  8.15  5.56 #> 10 -2  7 -2  8  4.82 7.26  6.42  7.91 #> 11 -4  5 -4  8  5.68 4.74  5.73  6.89 center(anscombe, exclude = c(\"x1\", \"x3\")) #>    x1 x2 x3 x4          y1         y2    y3         y4 #> 1  10  1 10 -1  0.53909091  1.6390909 -0.04 -0.9209091 #> 2   8 -1  8 -1 -0.55090909  0.6390909 -0.73 -1.7409091 #> 3  13  4 13 -1  0.07909091  1.2390909  5.24  0.2090909 #> 4   9  0  9 -1  1.30909091  1.2690909 -0.39  1.3390909 #> 5  11  2 11 -1  0.82909091  1.7590909  0.31  0.9690909 #> 6  14  5 14 -1  2.45909091  0.5990909  1.34 -0.4609091 #> 7   6 -3  6 -1 -0.26090909 -1.3709091 -1.42 -2.2509091 #> 8   4 -5  4 10 -3.24090909 -4.4009091 -2.11  4.9990909 #> 9  12  3 12 -1  3.33909091  1.6290909  0.65 -1.9409091 #> 10  7 -2  7 -1 -2.68090909 -0.2409091 -1.08  0.4090909 #> 11  5 -4  5 -1 -1.82090909 -2.7609091 -1.77 -0.6109091  # centering with reference center and scale d <- data.frame(   a = c(-2, -1, 0, 1, 2),   b = c(3, 4, 5, 6, 7) )  # default centering at mean center(d) #>    a  b #> 1 -2 -2 #> 2 -1 -1 #> 3  0  0 #> 4  1  1 #> 5  2  2  # centering, using 0 as mean center(d, center = 0) #>    a b #> 1 -2 3 #> 2 -1 4 #> 3  0 5 #> 4  1 6 #> 5  2 7  # centering, using -5 as mean center(d, center = -5) #>   a  b #> 1 3  8 #> 2 4  9 #> 3 5 10 #> 4 6 11 #> 5 7 12"},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to Numeric (if possible) — coerce_to_numeric","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"Tries convert vector numeric possible (warnings errors). Otherwise, leaves .","code":""},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"","code":"coerce_to_numeric(x)"},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"x vector converted.","code":""},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"Numeric vector (possible)","code":""},{"path":"https://easystats.github.io/datawizard/reference/coerce_to_numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert to Numeric (if possible) — coerce_to_numeric","text":"","code":"coerce_to_numeric(c(\"1\", \"2\")) #> [1] 1 2 coerce_to_numeric(c(\"1\", \"2\", \"A\")) #> [1] \"1\" \"2\" \"A\""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for working with column names — row_to_colnames","title":"Tools for working with column names — row_to_colnames","text":"Tools working column names","code":""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for working with column names — row_to_colnames","text":"","code":"row_to_colnames(x, row = 1, na_prefix = \"x\", verbose = TRUE)  colnames_to_row(x, prefix = \"x\")"},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for working with column names — row_to_colnames","text":"x data frame. row Row use column names. na_prefix Prefix give column name row NA. Default 'x', incremented NA (x1, x2, etc.). verbose Toggle warnings. prefix Prefix give column name. Default 'x', incremented column (x1, x2, etc.).","code":""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for working with column names — row_to_colnames","text":"row_to_colnames() colnames_to_row() return data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/colnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools for working with column names — row_to_colnames","text":"","code":"# Convert a row to column names -------------------------------- test <- data.frame(   a = c(\"iso\", 2, 5),   b = c(\"year\", 3, 6),   c = c(NA, 5, 7) ) test #>     a    b  c #> 1 iso year NA #> 2   2    3  5 #> 3   5    6  7 row_to_colnames(test) #> Warning: Some values of row 1 were NAs. The corresponding column names are #>   prefixed with 'x'. #>   iso year x1 #> 2   2    3  5 #> 3   5    6  7  # Convert column names to row -------------------------------- test <- data.frame(   ARG = c(\"BRA\", \"FRA\"),   `1960` = c(1960, 1960),   `2000` = c(2000, 2000) ) test #>   ARG X1960 X2000 #> 1 BRA  1960  2000 #> 2 FRA  1960  2000 colnames_to_row(test) #>    x1    x2    x3 #> 1 ARG X1960 X2000 #> 2 BRA  1960  2000 #> 3 FRA  1960  2000"},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace missing values in a variable or a data frame. — convert_na_to","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"Replace missing values variable data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"","code":"convert_na_to(x, ...)  # S3 method for numeric convert_na_to(x, replacement = NULL, verbose = TRUE, ...)  # S3 method for character convert_na_to(x, replacement = NULL, verbose = TRUE, ...)  # S3 method for data.frame convert_na_to(   x,   select = NULL,   exclude = NULL,   replacement = NULL,   replace_num = replacement,   replace_char = replacement,   replace_fac = replacement,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"x numeric, factor, character vector, data frame. ... used. replacement Numeric character value used replace NA. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. replace_num Value replace NA variable type numeric. replace_char Value replace NA variable type character. replace_fac Value replace NA variable type factor. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"x, NA values replaced replacement.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_na_to.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace missing values in a variable or a data frame. — convert_na_to","text":"","code":"# Convert NA to 0 in a numeric vector convert_na_to(   c(9, 3, NA, 2, 3, 1, NA, 8),   replacement = 0 ) #> [1] 9 3 0 2 3 1 0 8  # Convert NA to \"missing\" in a character vector convert_na_to(   c(\"a\", NA, \"d\", \"z\", NA, \"t\"),   replacement = \"missing\" ) #> [1] \"a\"       \"missing\" \"d\"       \"z\"       \"missing\" \"t\"        ### For data frames  test_df <- data.frame(   x = c(1, 2, NA),   x2 = c(4, 5, NA),   y = c(\"a\", \"b\", NA) )  # Convert all NA to 0 in numeric variables, and all NA to \"missing\" in # character variables convert_na_to(   test_df,   replace_num = 0,   replace_char = \"missing\" ) #>   x x2       y #> 1 1  4       a #> 2 2  5       b #> 3 0  0 missing  # Convert a specific variable in the data frame convert_na_to(   test_df,   replace_num = 0,   replace_char = \"missing\",   select = \"x\" ) #>   x x2    y #> 1 1  4    a #> 2 2  5    b #> 3 0 NA <NA>  # Convert all variables starting with \"x\" convert_na_to(   test_df,   replace_num = 0,   replace_char = \"missing\",   select = starts_with(\"x\") ) #>   x x2    y #> 1 1  4    a #> 2 2  5    b #> 3 0  0 <NA>  # Convert NA to 1 in variable 'x2' and to 0 in all other numeric # variables convert_na_to(   test_df,   replace_num = 0,   select = list(x2 = 1) ) #> Warning: Following variable(s) were not found: 1 #>   x x2    y #> 1 1  4    a #> 2 2  5    b #> 3 0  1 <NA>"},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert non-missing values in a variable into missing values. — convert_to_na","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"Convert non-missing values variable missing values.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"","code":"convert_to_na(x, ...)  # S3 method for numeric convert_to_na(x, na = NULL, verbose = TRUE, ...)  # S3 method for factor convert_to_na(x, na = NULL, drop_levels = FALSE, verbose = TRUE, ...)  # S3 method for data.frame convert_to_na(   x,   select = NULL,   exclude = NULL,   na = NULL,   drop_levels = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"x vector, factor data frame. ... used. na Numeric, character vector logical (list numeric, character vectors logicals) values converted NA. Numeric values applied numeric vectors, character values used factors, character vectors date variables, logical values logical vectors. verbose Toggle warnings. drop_levels Logical, factors, specific levels replaced NA, unused levels dropped? select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"x, values na converted NA.","code":""},{"path":"https://easystats.github.io/datawizard/reference/convert_to_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert non-missing values in a variable into missing values. — convert_to_na","text":"","code":"x <- sample(1:6, size = 30, replace = TRUE) x #>  [1] 2 3 4 5 5 3 6 1 2 5 5 4 5 2 1 1 3 1 6 5 1 2 4 4 6 6 3 6 6 1 # values 4 and 5 to NA convert_to_na(x, na = 4:5) #>  [1]  2  3 NA NA NA  3  6  1  2 NA NA NA NA  2  1  1  3  1  6 NA  1  2 NA NA  6 #> [26]  6  3  6  6  1  # data frames set.seed(123) x <- data.frame(   a = sample(1:6, size = 20, replace = TRUE),   b = sample(letters[1:6], size = 20, replace = TRUE),   c = sample(c(30:33, 99), size = 20, replace = TRUE) ) # for all numerics, convert 5 to NA. Character/factor will be ignored. convert_to_na(x, na = 5) #> Could not convert values into `NA` for a factor or character variable. #>   To do this, `na` needs to be a character vector, or a list that contains #>   character vector elements. #>     a b  c #> 1   3 a 33 #> 2   6 e 99 #> 3   3 c 99 #> 4   2 b 32 #> 5   2 b 30 #> 6   6 a 31 #> 7   3 f 99 #> 8  NA c 99 #> 9   4 d 33 #> 10  6 f 99 #> 11  6 a 31 #> 12  1 c 30 #> 13  2 e 30 #> 14  3 d 32 #> 15 NA b 30 #> 16  3 e 99 #> 17  3 a 30 #> 18  1 a 31 #> 19  4 b 33 #> 20  1 c 33  # for numerics, 5 to NA, for character/factor, \"f\" to NA convert_to_na(x, na = list(6, \"f\")) #>     a    b  c #> 1   3    a 33 #> 2  NA    e 99 #> 3   3    c 99 #> 4   2    b 32 #> 5   2    b 30 #> 6  NA    a 31 #> 7   3 <NA> 99 #> 8   5    c 99 #> 9   4    d 33 #> 10 NA <NA> 99 #> 11 NA    a 31 #> 12  1    c 30 #> 13  2    e 30 #> 14  3    d 32 #> 15  5    b 30 #> 16  3    e 99 #> 17  3    a 30 #> 18  1    a 31 #> 19  4    b 33 #> 20  1    c 33  # select specific variables convert_to_na(x, select = c(\"a\", \"b\"), na = list(6, \"f\")) #>     a    b  c #> 1   3    a 33 #> 2  NA    e 99 #> 3   3    c 99 #> 4   2    b 32 #> 5   2    b 30 #> 6  NA    a 31 #> 7   3 <NA> 99 #> 8   5    c 99 #> 9   4    d 33 #> 10 NA <NA> 99 #> 11 NA    a 31 #> 12  1    c 30 #> 13  2    e 30 #> 14  3    d 32 #> 15  5    b 30 #> 16  3    e 99 #> 17  3    a 30 #> 18  1    a 31 #> 19  4    b 33 #> 20  1    c 33"},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrange rows by column values — data_arrange","title":"Arrange rows by column values — data_arrange","text":"data_arrange() orders rows data frame values selected columns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrange rows by column values — data_arrange","text":"","code":"data_arrange(data, select = NULL, safe = TRUE)"},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrange rows by column values — data_arrange","text":"data data frame, object can coerced data frame. select Character vector column names. Use dash just column name arrange decreasing order, example \"-x1\". safe throw error one variables specified exist.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arrange rows by column values — data_arrange","text":"data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_arrange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arrange rows by column values — data_arrange","text":"","code":"if (FALSE) { # Arrange using several variables data_arrange(head(mtcars), \"gear\", \"carb\")  # Arrange in decreasing order data_arrange(head(mtcars), \"-carb\")  # Throw an error if one of the variables specified doesn't exist data_arrange(head(mtcars), \"gear\", \"foo\", safe = FALSE) }"},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract one or more columns or elements from an object — data_extract","title":"Extract one or more columns or elements from an object — data_extract","text":"data_extract() (alias extract()) similar $. extracts either single column element object (e.g., data frame, list), multiple columns resp. elements.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract one or more columns or elements from an object — data_extract","text":"","code":"data_extract(data, select, ...)  # S3 method for data.frame data_extract(   data,   select,   name = NULL,   extract = \"all\",   as_data_frame = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract one or more columns or elements from an object — data_extract","text":"data object subset. Methods currently available data frames data frame extensions (e.g., tibbles). select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". ... use future methods. name optional argument specifies column used names vector elements extraction. Must specified either literal variable name (e.g., column_name) string (\"column_name\"). name ignored data frame returned. extract String, indicating element extracted select matches multiple variables. Can \"\" (default) return matched variables, \"first\" \"last\" return first last match, \"odd\" \"even\" return odd-numbered even-numbered matches. Note \"first\" \"last\" return vector (unless as_data_frame = TRUE), \"\" can return vector (one match found) data frame (one match). Type safe return values possible extract \"first\" \"last\" (always return vector) as_data_frame = TRUE (always returns data frame). as_data_frame Logical, TRUE, always return data frame, even one variable matched. FALSE, either returns vector data frame. See extract details. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract one or more columns or elements from an object — data_extract","text":"vector (data frame) containing extracted element, NULL matching variable found.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract one or more columns or elements from an object — data_extract","text":"data_extract() can used select multiple variables pull single variable data frame. Thus, return value default type safe - data_extract() either returns vector data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"extracting-single-variables-vectors-","dir":"Reference","previous_headings":"","what":"Extracting single variables (vectors)","title":"Extract one or more columns or elements from an object — data_extract","text":"select name single column, select matches one column, vector returned. single variable also returned extract either \"first \"last\". Setting as_data_frame TRUE overrides behaviour always returns data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"extracting-a-data-frame-of-variables","dir":"Reference","previous_headings":"","what":"Extracting a data frame of variables","title":"Extract one or more columns or elements from an object — data_extract","text":"select character vector containing one column name (numeric vector one valid column indices), select uses one supported select-helpers match multiple columns, data frame returned. Setting as_data_frame TRUE always returns data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_extract.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract one or more columns or elements from an object — data_extract","text":"","code":"# single variable data_extract(mtcars, cyl, name = gear) #> 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4  #> 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4  data_extract(mtcars, \"cyl\", name = gear) #> 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4  #> 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4  data_extract(mtcars, -1, name = gear) #> 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4  #> 4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 6 8 2  data_extract(mtcars, cyl, name = 0) #>           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive  #>                   6                   6                   4                   6  #>   Hornet Sportabout             Valiant          Duster 360           Merc 240D  #>                   8                   6                   8                   4  #>            Merc 230            Merc 280           Merc 280C          Merc 450SE  #>                   4                   6                   6                   8  #>          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental  #>                   8                   8                   8                   8  #>   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla  #>                   8                   4                   4                   4  #>       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28  #>                   4                   8                   8                   8  #>    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa  #>                   8                   4                   4                   4  #>      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E  #>                   8                   6                   8                   4  data_extract(mtcars, cyl, name = \"row.names\") #>           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive  #>                   6                   6                   4                   6  #>   Hornet Sportabout             Valiant          Duster 360           Merc 240D  #>                   8                   6                   8                   4  #>            Merc 230            Merc 280           Merc 280C          Merc 450SE  #>                   4                   6                   6                   8  #>          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental  #>                   8                   8                   8                   8  #>   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla  #>                   8                   4                   4                   4  #>       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28  #>                   4                   8                   8                   8  #>    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa  #>                   8                   4                   4                   4  #>      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E  #>                   8                   6                   8                   4   # selecting multiple variables head(data_extract(iris, starts_with(\"Sepal\"))) #>   Sepal.Length Sepal.Width #> 1          5.1         3.5 #> 2          4.9         3.0 #> 3          4.7         3.2 #> 4          4.6         3.1 #> 5          5.0         3.6 #> 6          5.4         3.9 head(data_extract(iris, ends_with(\"Width\"))) #>   Sepal.Width Petal.Width #> 1         3.5         0.2 #> 2         3.0         0.2 #> 3         3.2         0.2 #> 4         3.1         0.2 #> 5         3.6         0.2 #> 6         3.9         0.4 head(data_extract(iris, 2:4)) #>   Sepal.Width Petal.Length Petal.Width #> 1         3.5          1.4         0.2 #> 2         3.0          1.4         0.2 #> 3         3.2          1.3         0.2 #> 4         3.1          1.5         0.2 #> 5         3.6          1.4         0.2 #> 6         3.9          1.7         0.4  # select first of multiple variables data_extract(iris, starts_with(\"Sepal\"), extract = \"first\") #>   [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 #>  [19] 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 #>  [37] 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 #>  [55] 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 #>  [73] 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 #>  [91] 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 #> [109] 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 #> [127] 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 #> [145] 6.7 6.7 6.3 6.5 6.2 5.9  # select first of multiple variables, return as data frame head(data_extract(iris, starts_with(\"Sepal\"), extract = \"first\", as_data_frame = TRUE)) #>   Sepal.Length #> 1          5.1 #> 2          4.9 #> 3          4.7 #> 4          4.6 #> 5          5.0 #> 6          5.4"},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a grouped data frame — data_group","title":"Create a grouped data frame — data_group","text":"function comparable dplyr::group_by(), just following datawizard function design. data_ungroup() removes grouping information grouped data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a grouped data frame — data_group","text":"","code":"data_group(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_ungroup(data, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a grouped data frame — data_group","text":"data data frame select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... Arguments passed functions. Mostly used yet.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a grouped data frame — data_group","text":"grouped data frame, .e. data frame additional information grouping structure saved attributes.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a grouped data frame — data_group","text":"","code":"data(efc) if (requireNamespace(\"poorman\")) {   suppressPackageStartupMessages(library(poorman, quietly = TRUE))    # total mean   efc %>%     summarize(mean_hours = mean(c12hour, na.rm = TRUE))    # mean by educational level   efc %>%     data_group(c172code) %>%     summarize(mean_hours = mean(c12hour, na.rm = TRUE)) } #> Loading required namespace: poorman #> # A tibble: 3 × 2 #> # Groups:   c172code [3] #>   c172code mean_hours #>      <dbl>      <dbl> #> 1        1       87.1 #> 2        2       94.0 #> 3        3       75"},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Return filtered or sliced data frame, or row indices — data_match","title":"Return filtered or sliced data frame, or row indices — data_match","text":"Return filtered (sliced) data frame row indices data frame match specific condition. data_filter() works like data_match(), works logical expressions row indices data frame specify matching conditions.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return filtered or sliced data frame, or row indices — data_match","text":"","code":"data_match(x, to, match = \"and\", return_indices = FALSE, drop_na = TRUE, ...)  data_filter(x, filter, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return filtered or sliced data frame, or row indices — data_match","text":"x data frame. data frame matching specified conditions. Note match value \"\", original row order might changed. See 'Details'. match String, indicating logical operation matching conditions combined. Can \"\" (\"&\"), \"\" (\"|\") \"\" (\"!\"). return_indices Logical, FALSE, return vector rows can used filter original data frame. FALSE (default), returns directly filtered data frame instead row indices. drop_na Logical, TRUE, missing values (NAs) removed filtering data. default behaviour, however, sometimes row indices requested (.e. return_indices=TRUE), might useful preserve NA values, returned row indices match row indices original data frame. ... used. filter logical expression indicating rows keep, numeric vector indicating row indices rows keep. Can also string representation logical expression. e.g. filter = \"x > 4\". might useful used packages avoid defining undefined global variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return filtered or sliced data frame, or row indices — data_match","text":"filtered data frame, row indices match specified configuration.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return filtered or sliced data frame, or row indices — data_match","text":"data_match(), match either \"\" \"\", original row order x might changed. preserving row order required, use data_filter() instead.   data_match() works data frames match conditions , data_filter() basically wrapper around subset(subset = <filter>). However, unlike subset(), preserves label attributes useful working labelled data.","code":"# mimics subset() behaviour, preserving original row order head(data_filter(mtcars[c(\"mpg\", \"vs\", \"am\")], vs == 0 | am == 1)) #>                    mpg vs am #> Mazda RX4         21.0  0  1 #> Mazda RX4 Wag     21.0  0  1 #> Datsun 710        22.8  1  1 #> Hornet Sportabout 18.7  0  0 #> Duster 360        14.3  0  0 #> Merc 450SE        16.4  0  0  # re-sorting rows head(data_match(mtcars[c(\"mpg\", \"vs\", \"am\")],                 data.frame(vs = 0, am = 1),                 match = \"or\")) #>                    mpg vs am #> Mazda RX4         21.0  0  1 #> Mazda RX4 Wag     21.0  0  1 #> Hornet Sportabout 18.7  0  0 #> Duster 360        14.3  0  0 #> Merc 450SE        16.4  0  0 #> Merc 450SL        17.3  0  0"},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return filtered or sliced data frame, or row indices — data_match","text":"","code":"data_match(mtcars, data.frame(vs = 0, am = 1)) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 data_match(mtcars, data.frame(vs = 0, am = c(0, 1))) #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  # observations where \"vs\" is NOT 0 AND \"am\" is NOT 1 data_match(mtcars, data.frame(vs = 0, am = 1), match = \"not\") #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Valiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Merc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Merc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Toyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 # equivalent to data_filter(mtcars, vs != 0 & am != 1) #>                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> Valiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Merc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> Merc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> Merc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Toyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  # observations where EITHER \"vs\" is 0 OR \"am\" is 1 data_match(mtcars, data.frame(vs = 0, am = 1), match = \"or\") #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 # equivalent to data_filter(mtcars, vs == 0 | am == 1) #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  # slice data frame by row indices data_filter(mtcars, 5:10) #>                    mpg cyl  disp  hp drat   wt  qsec vs am gear carb #> Hornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2 #> Valiant           18.1   6 225.0 105 2.76 3.46 20.22  1  0    3    1 #> Duster 360        14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4 #> Merc 240D         24.4   4 146.7  62 3.69 3.19 20.00  1  0    4    2 #> Merc 230          22.8   4 140.8  95 3.92 3.15 22.90  1  0    4    2 #> Merc 280          19.2   6 167.6 123 3.92 3.44 18.30  1  0    4    4  # Define a custom function containing data_filter() and pass variable names # to it using curly brackets my_filter <- function(data, variable) {   data_filter(data, {variable} <= 20) } my_filter(mtcars, \"mpg\") #>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8"},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge (join) two data frames, or a list of data frames — data_merge","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Merge (join) two data frames, list data frames. However, unlike base R's merge(), data_merge() offers methods join data frames, drop data frame column attributes.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"","code":"data_merge(x, ...)  data_join(x, ...)  # S3 method for data.frame data_merge(x, y, join = \"left\", by = NULL, id = NULL, verbose = TRUE, ...)  # S3 method for list data_merge(x, join = \"left\", by = NULL, id = NULL, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"x, y data frame merge. x may also list data frames merged. Note list-method y argument. ... used. join Character vector, indicating method joining data frames. Can \"full\", \"left\" (default), \"right\", \"inner\", \"anti\", \"semi\" \"bind\". See details . Specifications columns used merging. id Optional name ID column created indicate source data frames appended rows. applies join = \"bind\". verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"merged data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"merging-data-frames","dir":"Reference","previous_headings":"","what":"Merging data frames","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Merging data frames performed adding rows (cases), columns (variables) source data frame (y) target data frame (x). usually requires one variables included data frames used merging, typically indicated argument. contains variable present data frames, cases matched filtered identical values x y.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"left-and-right-joins","dir":"Reference","previous_headings":"","what":"Left- and right-joins","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Left- right joins usually add new rows (cases), new columns (variables) existing cases x. join = \"left\" join = \"right\" work, must indicate one columns included data frames. join = \"left\", identifier variable, included x y, variables y copied x, cases y matching values identifier variable x (.e. cases x also found y get related values new columns y). match identifiers x y, copied variable y get NA value particular case. variables occur x y, used identifiers (), renamed avoid multiple identical variable names. Cases y values identifier match x's identifier removed. join = \"right\" works similar way join = \"left\", just cases x matching values identifier variable y chosen.  base R, equivalent merge(x, y, .x = TRUE) merge(x, y, .y = TRUE).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"full-joins","dir":"Reference","previous_headings":"","what":"Full joins","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Full joins copy cases y x. matching cases data frames, values new variables copied y x. cases y present x, added new rows x. Thus, full joins add new columns (variables), also might add new rows (cases).  base R, equivalent merge(x, y, = TRUE).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"inner-joins","dir":"Reference","previous_headings":"","what":"Inner joins","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"Inner joins merge two data frames, however, rows (cases) kept present data frames. Thus, inner joins usually add new columns (variables), also remove rows (cases) occur one data frame.  base R, equivalent merge(x, y).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"binds","dir":"Reference","previous_headings":"","what":"Binds","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"join = \"bind\" row-binds complete second data frame y x. Unlike simple rbind(), requires columns data frames, join = \"bind\" bind shared columns y x, add new columns y x.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_merge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge (join) two data frames, or a list of data frames — data_merge","text":"","code":"x <- data.frame(a = 1:3, b = c(\"a\", \"b\", \"c\"), c = 5:7, id = 1:3) y <- data.frame(c = 6:8, d = c(\"f\", \"g\", \"h\"), e = 100:102, id = 2:4)  x #>   a b c id #> 1 1 a 5  1 #> 2 2 b 6  2 #> 3 3 c 7  3 y #>   c d   e id #> 1 6 f 100  2 #> 2 7 g 101  3 #> 3 8 h 102  4  # \"by\" will default to all shared columns, i.e. \"c\" and \"id\". new columns # \"d\" and \"e\" will be copied from \"y\" to \"x\", but there are only two cases # in \"x\" that have the same values for \"c\" and \"id\" in \"y\". only those cases # have values in the copied columns, the other case gets \"NA\". data_merge(x, y, join = \"left\") #>   a b c id    d   e #> 3 1 a 5  1 <NA>  NA #> 1 2 b 6  2    f 100 #> 2 3 c 7  3    g 101  # we change the id-value here x <- data.frame(a = 1:3, b = c(\"a\", \"b\", \"c\"), c = 5:7, id = 1:3) y <- data.frame(c = 6:8, d = c(\"f\", \"g\", \"h\"), e = 100:102, id = 3:5)  x #>   a b c id #> 1 1 a 5  1 #> 2 2 b 6  2 #> 3 3 c 7  3 y #>   c d   e id #> 1 6 f 100  3 #> 2 7 g 101  4 #> 3 8 h 102  5  # no cases in \"y\" have the same matching \"c\" and \"id\" as in \"x\", thus # copied variables from \"y\" to \"x\" copy no values, all get NA. data_merge(x, y, join = \"left\") #>   a b c id    d  e #> 1 1 a 5  1 <NA> NA #> 2 2 b 6  2 <NA> NA #> 3 3 c 7  3 <NA> NA  # one case in \"y\" has a match in \"id\" with \"x\", thus values for this # case from the remaining variables in \"y\" are copied to \"x\", all other # values (cases) in those remaining variables get NA data_merge(x, y, join = \"left\", by = \"id\") #>   a b id    d   e c.x c.y #> 2 1 a  1 <NA>  NA   5  NA #> 3 2 b  2 <NA>  NA   6  NA #> 1 3 c  3    f 100   7   6  data(mtcars) x <- mtcars[1:5, 1:3] y <- mtcars[28:32, 4:6]  # add ID common column x$id <- 1:5 y$id <- 3:7  # left-join, add new variables and copy values from y to x, # where \"id\" values match data_merge(x, y) #>    mpg cyl disp id  hp drat    wt #> 4 21.0   6  160  1  NA   NA    NA #> 5 21.0   6  160  2  NA   NA    NA #> 1 22.8   4  108  3 113 3.77 1.513 #> 2 21.4   6  258  4 264 4.22 3.170 #> 3 18.7   8  360  5 175 3.62 2.770  # right-join, add new variables and copy values from x to y, # where \"id\" values match data_merge(x, y, join = \"right\") #>    mpg cyl disp id  hp drat    wt #> 1 22.8   4  108  3 113 3.77 1.513 #> 2 21.4   6  258  4 264 4.22 3.170 #> 3 18.7   8  360  5 175 3.62 2.770 #> 4   NA  NA   NA  6 335 3.54 3.570 #> 5   NA  NA   NA  7 109 4.11 2.780  # full-join data_merge(x, y, join = \"full\") #>    mpg cyl disp id  hp drat    wt #> 4 21.0   6  160  1  NA   NA    NA #> 5 21.0   6  160  2  NA   NA    NA #> 1 22.8   4  108  3 113 3.77 1.513 #> 2 21.4   6  258  4 264 4.22 3.170 #> 3 18.7   8  360  5 175 3.62 2.770 #> 6   NA  NA   NA  6 335 3.54 3.570 #> 7   NA  NA   NA  7 109 4.11 2.780   data(mtcars) x <- mtcars[1:5, 1:3] y <- mtcars[28:32, c(1, 4:5)]  # add ID common column x$id <- 1:5 y$id <- 3:7  # left-join, no matching rows (because columns \"id\" and \"disp\" are used) # new variables get all NA values data_merge(x, y) #>    mpg cyl disp id hp drat #> 1 21.0   6  160  1 NA   NA #> 2 21.0   6  160  2 NA   NA #> 3 22.8   4  108  3 NA   NA #> 4 21.4   6  258  4 NA   NA #> 5 18.7   8  360  5 NA   NA  # one common value in \"mpg\", so one row from y is copied to x data_merge(x, y, by = \"mpg\") #>    mpg cyl disp  hp drat id.x id.y #> 2 21.0   6  160  NA   NA    1   NA #> 3 21.0   6  160  NA   NA    2   NA #> 4 22.8   4  108  NA   NA    3   NA #> 1 21.4   6  258 109 4.11    4    7 #> 5 18.7   8  360  NA   NA    5   NA  # only keep rows with matching values in by-column data_merge(x, y, join = \"semi\", by = \"mpg\") #>                 mpg cyl disp id #> Hornet 4 Drive 21.4   6  258  4  # only keep rows with non-matching values in by-column data_merge(x, y, join = \"anti\", by = \"mpg\") #>                    mpg cyl disp id #> Mazda RX4         21.0   6  160  1 #> Mazda RX4 Wag     21.0   6  160  2 #> Datsun 710        22.8   4  108  3 #> Hornet Sportabout 18.7   8  360  5  # merge list of data frames. can be of different rows x <- mtcars[1:5, 1:3] y <- mtcars[28:31, 3:5] z <- mtcars[11:18, c(1, 3:4, 6:8)] x$id <- 1:5 y$id <- 4:7 z$id <- 3:10 data_merge(list(x, y, z), join = \"bind\", by = \"id\", id = \"source\") #>     mpg cyl  disp id  hp drat    wt  qsec vs source #> 1  21.0   6 160.0  1  NA   NA    NA    NA NA      1 #> 2  21.0   6 160.0  2  NA   NA    NA    NA NA      1 #> 3  22.8   4 108.0  3  NA   NA    NA    NA NA      1 #> 4  21.4   6 258.0  4  NA   NA    NA    NA NA      1 #> 5  18.7   8 360.0  5  NA   NA    NA    NA NA      1 #> 6    NA  NA  95.1  4 113 3.77    NA    NA NA      2 #> 7    NA  NA 351.0  5 264 4.22    NA    NA NA      2 #> 8    NA  NA 145.0  6 175 3.62    NA    NA NA      2 #> 9    NA  NA 301.0  7 335 3.54    NA    NA NA      2 #> 10 17.8  NA 167.6  3 123   NA 3.440 18.90  1      3 #> 11 16.4  NA 275.8  4 180   NA 4.070 17.40  0      3 #> 12 17.3  NA 275.8  5 180   NA 3.730 17.60  0      3 #> 13 15.2  NA 275.8  6 180   NA 3.780 18.00  0      3 #> 14 10.4  NA 472.0  7 205   NA 5.250 17.98  0      3 #> 15 10.4  NA 460.0  8 215   NA 5.424 17.82  0      3 #> 16 14.7  NA 440.0  9 230   NA 5.345 17.42  0      3 #> 17 32.4  NA  78.7 10  66   NA 2.200 19.47  1      3"},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition data — data_partition","title":"Partition data — data_partition","text":"Creates data partitions (instance, training test set) based data frame can also stratified (.e., evenly spread given factor) using group argument.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition data — data_partition","text":"","code":"data_partition(   data,   proportion = 0.7,   group = NULL,   seed = NULL,   row_id = \".row_id\",   verbose = TRUE,   training_proportion = proportion,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partition data — data_partition","text":"data data frame, object can coerced data frame. proportion Scalar (0 1) numeric vector, indicating proportion(s) training set(s). sum proportion must greater 1. remaining part used test set. group character vector indicating name(s) column(s) used stratified partitioning. seed random number generator seed. Enter integer (e.g. 123) random sampling time run function. row_id Character string, indicating name column contains row-id's. verbose Toggle messages warnings. training_proportion Deprecated, please use proportion. ... arguments passed functions.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partition data — data_partition","text":"list data frames. list includes one training set per given proportion remaining data test set. List elements training sets named given proportions (e.g., $p_0.7), test set named $test.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_partition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partition data — data_partition","text":"","code":"data(iris) out <- data_partition(iris, proportion = 0.9) out$test #>    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species .row_id #> 1           4.8         3.4          1.6         0.2     setosa      12 #> 2           5.8         4.0          1.2         0.2     setosa      15 #> 3           4.8         3.1          1.6         0.2     setosa      31 #> 4           5.0         3.5          1.3         0.3     setosa      41 #> 5           6.0         2.2          4.0         1.0 versicolor      63 #> 6           5.6         2.9          3.6         1.3 versicolor      65 #> 7           6.7         3.1          4.4         1.4 versicolor      66 #> 8           6.3         2.5          4.9         1.5 versicolor      73 #> 9           5.5         2.4          3.8         1.1 versicolor      81 #> 10          5.7         2.9          4.2         1.3 versicolor      97 #> 11          6.3         3.3          6.0         2.5  virginica     101 #> 12          6.3         2.9          5.6         1.8  virginica     104 #> 13          6.5         3.0          5.8         2.2  virginica     105 #> 14          5.7         2.5          5.0         2.0  virginica     114 #> 15          6.9         3.1          5.1         2.3  virginica     142 nrow(out$p_0.9) #> [1] 135  # Stratify by group (equal proportions of each species) out <- data_partition(iris, proportion = 0.9, group = \"Species\") out$test #>    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species .row_id #> 1           5.8         4.0          1.2         0.2     setosa      15 #> 2           5.7         4.4          1.5         0.4     setosa      16 #> 3           5.7         3.8          1.7         0.3     setosa      19 #> 4           5.1         3.7          1.5         0.4     setosa      22 #> 5           4.4         3.0          1.3         0.2     setosa      39 #> 6           7.0         3.2          4.7         1.4 versicolor      51 #> 7           6.6         2.9          4.6         1.3 versicolor      59 #> 8           5.6         2.9          3.6         1.3 versicolor      65 #> 9           6.2         2.2          4.5         1.5 versicolor      69 #> 10          6.6         3.0          4.4         1.4 versicolor      76 #> 11          6.3         3.3          6.0         2.5  virginica     101 #> 12          6.5         3.0          5.8         2.2  virginica     105 #> 13          6.3         2.7          4.9         1.8  virginica     124 #> 14          7.2         3.2          6.0         1.8  virginica     126 #> 15          6.7         3.0          5.2         2.3  virginica     146  # Create multiple partitions out <- data_partition(iris, proportion = c(0.3, 0.3)) lapply(out, head) #> $p_0.3 #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .row_id #> 1          4.7         3.2          1.3         0.2  setosa       3 #> 2          5.0         3.4          1.5         0.2  setosa       8 #> 3          4.4         2.9          1.4         0.2  setosa       9 #> 4          4.9         3.1          1.5         0.1  setosa      10 #> 5          5.4         3.7          1.5         0.2  setosa      11 #> 6          4.8         3.4          1.6         0.2  setosa      12 #>  #> $p_0.3 #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .row_id #> 1          5.0         3.6          1.4         0.2  setosa       5 #> 2          5.4         3.9          1.7         0.4  setosa       6 #> 3          4.6         3.4          1.4         0.3  setosa       7 #> 4          4.3         3.0          1.1         0.1  setosa      14 #> 5          5.4         3.9          1.3         0.4  setosa      17 #> 6          5.7         3.8          1.7         0.3  setosa      19 #>  #> $test #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .row_id #> 1          5.1         3.5          1.4         0.2  setosa       1 #> 2          4.9         3.0          1.4         0.2  setosa       2 #> 3          4.6         3.1          1.5         0.2  setosa       4 #> 4          4.8         3.0          1.4         0.1  setosa      13 #> 5          5.8         4.0          1.2         0.2  setosa      15 #> 6          5.1         3.8          1.5         0.3  setosa      20 #>   # Create multiple partitions, stratified by group - 30% equally sampled # from species in first training set, 50% in second training set and # remaining 20% equally sampled from each species in test set. out <- data_partition(iris, proportion = c(0.3, 0.5), group = \"Species\") lapply(out, function(i) table(i$Species)) #> $p_0.3 #>  #>     setosa versicolor  virginica  #>         15         15         15  #>  #> $p_0.5 #>  #>     setosa versicolor  virginica  #>         25         25         25  #>  #> $test #>  #>     setosa versicolor  virginica  #>         10         10         10  #>"},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":null,"dir":"Reference","previous_headings":"","what":"Peek at values and type of variables in a data frame — data_peek","title":"Peek at values and type of variables in a data frame — data_peek","text":"function creates table data frame, showing column names, variable types first values (many fit screen).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Peek at values and type of variables in a data frame — data_peek","text":"","code":"data_peek(x, ...)  # S3 method for data.frame data_peek(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   width = NULL,   n = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Peek at values and type of variables in a data frame — data_peek","text":"x data frame. ... used. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. width Maximum width line length display. NULL, width determined using options()$width. n Number variables display. NULL, variables shown. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Peek at values and type of variables in a data frame — data_peek","text":"data frame three columns, containing information name, type first values input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Peek at values and type of variables in a data frame — data_peek","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_peek.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Peek at values and type of variables in a data frame — data_peek","text":"","code":"data(efc) data_peek(efc) #> Data frame with 100 rows and 5 columns #>  #> Variable | Type    | Values                                            #> ---------------------------------------------------------------------- #> c12hour  | numeric | 16, 148, 70, NA, 168, 16, 161, 110, 28, 40, ...   #> e16sex   | numeric | 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, ...  #> e42dep   | factor  | 3, 3, 3, NA, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, ... #> c172code | numeric | 2, 2, 1, 2, 2, 2, 2, 2, NA, 2, 2, 2, 3, 1, 3, ... #> neg_c_7  | numeric | 12, 20, 11, 10, 12, 19, 15, 11, 15, 10, 28, ..."},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":null,"dir":"Reference","previous_headings":"","what":"Read (import) data files from various sources — data_read","title":"Read (import) data files from various sources — data_read","text":"functions imports data various file types. small wrapper around haven::read_spss(), haven::read_stata(), haven::read_sas(), readxl::read_excel() data.table::fread() resp. readr::read_delim() (latter package data.table installed). Thus, supported file types importing data data files SPSS, SAS Stata, Excel files text files (like '.csv' files). non-supported file types passed rio::import().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read (import) data files from various sources — data_read","text":"","code":"data_read(path, path_catalog = NULL, encoding = NULL, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read (import) data files from various sources — data_read","text":"path Character string, file path data file. path_catalog Character string, path catalog file. relevant SAS data files. encoding character encoding used file. Usually needed. verbose Toggle warnings messages. ... Arguments passed related read_*() function.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read (import) data files from various sources — data_read","text":"data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"supported-file-types","dir":"Reference","previous_headings":"","what":"Supported file types","title":"Read (import) data files from various sources — data_read","text":"data_read() wrapper around haven, data.table, readr readxl rio packages. Currently supported file types .txt, .csv, .xls, .xlsx, .sav, .por, .dta .sas (related files). file types passed rio::import().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"compressed-files-zip-and-urls","dir":"Reference","previous_headings":"","what":"Compressed files (zip) and URLs","title":"Read (import) data files from various sources — data_read","text":"data_read() can also read mentioned files URLs inside zip-compressed files. Thus, path can also URL file like \"http://www.url.com/file.csv\". path points zip-compressed file, multiple files inside zip-archive, first supported file extracted loaded.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"general-behaviour","dir":"Reference","previous_headings":"","what":"General behaviour","title":"Read (import) data files from various sources — data_read","text":"data_read() detects appropriate read_*() function based file-extension data file. Thus, cases enough specify path argument. However, control needed, arguments ... passed related read_*() function.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_read.html","id":"differences-to-other-packages-that-read-foreign-data-formats","dir":"Reference","previous_headings":"","what":"Differences to other packages that read foreign data formats","title":"Read (import) data files from various sources — data_read","text":"data_read() comparable rio::import(). data files SPSS, SAS Stata, support labelled data, variables converted appropriate type. major difference rio::import() data_read() automatically converts variables factors, unless variables partially labelled, case variables converted numerics. Character vectors preserved. Hence, variables, values labelled, converted factors, imported value labels set factor levels. Else, variable value labels less value labels values, variable either converted numeric character vector. Value labels preserved \"labels\" attribute.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":null,"dir":"Reference","previous_headings":"","what":"Relocate (reorder) columns of a data frame — data_relocate","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"data_relocate() reorder columns specific positions, indicated . data_reorder() instead move selected columns beginning data frame. Finally, data_remove() removes columns data frame. functions support select-helpers allow flexible specification search pattern find matching columns, reordered removed.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"","code":"data_relocate(   data,   select,   before = NULL,   after = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_reorder(   data,   select,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_remove(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". , Destination columns. Supplying neither move columns left-hand side; specifying error. Can character vector, indicating name destination column, numeric value, indicating index number destination column. -1, added last column. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... Arguments passed functions. Mostly used yet. exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"data frame reordered columns.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_relocate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relocate (reorder) columns of a data frame — data_relocate","text":"","code":"# Reorder columns head(data_relocate(iris, select = \"Species\", before = \"Sepal.Length\")) #>   Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1  setosa          5.1         3.5          1.4         0.2 #> 2  setosa          4.9         3.0          1.4         0.2 #> 3  setosa          4.7         3.2          1.3         0.2 #> 4  setosa          4.6         3.1          1.5         0.2 #> 5  setosa          5.0         3.6          1.4         0.2 #> 6  setosa          5.4         3.9          1.7         0.4 head(data_relocate(iris, select = \"Species\", before = \"Sepal.Width\")) #>   Sepal.Length Species Sepal.Width Petal.Length Petal.Width #> 1          5.1  setosa         3.5          1.4         0.2 #> 2          4.9  setosa         3.0          1.4         0.2 #> 3          4.7  setosa         3.2          1.3         0.2 #> 4          4.6  setosa         3.1          1.5         0.2 #> 5          5.0  setosa         3.6          1.4         0.2 #> 6          5.4  setosa         3.9          1.7         0.4 head(data_relocate(iris, select = \"Sepal.Width\", after = \"Species\")) #>   Sepal.Length Petal.Length Petal.Width Species Sepal.Width #> 1          5.1          1.4         0.2  setosa         3.5 #> 2          4.9          1.4         0.2  setosa         3.0 #> 3          4.7          1.3         0.2  setosa         3.2 #> 4          4.6          1.5         0.2  setosa         3.1 #> 5          5.0          1.4         0.2  setosa         3.6 #> 6          5.4          1.7         0.4  setosa         3.9 # same as head(data_relocate(iris, select = \"Sepal.Width\", after = -1)) #>   Sepal.Length Petal.Length Petal.Width Species Sepal.Width #> 1          5.1          1.4         0.2  setosa         3.5 #> 2          4.9          1.4         0.2  setosa         3.0 #> 3          4.7          1.3         0.2  setosa         3.2 #> 4          4.6          1.5         0.2  setosa         3.1 #> 5          5.0          1.4         0.2  setosa         3.6 #> 6          5.4          1.7         0.4  setosa         3.9  # reorder multiple columns head(data_relocate(iris, select = c(\"Species\", \"Petal.Length\"), after = \"Sepal.Width\")) #>   Sepal.Length Sepal.Width Species Petal.Length Petal.Width #> 1          5.1         3.5  setosa          1.4         0.2 #> 2          4.9         3.0  setosa          1.4         0.2 #> 3          4.7         3.2  setosa          1.3         0.2 #> 4          4.6         3.1  setosa          1.5         0.2 #> 5          5.0         3.6  setosa          1.4         0.2 #> 6          5.4         3.9  setosa          1.7         0.4 # same as head(data_relocate(iris, select = c(\"Species\", \"Petal.Length\"), after = 2)) #>   Sepal.Length Sepal.Width Species Petal.Length Petal.Width #> 1          5.1         3.5  setosa          1.4         0.2 #> 2          4.9         3.0  setosa          1.4         0.2 #> 3          4.7         3.2  setosa          1.3         0.2 #> 4          4.6         3.1  setosa          1.5         0.2 #> 5          5.0         3.6  setosa          1.4         0.2 #> 6          5.4         3.9  setosa          1.7         0.4  # Reorder columns head(data_reorder(iris, c(\"Species\", \"Sepal.Length\"))) #>   Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1  setosa          5.1         3.5          1.4         0.2 #> 2  setosa          4.9         3.0          1.4         0.2 #> 3  setosa          4.7         3.2          1.3         0.2 #> 4  setosa          4.6         3.1          1.5         0.2 #> 5  setosa          5.0         3.6          1.4         0.2 #> 6  setosa          5.4         3.9          1.7         0.4 head(data_reorder(iris, c(\"Species\", \"dupa\"))) # Safe for non-existing cols #> Warning: Following variable(s) were not found: dupa #>   Species Sepal.Length Sepal.Width Petal.Length Petal.Width #> 1  setosa          5.1         3.5          1.4         0.2 #> 2  setosa          4.9         3.0          1.4         0.2 #> 3  setosa          4.7         3.2          1.3         0.2 #> 4  setosa          4.6         3.1          1.5         0.2 #> 5  setosa          5.0         3.6          1.4         0.2 #> 6  setosa          5.4         3.9          1.7         0.4  # Remove columns head(data_remove(iris, \"Sepal.Length\")) #>   Sepal.Width Petal.Length Petal.Width Species #> 1         3.5          1.4         0.2  setosa #> 2         3.0          1.4         0.2  setosa #> 3         3.2          1.3         0.2  setosa #> 4         3.1          1.5         0.2  setosa #> 5         3.6          1.4         0.2  setosa #> 6         3.9          1.7         0.4  setosa head(data_remove(iris, starts_with(\"Sepal\"))) #>   Petal.Length Petal.Width Species #> 1          1.4         0.2  setosa #> 2          1.4         0.2  setosa #> 3          1.3         0.2  setosa #> 4          1.5         0.2  setosa #> 5          1.4         0.2  setosa #> 6          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename columns and variable names — data_addprefix","title":"Rename columns and variable names — data_addprefix","text":"Safe intuitive functions rename variables rows data frames. data_rename() rename column names, .e. facilitates renaming variables data_addprefix() data_addsuffix() add prefixes suffixes column names. data_rename_rows() convenient shortcut add rename row names data frame, unlike row.names(), input output data frame, thus, integrating smoothly possible pipe-workflow.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename columns and variable names — data_addprefix","text":"","code":"data_addprefix(   data,   pattern,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_addsuffix(   data,   pattern,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_rename(data, pattern = NULL, replacement = NULL, safe = TRUE, ...)  data_rename_rows(data, rows = NULL)"},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename columns and variable names — data_addprefix","text":"data data frame, object can coerced data frame. pattern Character vector. data_rename(), indicates columns selected renaming. Can NULL (case columns selected). data_addprefix() data_addsuffix(), character string, added prefix suffix column names. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... arguments passed functions. replacement Character vector. Indicates new name columns selected pattern. Can NULL (case column numbered sequential order). NULL, pattern replacement must length. safe throw error instance variable renamed/removed exist. rows Vector row names.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename columns and variable names — data_addprefix","text":"modified data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_rename.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rename columns and variable names — data_addprefix","text":"","code":"# Add prefix / suffix to all columns head(data_addprefix(iris, \"NEW_\")) #>   NEW_Sepal.Length NEW_Sepal.Width NEW_Petal.Length NEW_Petal.Width NEW_Species #> 1              5.1             3.5              1.4             0.2      setosa #> 2              4.9             3.0              1.4             0.2      setosa #> 3              4.7             3.2              1.3             0.2      setosa #> 4              4.6             3.1              1.5             0.2      setosa #> 5              5.0             3.6              1.4             0.2      setosa #> 6              5.4             3.9              1.7             0.4      setosa head(data_addsuffix(iris, \"_OLD\")) #>   Sepal.Length_OLD Sepal.Width_OLD Petal.Length_OLD Petal.Width_OLD Species_OLD #> 1              5.1             3.5              1.4             0.2      setosa #> 2              4.9             3.0              1.4             0.2      setosa #> 3              4.7             3.2              1.3             0.2      setosa #> 4              4.6             3.1              1.5             0.2      setosa #> 5              5.0             3.6              1.4             0.2      setosa #> 6              5.4             3.9              1.7             0.4      setosa  # Rename columns head(data_rename(iris, \"Sepal.Length\", \"length\")) #>   length Sepal.Width Petal.Length Petal.Width Species #> 1    5.1         3.5          1.4         0.2  setosa #> 2    4.9         3.0          1.4         0.2  setosa #> 3    4.7         3.2          1.3         0.2  setosa #> 4    4.6         3.1          1.5         0.2  setosa #> 5    5.0         3.6          1.4         0.2  setosa #> 6    5.4         3.9          1.7         0.4  setosa # data_rename(iris, \"FakeCol\", \"length\", safe=FALSE)  # This fails head(data_rename(iris, \"FakeCol\", \"length\")) # This doesn't #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          5.1         3.5          1.4         0.2  setosa #> 2          4.9         3.0          1.4         0.2  setosa #> 3          4.7         3.2          1.3         0.2  setosa #> 4          4.6         3.1          1.5         0.2  setosa #> 5          5.0         3.6          1.4         0.2  setosa #> 6          5.4         3.9          1.7         0.4  setosa head(data_rename(iris, c(\"Sepal.Length\", \"Sepal.Width\"), c(\"length\", \"width\"))) #>   length width Petal.Length Petal.Width Species #> 1    5.1   3.5          1.4         0.2  setosa #> 2    4.9   3.0          1.4         0.2  setosa #> 3    4.7   3.2          1.3         0.2  setosa #> 4    4.6   3.1          1.5         0.2  setosa #> 5    5.0   3.6          1.4         0.2  setosa #> 6    5.4   3.9          1.7         0.4  setosa  # Reset names head(data_rename(iris, NULL)) #>     1   2   3   4      5 #> 1 5.1 3.5 1.4 0.2 setosa #> 2 4.9 3.0 1.4 0.2 setosa #> 3 4.7 3.2 1.3 0.2 setosa #> 4 4.6 3.1 1.5 0.2 setosa #> 5 5.0 3.6 1.4 0.2 setosa #> 6 5.4 3.9 1.7 0.4 setosa  # Change all head(data_rename(iris, paste0(\"Var\", 1:5))) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          5.1         3.5          1.4         0.2  setosa #> 2          4.9         3.0          1.4         0.2  setosa #> 3          4.7         3.2          1.3         0.2  setosa #> 4          4.6         3.1          1.5         0.2  setosa #> 5          5.0         3.6          1.4         0.2  setosa #> 6          5.4         3.9          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore the type of columns according to a reference data frame — data_restoretype","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"Restore type columns according reference data frame","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"","code":"data_restoretype(data, reference = NULL, ...)"},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"data data frame pivot. reference reference data frame find correct column types. ... Currently used.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"data frame columns whose types restored based reference data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_restoretype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore the type of columns according to a reference data frame — data_restoretype","text":"","code":"data <- data.frame(   Sepal.Length = c(\"1\", \"3\", \"2\"),   Species = c(\"setosa\", \"versicolor\", \"setosa\"),   New = c(\"1\", \"3\", \"4\") )  fixed <- data_restoretype(data, reference = iris) summary(fixed) #>   Sepal.Length       Species      New            #>  Min.   :1.0   setosa    :2   Length:3           #>  1st Qu.:1.5   versicolor:1   Class :character   #>  Median :2.0   virginica :0   Mode  :character   #>  Mean   :2.0                                     #>  3rd Qu.:2.5                                     #>  Max.   :3.0"},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":null,"dir":"Reference","previous_headings":"","what":"Rotate a data frame — data_rotate","title":"Rotate a data frame — data_rotate","text":"function rotates data frame, .e. columns become rows vice versa. equivalent using t() restores data.frame class, preserves attributes prints warning data type modified (see example).","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rotate a data frame — data_rotate","text":"","code":"data_rotate(data, rownames = NULL, colnames = FALSE, verbose = TRUE)  data_transpose(data, rownames = NULL, colnames = FALSE, verbose = TRUE)"},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rotate a data frame — data_rotate","text":"data data frame. rownames Character vector (optional). NULL, data frame's rownames added (first) column output, rownames name column. colnames Logical character vector (optional). TRUE, values first column x used column names rotated data frame. character vector, values column used column names. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rotate a data frame — data_rotate","text":"(rotated) data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_rotate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rotate a data frame — data_rotate","text":"","code":"x <- mtcars[1:3, 1:4]  x #>                mpg cyl disp  hp #> Mazda RX4     21.0   6  160 110 #> Mazda RX4 Wag 21.0   6  160 110 #> Datsun 710    22.8   4  108  93  data_rotate(x) #>      Mazda RX4 Mazda RX4 Wag Datsun 710 #> mpg         21            21       22.8 #> cyl          6             6        4.0 #> disp       160           160      108.0 #> hp         110           110       93.0 data_rotate(x, rownames = \"property\") #>   property Mazda RX4 Mazda RX4 Wag Datsun 710 #> 1      mpg        21            21       22.8 #> 2      cyl         6             6        4.0 #> 3     disp       160           160      108.0 #> 4       hp       110           110       93.0  # use values in 1. column as column name data_rotate(x, colnames = TRUE) #>       21  21 22.8 #> cyl    6   6    4 #> disp 160 160  108 #> hp   110 110   93 data_rotate(x, rownames = \"property\", colnames = TRUE) #>   property  21  21 22.8 #> 1      cyl   6   6    4 #> 2     disp 160 160  108 #> 3       hp 110 110   93  # warn that data types are changed str(data_rotate(iris[1:4, ])) #> Warning: Your data frame contains mixed types of data. After transposition, all #>   variables will be transformed into characters. #> 'data.frame':\t5 obs. of  4 variables: #>  $ 1: chr  \"5.1\" \"3.5\" \"1.4\" \"0.2\" ... #>  $ 2: chr  \"4.9\" \"3.0\" \"1.4\" \"0.2\" ... #>  $ 3: chr  \"4.7\" \"3.2\" \"1.3\" \"0.2\" ... #>  $ 4: chr  \"4.6\" \"3.1\" \"1.5\" \"0.2\" ...  # use either first column or specific column for column names x <- data.frame(a = 1:5, b = 11:15, c = letters[1:5], d = rnorm(5)) data_rotate(x, colnames = TRUE) #> Warning: Your data frame contains mixed types of data. After transposition, all #>   variables will be transformed into characters. #>            1          2          3          4          5 #> b         11         12         13         14         15 #> c          a          b          c          d          e #> d  0.3461036 -0.6470456 -2.1576463  0.8842508 -0.8294776 data_rotate(x, colnames = \"c\") #> Warning: Your data frame contains mixed types of data. After transposition, all #>   variables will be transformed into characters. #>            a          b         c          d          e #> a  1.0000000  2.0000000  3.000000  4.0000000  5.0000000 #> b 11.0000000 12.0000000 13.000000 14.0000000 15.0000000 #> d  0.3461036 -0.6470456 -2.157646  0.8842508 -0.8294776"},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create frequency tables of variables — data_tabulate","title":"Create frequency tables of variables — data_tabulate","text":"function creates frequency tables variables, including number levels/values well distribution raw, valid cumulative percentages.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create frequency tables of variables — data_tabulate","text":"","code":"data_tabulate(x, ...)  # S3 method for default data_tabulate(x, drop_levels = FALSE, name = NULL, verbose = TRUE, ...)  # S3 method for data.frame data_tabulate(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   collapse = FALSE,   drop_levels = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create frequency tables of variables — data_tabulate","text":"x (grouped) data frame, vector factor. ... used. drop_levels Logical, TRUE, factor levels occur data included table (frequency zero), else unused factor levels dropped frequency table. name Optional character string, includes name used printing. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. collapse Logical, TRUE collapses multiple tables one larger table printing. affects printing, returned object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create frequency tables of variables — data_tabulate","text":"data frame, list data frames, one frequency table data frame per variable.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Create frequency tables of variables — data_tabulate","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_tabulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create frequency tables of variables — data_tabulate","text":"","code":"data(efc)  # vector/factor data_tabulate(efc$c172code) #> carer's level of education (efc$c172code) <numeric> #> # total N=100 valid N=90 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  8 |  8.00 |    8.89 |         8.89 #> 2     | 66 | 66.00 |   73.33 |        82.22 #> 3     | 16 | 16.00 |   17.78 |       100.00 #> <NA>  | 10 | 10.00 |    <NA> |         <NA>  # data frame data_tabulate(efc, c(\"e42dep\", \"c172code\")) #> elder's dependency (e42dep) <categorical> #> # total N=100 valid N=97 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  2 |  2.00 |    2.06 |         2.06 #> 2     |  4 |  4.00 |    4.12 |         6.19 #> 3     | 28 | 28.00 |   28.87 |        35.05 #> 4     | 63 | 63.00 |   64.95 |       100.00 #> <NA>  |  3 |  3.00 |    <NA> |         <NA> #>  #> carer's level of education (c172code) <numeric> #> # total N=100 valid N=90 #>  #> Value |  N | Raw % | Valid % | Cumulative % #> ------+----+-------+---------+------------- #> 1     |  8 |  8.00 |    8.89 |         8.89 #> 2     | 66 | 66.00 |   73.33 |        82.22 #> 3     | 16 | 16.00 |   17.78 |       100.00 #> <NA>  | 10 | 10.00 |    <NA> |         <NA>  # grouped data frame if (requireNamespace(\"poorman\")) {   suppressPackageStartupMessages(library(poorman, quietly = TRUE))   efc %>%     group_by(c172code) %>%     data_tabulate(\"e16sex\")    # collapse tables   efc %>%     group_by(c172code) %>%     data_tabulate(\"e16sex\", collapse = TRUE) } #> # Frequency Table #>  #> Variable |         Group | Value |  N | Raw % | Valid % | Cumulative % #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   |  c172code (1) |     1 |  5 | 62.50 |   62.50 |        62.50 #>          |               |     2 |  3 | 37.50 |   37.50 |       100.00 #>          |               |  <NA> |  0 |  0.00 |    <NA> |         <NA> #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   |  c172code (2) |     1 | 32 | 48.48 |   48.48 |        48.48 #>          |               |     2 | 34 | 51.52 |   51.52 |       100.00 #>          |               |  <NA> |  0 |  0.00 |    <NA> |         <NA> #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   |  c172code (3) |     1 |  4 | 25.00 |   25.00 |        25.00 #>          |               |     2 | 12 | 75.00 |   75.00 |       100.00 #>          |               |  <NA> |  0 |  0.00 |    <NA> |         <NA> #> ---------+---------------+-------+----+-------+---------+------------- #> e16sex   | c172code (NA) |     1 |  5 | 50.00 |   50.00 |        50.00 #>          |               |     2 |  5 | 50.00 |   50.00 |       100.00 #>          |               |  <NA> |  0 |  0.00 |    <NA> |         <NA> #> ----------------------------------------------------------------------  # for larger N's (> 100000), a big mark is automatically added set.seed(123) x <- sample(1:3, 1e6, TRUE) data_tabulate(x, name = \"Large Number\") #> Large Number (x) <integer> #> # total N=1000000 valid N=1000000 #>  #> Value |       N | Raw % | Valid % | Cumulative % #> ------+---------+-------+---------+------------- #> 1     | 333,852 | 33.39 |   33.39 |        33.39 #> 2     | 332,910 | 33.29 |   33.29 |        66.68 #> 3     | 333,238 | 33.32 |   33.32 |       100.00 #> <NA>  |       0 |  0.00 |    <NA> |         <NA>  # to remove the big mark, use \"print(..., big_mark = \"\")\" print(data_tabulate(x), big_mark = \"\") #> x <integer> #> # total N=1000000 valid N=1000000 #>  #> Value |      N | Raw % | Valid % | Cumulative % #> ------+--------+-------+---------+------------- #> 1     | 333852 | 33.39 |   33.39 |        33.39 #> 2     | 332910 | 33.29 |   33.29 |        66.68 #> 3     | 333238 | 33.32 |   33.32 |       100.00 #> <NA>  |      0 |  0.00 |    <NA> |         <NA>"},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape (pivot) data from wide to long — data_to_long","title":"Reshape (pivot) data from wide to long — data_to_long","text":"function \"lengthens\" data, increasing number rows decreasing number columns. dependency-free base-R equivalent tidyr::pivot_longer().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape (pivot) data from wide to long — data_to_long","text":"","code":"data_to_long(   data,   select = \"all\",   names_to = \"name\",   names_prefix = NULL,   names_sep = NULL,   names_pattern = NULL,   values_to = \"value\",   values_drop_na = FALSE,   rows_to = NULL,   ignore_case = FALSE,   regex = FALSE,   ...,   cols,   colnames_to )  reshape_longer(   data,   select = \"all\",   names_to = \"name\",   names_prefix = NULL,   names_sep = NULL,   names_pattern = NULL,   values_to = \"value\",   values_drop_na = FALSE,   rows_to = NULL,   ignore_case = FALSE,   regex = FALSE,   ...,   cols,   colnames_to )"},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape (pivot) data from wide to long — data_to_long","text":"data data frame pivot. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". names_to name new column contain column names. names_prefix regular expression used remove matching text start variable name. names_sep, names_pattern names_to contains multiple values, argument controls column name broken . names_pattern takes regular expression containing matching groups, .e. \"()\". values_to name new column contain values pivoted variables. values_drop_na TRUE, drop rows contain NA values_to column. effectively converts explicit missing values implicit missing values, generally used missing values data created structure. rows_to name column contain row names row numbers original data. NULL, removed. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. ... Currently used. cols Identical select. argument ensure compatibility tidyr::pivot_longer(). select cols provided, cols used. colnames_to Deprecated. Use names_to instead.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape (pivot) data from wide to long — data_to_long","text":"tibble provided input, reshape_longer() also returns tibble. Otherwise, returns data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_to_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape (pivot) data from wide to long — data_to_long","text":"","code":"# \\donttest{ wide_data <- data.frame(replicate(5, rnorm(10)))  # Default behaviour (equivalent to tidyr::pivot_longer(wide_data, cols = 1:5)) data_to_long(wide_data) #>    name       value #> 1    X1  0.96438796 #> 2    X2 -0.05906520 #> 3    X3 -0.49945619 #> 4    X4 -1.18164198 #> 5    X5 -0.26924131 #> 6    X1  0.78540975 #> 7    X2 -0.66621750 #> 8    X3  1.11673935 #> 9    X4 -0.43727481 #> 10   X5 -0.28183866 #> 11   X1 -0.68673736 #> 12   X2 -0.83318830 #> 13   X3  0.17915927 #> 14   X4 -0.27775661 #> 15   X5  1.62361443 #> 16   X1 -0.35491405 #> 17   X2 -1.41166020 #> 18   X3 -1.14038587 #> 19   X4 -0.65407266 #> 20   X5  0.82933164 #> 21   X1 -0.25090623 #> 22   X2  0.22522310 #> 23   X3  0.80261795 #> 24   X4  0.18375250 #> 25   X5 -0.79579710 #> 26   X1  0.71122444 #> 27   X2  1.30430074 #> 28   X3 -0.01983587 #> 29   X4 -0.67286229 #> 30   X5 -0.52205496 #> 31   X1  1.69081622 #> 32   X2  0.28000624 #> 33   X3  0.73973690 #> 34   X4  1.98316979 #> 35   X5 -0.02966633 #> 36   X1  0.21996840 #> 37   X2  1.21381633 #> 38   X3 -1.76563045 #> 39   X4  0.98711564 #> 40   X5  0.72787721 #> 41   X1 -0.88773194 #> 42   X2 -0.53360955 #> 43   X3  0.74375283 #> 44   X4 -0.49170812 #> 45   X5 -2.91160978 #> 46   X1 -0.91386940 #> 47   X2  0.78988333 #> 48   X3 -0.44083106 #> 49   X4 -0.35785520 #> 50   X5 -1.48411421  # Customizing the names data_to_long(wide_data,   select = c(1, 2),   names_to = \"Column\",   values_to = \"Numbers\",   rows_to = \"Row\" ) #>             X3         X4          X5 Row Column    Numbers #> 1  -0.49945619 -1.1816420 -0.26924131   1     X1  0.9643880 #> 2  -0.49945619 -1.1816420 -0.26924131   1     X2 -0.0590652 #> 3   1.11673935 -0.4372748 -0.28183866   2     X1  0.7854097 #> 4   1.11673935 -0.4372748 -0.28183866   2     X2 -0.6662175 #> 5   0.17915927 -0.2777566  1.62361443   3     X1 -0.6867374 #> 6   0.17915927 -0.2777566  1.62361443   3     X2 -0.8331883 #> 7  -1.14038587 -0.6540727  0.82933164   4     X1 -0.3549140 #> 8  -1.14038587 -0.6540727  0.82933164   4     X2 -1.4116602 #> 9   0.80261795  0.1837525 -0.79579710   5     X1 -0.2509062 #> 10  0.80261795  0.1837525 -0.79579710   5     X2  0.2252231 #> 11 -0.01983587 -0.6728623 -0.52205496   6     X1  0.7112244 #> 12 -0.01983587 -0.6728623 -0.52205496   6     X2  1.3043007 #> 13  0.73973690  1.9831698 -0.02966633   7     X1  1.6908162 #> 14  0.73973690  1.9831698 -0.02966633   7     X2  0.2800062 #> 15 -1.76563045  0.9871156  0.72787721   8     X1  0.2199684 #> 16 -1.76563045  0.9871156  0.72787721   8     X2  1.2138163 #> 17  0.74375283 -0.4917081 -2.91160978   9     X1 -0.8877319 #> 18  0.74375283 -0.4917081 -2.91160978   9     X2 -0.5336095 #> 19 -0.44083106 -0.3578552 -1.48411421  10     X1 -0.9138694 #> 20 -0.44083106 -0.3578552 -1.48411421  10     X2  0.7898833  # Full example # ------------------ if (require(\"psych\")) {   data <- psych::bfi # Wide format with one row per participant's personality test    # Pivot long format   data_to_long(data,     select = regex(\"\\\\d\"), # Select all columns that contain a digit     names_to = \"Item\",     values_to = \"Score\",     rows_to = \"Participant\"   )    if (require(\"tidyr\")) {     reshape_longer(       tidyr::who,       select = new_sp_m014:newrel_f65,       names_to = c(\"diagnosis\", \"gender\", \"age\"),       names_pattern = \"new_?(.*)_(.)(.*)\",       values_to = \"count\"     )   } } #> Loading required package: psych #>  #> Attaching package: ‘psych’ #> The following object is masked from ‘package:datawizard’: #>  #>     rescale #> Loading required package: tidyr #>  #> Attaching package: ‘tidyr’ #> The following objects are masked from ‘package:poorman’: #>  #>     %>%, all_of, any_of, contains, ends_with, everything, last_col, #>     matches, num_range, pivot_longer, pivot_wider, replace_na, #>     starts_with, unite #> # A tibble: 405,440 × 8 #>    country     iso2  iso3   year diagnosis gender age   count #>  * <chr>       <chr> <chr> <int> <chr>     <chr>  <chr> <int> #>  1 Afghanistan AF    AFG    1980 sp        m      014      NA #>  2 Afghanistan AF    AFG    1980 sp        m      1524     NA #>  3 Afghanistan AF    AFG    1980 sp        m      2534     NA #>  4 Afghanistan AF    AFG    1980 sp        m      3544     NA #>  5 Afghanistan AF    AFG    1980 sp        m      4554     NA #>  6 Afghanistan AF    AFG    1980 sp        m      5564     NA #>  7 Afghanistan AF    AFG    1980 sp        m      65       NA #>  8 Afghanistan AF    AFG    1980 sp        f      014      NA #>  9 Afghanistan AF    AFG    1980 sp        f      1524     NA #> 10 Afghanistan AF    AFG    1980 sp        f      2534     NA #> # … with 405,430 more rows # }"},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape (pivot) data from long to wide — data_to_wide","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"function \"widens\" data, increasing number columns decreasing number rows. dependency-free base-R equivalent tidyr::pivot_wider().","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"","code":"data_to_wide(   data,   id_cols = NULL,   values_from = \"Value\",   names_from = \"Name\",   names_sep = \"_\",   names_prefix = \"\",   names_glue = NULL,   values_fill = NULL,   verbose = TRUE,   ...,   colnames_from,   rows_from,   sep )  reshape_wider(   data,   id_cols = NULL,   values_from = \"Value\",   names_from = \"Name\",   names_sep = \"_\",   names_prefix = \"\",   names_glue = NULL,   values_fill = NULL,   verbose = TRUE,   ...,   colnames_from,   rows_from,   sep )"},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"data data frame pivot. id_cols name column identifies rows. NULL, use unique rows. values_from name column contains values used future variable values. names_from name column contains levels used future column names. names_sep names_from values_from contains multiple variables, used join values together single string use column name. names_prefix String added start every variable name. particularly useful names_from numeric vector want create syntactic variable names. names_glue Instead names_sep names_prefix, can supply glue specification uses names_from columns create custom column names. Note delimiters supported names_glue curly brackets, { }. values_fill Optionally, (scalar) value used replace missing values new columns created. verbose Toggle warnings. ... used now. colnames_from Deprecated. Use names_from instead. rows_from Deprecated. Use id_cols instead. sep Deprecated. Use names_sep instead.","code":""},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"tibble provided input, reshape_wider() also returns tibble. Otherwise, returns data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/data_to_wide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape (pivot) data from long to wide — data_to_wide","text":"","code":"data_long <- read.table(header = TRUE, text = \"  subject sex condition measurement        1   M   control         7.9        1   M     cond1        12.3        1   M     cond2        10.7        2   F   control         6.3        2   F     cond1        10.6        2   F     cond2        11.1        3   F   control         9.5        3   F     cond1        13.1        3   F     cond2        13.8        4   M   control        11.5        4   M     cond1        13.4        4   M     cond2        12.9\")   reshape_wider(   data_long,   id_cols = \"subject\",   names_from = \"condition\",   values_from = \"measurement\" ) #>   subject sex control cond1 cond2 #> 1       1   M     7.9  12.3  10.7 #> 2       2   F     6.3  10.6  11.1 #> 3       3   F     9.5  13.1  13.8 #> 4       4   M    11.5  13.4  12.9  reshape_wider(   data_long,   id_cols = \"subject\",   names_from = \"condition\",   values_from = \"measurement\",   names_prefix = \"Var.\",   names_sep = \".\" ) #>   subject sex Var.control Var.cond1 Var.cond2 #> 1       1   M         7.9      12.3      10.7 #> 2       2   F         6.3      10.6      11.1 #> 3       3   F         9.5      13.1      13.8 #> 4       4   M        11.5      13.4      12.9  production <- expand.grid(   product = c(\"A\", \"B\"),   country = c(\"AI\", \"EI\"),   year = 2000:2014 ) production <- data_filter(production, (product == \"A\" & country == \"AI\") | product == \"B\")  production$production <- rnorm(nrow(production))  reshape_wider(   production,   names_from = c(\"product\", \"country\"),   values_from = \"production\",   names_glue = \"prod_{product}_{country}\" ) #>    year  prod_A_AI    prod_B_AI  prod_B_EI #> 1  2000 -0.8408539  1.430252916  0.3920247 #> 2  2001 -0.4726417 -0.996105337 -0.1950098 #> 3  2002  1.3394131 -0.711765324 -0.9245581 #> 4  2003  0.8737440 -1.043327370  1.0166035 #> 5  2004 -2.2241873  1.878421273 -0.5218175 #> 6  2005 -0.6546695  0.993425211 -0.2819180 #> 7  2006 -1.0952392  1.164258300  0.2246749 #> 8  2007 -1.1649528  0.748724154 -1.3051249 #> 9  2008 -0.3766038  0.004485138  1.5616184 #> 10 2009 -0.7426178 -0.331893557  0.1463996 #> 11 2010  0.4176823  0.036978385 -1.7524488 #> 12 2011  0.1575659  0.411082845 -0.9077312 #> 13 2012  1.4151629 -0.205867410 -0.8926030 #> 14 2013  0.5674379  0.764974595 -1.9997762 #> 15 2014 -1.5185747  0.560874533 -0.8971569"},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute group-meaned and de-meaned variables — demean","title":"Compute group-meaned and de-meaned variables — demean","text":"demean() computes group- de-meaned versions variable can used regression analysis model - within-subject effect. degroup() generic terms centering-operation. demean() always uses mean-centering, degroup() can also use mode median centering.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute group-meaned and de-meaned variables — demean","text":"","code":"demean(   x,   select,   group,   suffix_demean = \"_within\",   suffix_groupmean = \"_between\",   add_attributes = TRUE,   verbose = TRUE )  degroup(   x,   select,   group,   center = \"mean\",   suffix_demean = \"_within\",   suffix_groupmean = \"_between\",   add_attributes = TRUE,   verbose = TRUE )  detrend(   x,   select,   group,   center = \"mean\",   suffix_demean = \"_within\",   suffix_groupmean = \"_between\",   add_attributes = TRUE,   verbose = TRUE )"},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute group-meaned and de-meaned variables — demean","text":"x data frame. select Character vector (formula) names variables select group- de-meaned. group Character vector (formula) name variable indicates group- cluster-ID. suffix_demean, suffix_groupmean String value, appended names group-meaned de-meaned variables x. default, de-meaned variables suffixed \"_within\" grouped-meaned variables \"_between\". add_attributes Logical, TRUE, returned variables gain attributes indicate within- -effects. relevant printing model_parameters() - cases, within- -effects printed separated blocks. verbose Toggle warnings messages. center Method centering. demean() always performs mean-centering, degroup() can use center = \"median\" center = \"mode\" median- mode-centering, also \"min\" \"max\".","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute group-meaned and de-meaned variables — demean","text":"data frame group-/de-meaned variables, get suffix \"_between\" (group-meaned variable) \"_within\" (de-meaned variable) default.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"heterogeneity-bias","dir":"Reference","previous_headings":"","what":"Heterogeneity Bias","title":"Compute group-meaned and de-meaned variables — demean","text":"Mixed models include different levels sources variability, .e. error terms level. macro-indicators (level-2 predictors, higher-level units, general: group-level predictors vary within across groups) included fixed effects (.e. treated covariate level-1), variance left unaccounted covariate absorbed error terms level-1 level-2 (Bafumi Gelman 2006; Gelman Hill 2007, Chapter 12.6.): “covariates contain two parts: one specific higher-level entity vary occasions, one represents difference occasions, within higher-level entities” (Bell et al. 2015). Hence, error terms correlated covariate, violates one assumptions mixed models (iid, independent identically distributed error terms). bias also called heterogeneity bias (Bell et al. 2015). resolve problem, level-2 predictors used (level-1) covariates separated \"within\" \"\" effects \"de-meaning\" \"group-meaning\": demeaning time-varying predictors, “higher level, mean term longer constrained Level 1 effects, free account higher-level variance associated variable” (Bell et al. 2015).","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"panel-data-and-correlating-fixed-and-group-effects","dir":"Reference","previous_headings":"","what":"Panel data and correlating fixed and group effects","title":"Compute group-meaned and de-meaned variables — demean","text":"demean() intended create group- de-meaned variables panel regression models (fixed effects models), complex random-effect-within-models (see Bell et al. 2015, 2018), group-effects (random effects) fixed effects correlate (see Bafumi Gelman 2006). can happen, instance, analyzing panel data, can lead Heterogeneity Bias. control correlating predictors group effects, recommended include group-meaned de-meaned version time-varying covariates (group-meaned version time-invariant covariates higher level, e.g. level-2 predictors) model. , one can fit complex multilevel models panel data, including time-varying predictors, time-invariant predictors random effects.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"why-mixed-models-are-preferred-over-fixed-effects-models","dir":"Reference","previous_headings":"","what":"Why mixed models are preferred over fixed effects models","title":"Compute group-meaned and de-meaned variables — demean","text":"mixed models approach can model causes endogeneity explicitly including (separated) within- -effects time-varying fixed effects including time-constant fixed effects. Furthermore, mixed models also include random effects, thus mixed models approach superior classic fixed-effects models, lack information variation group-effects -subject effects. Furthermore, fixed effects regression include random slopes, means fixed effects regressions neglecting “cross-cluster differences effects lower-level controls () reduces precision estimated context effects, resulting unnecessarily wide confidence intervals low statistical power” (Heisig et al. 2017).","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"terminology","dir":"Reference","previous_headings":"","what":"Terminology","title":"Compute group-meaned and de-meaned variables — demean","text":"group-meaned variable simply mean independent variable within group (id-level cluster) represented group. represents cluster-mean independent variable. regression coefficient group-meaned variable -subject-effect. de-meaned variable centered version group-meaned variable. De-meaning sometimes also called person-mean centering centering within clusters. regression coefficient de-meaned variable represents within-subject-effect.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-with-continuous-predictors","dir":"Reference","previous_headings":"","what":"De-meaning with continuous predictors","title":"Compute group-meaned and de-meaned variables — demean","text":"continuous time-varying predictors, recommendation include de-meaned group-meaned versions fixed effects, raw (untransformed) time-varying predictors . de-meaned predictor also included random effect (random slope). regression models, coefficient de-meaned predictors indicates within-subject effect, coefficient group-meaned predictor indicates -subject effect.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-with-binary-predictors","dir":"Reference","previous_headings":"","what":"De-meaning with binary predictors","title":"Compute group-meaned and de-meaned variables — demean","text":"binary time-varying predictors, two recommendations. First include raw (untransformed) binary predictor fixed effect de-meaned variable random effect (random slope). alternative add de-meaned version(s) binary time-varying covariates additional fixed effect well (instead adding random slope). Centering time-varying binary variables obtain within-effects (level 1) necessary. sensible interpretation left typical 0/1 format (Hoffmann 2015, chapter 8-2.). demean() thus coerce categorical time-varying predictors numeric compute de- group-meaned versions variables, raw (untransformed) binary predictor de-meaned version added model.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-of-factors-with-more-than-levels","dir":"Reference","previous_headings":"","what":"De-meaning of factors with more than 2 levels","title":"Compute group-meaned and de-meaned variables — demean","text":"Factors two levels demeaned two ways: first, also converted numeric de-meaned; second, dummy variables created (binary, 0/1 coding level) binary dummy-variables de-meaned way (described ). Packages like panelr internally convert factors dummies demeaning, behaviour can mimicked .","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"de-meaning-interaction-terms","dir":"Reference","previous_headings":"","what":"De-meaning interaction terms","title":"Compute group-meaned and de-meaned variables — demean","text":"multiple ways deal interaction terms within- -effects. classical approach simply use product term de-meaned variables (.e. introducing de-meaned variables interaction term model formula, e.g. y ~ x_within * time_within). approach, however, might subject bias (see Giesselmann & Schmidt-Catran 2020).  Another option first calculate product term apply de-meaning . approach produces estimator “reflects unit-level differences interacted variables whose moderators vary within units”, desirable within interaction two time-dependent variables required.  third option, interaction result genuine within estimator, \"double de-mean\" interaction terms (Giesselmann & Schmidt-Catran 2018), however, currently supported demean(). required, wmb() function panelr package used.  de-mean interaction terms within-models, simply specify term interaction select-argument, e.g. select = \"*b\" (see 'Examples').","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"analysing-panel-data-with-mixed-models-using-lme-","dir":"Reference","previous_headings":"","what":"Analysing panel data with mixed models using lme4","title":"Compute group-meaned and de-meaned variables — demean","text":"description translate formulas described Bell et al. 2018 R using lmer() lme4 can found vignette.","code":""},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute group-meaned and de-meaned variables — demean","text":"Bafumi J, Gelman . 2006. Fitting Multilevel Models Predictors Group Effects Correlate. . Philadelphia, PA: Annual meeting American Political Science Association. Bell , Fairbrother M, Jones K. 2019. Fixed Random Effects Models: Making Informed Choice. Quality & Quantity (53); 1051-1074 Bell , Jones K. 2015. Explaining Fixed Effects: Random Effects Modeling Time-Series Cross-Sectional Panel Data. Political Science Research Methods, 3(1), 133–153. Gelman , Hill J. 2007. Data Analysis Using Regression Multilevel/Hierarchical Models. Analytical Methods Social Research. Cambridge, New York: Cambridge University Press Giesselmann M, Schmidt-Catran, AW. 2020. Interactions fixed effects regression models. Sociological Methods & Research, 1–28. https://doi.org/10.1177/0049124120914934 Heisig JP, Schaeffer M, Giesecke J. 2017. Costs Simplicity: Multilevel Models May Benefit Accounting Cross-Cluster Differences Effects Controls. American Sociological Review 82 (4): 796–827. Hoffman L. 2015. Longitudinal analysis: modeling within-person fluctuation change. New York: Routledge","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/demean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute group-meaned and de-meaned variables — demean","text":"","code":"data(iris) iris$ID <- sample(1:4, nrow(iris), replace = TRUE) # fake-ID iris$binary <- as.factor(rbinom(150, 1, .35)) # binary variable  x <- demean(iris, select = c(\"Sepal.Length\", \"Petal.Length\"), group = \"ID\") head(x) #>   Sepal.Length_between Petal.Length_between Sepal.Length_within #> 1             5.809375             3.687500          -0.7093750 #> 2             5.692500             3.385000          -0.7925000 #> 3             5.809375             3.687500          -1.1093750 #> 4             5.692500             3.385000          -1.0925000 #> 5             5.895238             3.811905          -0.8952381 #> 6             5.980556             4.172222          -0.5805556 #>   Petal.Length_within #> 1           -2.287500 #> 2           -1.985000 #> 3           -2.387500 #> 4           -1.885000 #> 5           -2.411905 #> 6           -2.472222  x <- demean(iris, select = c(\"Sepal.Length\", \"binary\", \"Species\"), group = \"ID\") #> Categorical predictors (Species, binary) have been coerced to numeric values to compute de- and group-meaned variables. head(x) #>   Sepal.Length_between Species_between binary_between Species_setosa_between #> 1             5.809375        0.968750      0.3125000              0.3437500 #> 2             5.692500        0.875000      0.2500000              0.4250000 #> 3             5.809375        0.968750      0.3125000              0.3437500 #> 4             5.692500        0.875000      0.2500000              0.4250000 #> 5             5.895238        1.047619      0.3333333              0.3571429 #> 6             5.980556        1.111111      0.4166667              0.1944444 #>   Species_versicolor_between Species_virginica_between Sepal.Length_within #> 1                  0.3437500                 0.3125000          -0.7093750 #> 2                  0.2750000                 0.3000000          -0.7925000 #> 3                  0.3437500                 0.3125000          -1.1093750 #> 4                  0.2750000                 0.3000000          -1.0925000 #> 5                  0.2380952                 0.4047619          -0.8952381 #> 6                  0.5000000                 0.3055556          -0.5805556 #>   Species_within binary_within Species_setosa_within Species_versicolor_within #> 1      -0.968750    -0.3125000             0.6562500                -0.3437500 #> 2      -0.875000    -0.2500000             0.5750000                -0.2750000 #> 3      -0.968750    -0.3125000             0.6562500                -0.3437500 #> 4      -0.875000     0.7500000             0.5750000                -0.2750000 #> 5      -1.047619     0.6666667             0.6428571                -0.2380952 #> 6      -1.111111    -0.4166667             0.8055556                -0.5000000 #>   Species_virginica_within #> 1               -0.3125000 #> 2               -0.3000000 #> 3               -0.3125000 #> 4               -0.3000000 #> 5               -0.4047619 #> 6               -0.3055556   # demean interaction term x*y dat <- data.frame(   a = c(1, 2, 3, 4, 1, 2, 3, 4),   x = c(4, 3, 3, 4, 1, 2, 1, 2),   y = c(1, 2, 1, 2, 4, 3, 2, 1),   ID = c(1, 2, 3, 1, 2, 3, 1, 2) ) demean(dat, select = c(\"a\", \"x*y\"), group = \"ID\") #>   a_between x_y_between   a_within x_y_within #> 1  2.666667    4.666667 -1.6666667 -0.6666667 #> 2  2.333333    4.000000 -0.3333333  2.0000000 #> 3  2.500000    4.500000  0.5000000 -1.5000000 #> 4  2.666667    4.666667  1.3333333  3.3333333 #> 5  2.333333    4.000000 -1.3333333  0.0000000 #> 6  2.500000    4.500000 -0.5000000  1.5000000 #> 7  2.666667    4.666667  0.3333333 -2.6666667 #> 8  2.333333    4.000000  1.6666667 -2.0000000  # or in formula-notation demean(dat, select = ~ a + x * y, group = ~ID) #>   a_between x_y_between   a_within x_y_within #> 1  2.666667    4.666667 -1.6666667 -0.6666667 #> 2  2.333333    4.000000 -0.3333333  2.0000000 #> 3  2.500000    4.500000  0.5000000 -1.5000000 #> 4  2.666667    4.666667  1.3333333  3.3333333 #> 5  2.333333    4.000000 -1.3333333  0.0000000 #> 6  2.500000    4.500000 -0.5000000  1.5000000 #> 7  2.666667    4.666667  0.3333333 -2.6666667 #> 8  2.333333    4.000000  1.6666667 -2.0000000"},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe a distribution — describe_distribution","title":"Describe a distribution — describe_distribution","text":"function describes distribution set indices (e.g., measures centrality, dispersion, range, skewness, kurtosis).","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe a distribution — describe_distribution","text":"","code":"describe_distribution(x, ...)  # S3 method for numeric describe_distribution(   x,   centrality = \"mean\",   dispersion = TRUE,   iqr = TRUE,   range = TRUE,   quartiles = FALSE,   ci = NULL,   iterations = 100,   threshold = 0.1,   verbose = TRUE,   ... )  # S3 method for factor describe_distribution(x, dispersion = TRUE, range = TRUE, verbose = TRUE, ...)  # S3 method for data.frame describe_distribution(   x,   select = NULL,   exclude = NULL,   centrality = \"mean\",   dispersion = TRUE,   iqr = TRUE,   range = TRUE,   quartiles = FALSE,   include_factors = FALSE,   ci = NULL,   iterations = 100,   threshold = 0.1,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe a distribution — describe_distribution","text":"x numeric vector, character vector, data frame, list. See Details. ... Additional arguments passed methods. centrality point-estimates (centrality indices) compute.  Character (vector) list one options: \"median\", \"mean\", \"MAP\" \"\". dispersion Logical, TRUE, computes indices dispersion related estimate(s) (SD MAD mean median, respectively). iqr Logical, TRUE, interquartile range calculated (based stats::IQR(), using type = 6). range Return range (min max). quartiles Return first third quartiles (25th 75pth percentiles). ci Confidence Interval (CI) level. Default NULL, .e. confidence intervals computed. NULL, confidence intervals based bootstrap replicates (see iterations). centrality = \"\", bootstrapped confidence interval refers first centrality index (typically median). iterations number bootstrap replicates computing confidence intervals. applies ci NULL. threshold centrality = \"trimmed\" (.e. trimmed mean), indicates fraction (0 0.5) observations trimmed end vector mean computed. verbose Toggle warnings messages. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. include_factors Logical, TRUE, factors included output, however, columns range (first last factor levels) well n missing contain information. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe a distribution — describe_distribution","text":"data frame columns describe properties variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Describe a distribution — describe_distribution","text":"x data frame, numeric variables kept displayed summary. x list, behavior different whether x stored list. x stored (example, describe_distribution(mylist) mylist created ), artificial variable names used summary (Var_1, Var_2, etc.). x unstored list (example, describe_distribution(list(mtcars$mpg))), \"mtcars$mpg\" used variable name.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Describe a distribution — describe_distribution","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Describe a distribution — describe_distribution","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/describe_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe a distribution — describe_distribution","text":"","code":"describe_distribution(rnorm(100)) #>  Mean |   SD |  IQR |         Range | Skewness | Kurtosis |   n | n_Missing #> --------------------------------------------------------------------------- #> -0.11 | 1.06 | 1.43 | [-3.51, 2.50] |    -0.17 |     0.50 | 100 |         0  data(iris) describe_distribution(iris) #> Variable     | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |   n | n_Missing #> ---------------------------------------------------------------------------------------- #> Sepal.Length | 5.84 | 0.83 | 1.30 | [4.30, 7.90] |     0.31 |    -0.55 | 150 |         0 #> Sepal.Width  | 3.06 | 0.44 | 0.52 | [2.00, 4.40] |     0.32 |     0.23 | 150 |         0 #> Petal.Length | 3.76 | 1.77 | 3.52 | [1.00, 6.90] |    -0.27 |    -1.40 | 150 |         0 #> Petal.Width  | 1.20 | 0.76 | 1.50 | [0.10, 2.50] |    -0.10 |    -1.34 | 150 |         0 describe_distribution(iris, include_factors = TRUE, quartiles = TRUE) #> Variable     | Mean |   SD |  IQR |               Range |  Quartiles | Skewness | Kurtosis |   n | n_Missing #> ------------------------------------------------------------------------------------------------------------ #> Sepal.Length | 5.84 | 0.83 | 1.30 |          [4.3, 7.9] | 5.10, 6.40 |     0.31 |    -0.55 | 150 |         0 #> Sepal.Width  | 3.06 | 0.44 | 0.52 |            [2, 4.4] | 2.80, 3.30 |     0.32 |     0.23 | 150 |         0 #> Petal.Length | 3.76 | 1.77 | 3.52 |            [1, 6.9] | 1.60, 5.10 |    -0.27 |    -1.40 | 150 |         0 #> Petal.Width  | 1.20 | 0.76 | 1.50 |          [0.1, 2.5] | 0.30, 1.80 |    -0.10 |    -1.34 | 150 |         0 #> Species      |      |      |      | [setosa, virginica] |            |     0.00 |    -1.51 | 150 |         0 describe_distribution(list(mtcars$mpg, mtcars$cyl)) #> Variable   |  Mean |   SD |  IQR |          Range | Skewness | Kurtosis |  n | n_Missing #> ---------------------------------------------------------------------------------------- #> mtcars$mpg | 20.09 | 6.03 | 7.53 | [10.40, 33.90] |     0.67 |    -0.02 | 32 |         0 #> mtcars$cyl |  6.19 | 1.79 | 4.00 |   [4.00, 8.00] |    -0.19 |    -1.76 | 32 |         0"},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute mode for a statistical distribution — distribution_mode","title":"Compute mode for a statistical distribution — distribution_mode","text":"Compute mode statistical distribution","code":""},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute mode for a statistical distribution — distribution_mode","text":"","code":"distribution_mode(x)"},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute mode for a statistical distribution — distribution_mode","text":"x atomic vector, list, data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute mode for a statistical distribution — distribution_mode","text":"value appears frequently provided data. returned data structure entered one.","code":""},{"path":"https://easystats.github.io/datawizard/reference/distribution_mode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute mode for a statistical distribution — distribution_mode","text":"","code":"distribution_mode(c(1, 2, 3, 3, 4, 5)) #> [1] 3 distribution_mode(c(1.5, 2.3, 3.7, 3.7, 4.0, 5)) #> [1] 3.7"},{"path":"https://easystats.github.io/datawizard/reference/dot-is_deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a message saying that an argument is deprecated and that the user\nshould use its replacement instead. — .is_deprecated","title":"Print a message saying that an argument is deprecated and that the user\nshould use its replacement instead. — .is_deprecated","text":"Print message saying argument deprecated user use replacement instead.","code":""},{"path":"https://easystats.github.io/datawizard/reference/dot-is_deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a message saying that an argument is deprecated and that the user\nshould use its replacement instead. — .is_deprecated","text":"","code":".is_deprecated(arg, replacement)"},{"path":"https://easystats.github.io/datawizard/reference/dot-is_deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a message saying that an argument is deprecated and that the user\nshould use its replacement instead. — .is_deprecated","text":"arg Argument deprecated replacement Argument replaces deprecated argument","code":""},{"path":"https://easystats.github.io/datawizard/reference/efc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from the EFC Survey — efc","title":"Sample dataset from the EFC Survey — efc","text":"Selected variables EUROFAMCARE survey. Useful testing \"real-life\" data sets, including random missing values. data set also value variable label attributes.","code":""},{"path":"https://easystats.github.io/datawizard/reference/find_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Find or get columns in a data frame based on search patterns — find_columns","title":"Find or get columns in a data frame based on search patterns — find_columns","text":"find_columns() returns column names data set match certain search pattern, get_columns() returns found data. data_select() alias get_columns(), data_find() alias find_columns().","code":""},{"path":"https://easystats.github.io/datawizard/reference/find_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find or get columns in a data frame based on search patterns — find_columns","text":"","code":"find_columns(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_find(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  get_columns(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  data_select(   data,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/find_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find or get columns in a data frame based on search patterns — find_columns","text":"data data frame. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings. ... Arguments passed functions. Mostly used yet.","code":""},{"path":"https://easystats.github.io/datawizard/reference/find_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find or get columns in a data frame based on search patterns — find_columns","text":"find_columns() returns character vector column names matched pattern select exclude, NULL matching column name found. get_columns() returns data frame matching columns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/find_columns.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find or get columns in a data frame based on search patterns — find_columns","text":"Note limitations calling inside functions. following work expected, returning columns start \"Sep\":   However, example work expected!   One workaround use regex argument, provides least bit flexibility exact matching. regex basic usage (seen ) means select behaves like contains(\"\") select-helper, can also make function flexible allowing define complex regular expression pattern select.","code":"foo <- function(data) {   find_columns(data, select = starts_with(\"Sep\")) } foo(iris) foo <- function(data) {   i <- \"Sep\"   find_columns(data, select = starts_with(i)) } foo(iris) foo <- function(data) {   i <- \"Sep\"   find_columns(data, select = i, regex = TRUE) } foo(iris)"},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/find_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find or get columns in a data frame based on search patterns — find_columns","text":"","code":"# Find columns names by pattern find_columns(iris, starts_with(\"Sepal\")) #> [1] \"Sepal.Length\" \"Sepal.Width\"  find_columns(iris, ends_with(\"Width\")) #> [1] \"Sepal.Width\" \"Petal.Width\" find_columns(iris, regex(\"\\\\.\")) #> [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  find_columns(iris, c(\"Petal.Width\", \"Sepal.Length\")) #> [1] \"Petal.Width\"  \"Sepal.Length\"  # starts with \"Sepal\", but not allowed to end with \"width\" find_columns(iris, starts_with(\"Sepal\"), exclude = contains(\"Width\")) #> [1] \"Sepal.Length\"  # find numeric with mean > 3.5 numeric_mean_35 <- function(x) is.numeric(x) && mean(x, na.rm = TRUE) > 3.5 find_columns(iris, numeric_mean_35) #> [1] \"Sepal.Length\" \"Petal.Length\""},{"path":"https://easystats.github.io/datawizard/reference/nhanes_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from the National Health and Nutrition Examination Survey — nhanes_sample","title":"Sample dataset from the National Health and Nutrition Examination Survey — nhanes_sample","text":"Selected variables National Health Nutrition Examination Survey used example Lumley (2010), Appendix E.","code":""},{"path":"https://easystats.github.io/datawizard/reference/nhanes_sample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample dataset from the National Health and Nutrition Examination Survey — nhanes_sample","text":"Lumley T (2010). Complex Surveys: guide analysis using R. Wiley","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize numeric variable to 0-1 range — normalize","title":"Normalize numeric variable to 0-1 range — normalize","text":"Performs normalization data, .e., scales variables range 0 - 1. special case rescale(). unnormalize() counterpart, works variables normalized normalize().","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize numeric variable to 0-1 range — normalize","text":"","code":"normalize(x, ...)  # S3 method for numeric normalize(x, include_bounds = TRUE, verbose = TRUE, ...)  # S3 method for data.frame normalize(   x,   select = NULL,   exclude = NULL,   include_bounds = TRUE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  unnormalize(x, ...)  # S3 method for numeric unnormalize(x, verbose = TRUE, ...)  # S3 method for data.frame unnormalize(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize numeric variable to 0-1 range — normalize","text":"x numeric vector, (grouped) data frame, matrix. See 'Details'. ... Arguments passed methods. include_bounds Logical, TRUE, return value may include 0 1. FALSE, return value compressed, using Smithson Verkuilen's (2006) formula (x * (n - 1) + 0.5) / n, avoid zeros ones normalized variables. can useful case beta-regression, response variable allowed include zeros ones. verbose Toggle warnings messages . select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize numeric variable to 0-1 range — normalize","text":"normalized object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize numeric variable to 0-1 range — normalize","text":"x matrix, normalization performed across values (column- row-wise). column-wise normalization, convert matrix data.frame. x grouped data frame (grouped_df), normalization performed separately group.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Normalize numeric variable to 0-1 range — normalize","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normalize numeric variable to 0-1 range — normalize","text":"Smithson M, Verkuilen J (2006). Better Lemon Squeezer? Maximum-Likelihood Regression Beta-Distributed Dependent Variables. Psychological Methods, 11(1), 54–71.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize numeric variable to 0-1 range — normalize","text":"","code":"normalize(c(0, 1, 5, -5, -2)) #> [1] 0.5 0.6 1.0 0.0 0.3 #> attr(,\"include_bounds\") #> [1] TRUE #> attr(,\"min_value\") #> [1] -5 #> attr(,\"range_difference\") #> [1] 10 normalize(c(0, 1, 5, -5, -2), include_bounds = FALSE) #> [1] 0.50 0.58 0.90 0.10 0.34 #> attr(,\"include_bounds\") #> [1] FALSE #> attr(,\"min_value\") #> [1] -5 #> attr(,\"range_difference\") #> [1] 10  head(normalize(trees)) #>        Girth     Height      Volume #> 1 0.00000000 0.29166667 0.001497006 #> 2 0.02439024 0.08333333 0.001497006 #> 3 0.04065041 0.00000000 0.000000000 #> 4 0.17886179 0.37500000 0.092814371 #> 5 0.19512195 0.75000000 0.128742515 #> 6 0.20325203 0.83333333 0.142215569"},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":null,"dir":"Reference","previous_headings":"","what":"(Signed) rank transformation — ranktransform","title":"(Signed) rank transformation — ranktransform","text":"Transform numeric values integers rank (.e., 1st smallest, 2nd smallest, 3rd smallest, etc.). Setting sign argument TRUE give signed ranks, ranking done according absolute size sign preserved (.e., 2, 1, -3, 4).","code":""},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Signed) rank transformation — ranktransform","text":"","code":"ranktransform(x, ...)  # S3 method for numeric ranktransform(x, sign = FALSE, method = \"average\", verbose = TRUE, ...)  # S3 method for data.frame ranktransform(   x,   select = NULL,   exclude = NULL,   sign = FALSE,   method = \"average\",   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Signed) rank transformation — ranktransform","text":"x Object. ... Arguments passed methods. sign Logical, TRUE, return signed ranks. method Treatment ties. Can one \"average\" (default), \"first\", \"last\", \"random\", \"max\" \"min\". See rank() details. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Signed) rank transformation — ranktransform","text":"rank-transformed object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"(Signed) rank transformation — ranktransform","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/ranktransform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Signed) rank transformation — ranktransform","text":"","code":"ranktransform(c(0, 1, 5, -5, -2)) #> [1] 3 4 5 1 2 ranktransform(c(0, 1, 5, -5, -2), sign = TRUE) #> Warning: Zeros detected. These cannot be sign-rank transformed. #> [1]   NA  1.0  3.5 -3.5 -2.0  head(ranktransform(trees)) #>   Girth Height Volume #> 1     1    6.0    2.5 #> 2     2    3.0    2.5 #> 3     3    1.0    1.0 #> 4     4    8.5    5.0 #> 5     5   25.5    7.0 #> 6     6   28.0    9.0"},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode old values of variables into new values — recode_values","title":"Recode old values of variables into new values — recode_values","text":"functions recodes old values new values can used recode numeric character vectors, factors.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode old values of variables into new values — recode_values","text":"","code":"recode_values(x, ...)  # S3 method for numeric recode_values(   x,   recode = NULL,   default = NULL,   preserve_na = TRUE,   verbose = TRUE,   ... )  # S3 method for data.frame recode_values(   x,   select = NULL,   exclude = NULL,   recode = NULL,   default = NULL,   preserve_na = TRUE,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  change_code(x, ...)"},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode old values of variables into new values — recode_values","text":"x data frame, numeric character vector, factor. ... used. recode list named vectors, indicate recode pairs. names list-elements (.e. left-hand side) represent new values, values list-elements indicate original (old) values replaced. recoding numeric vectors, element names surrounded backticks. example, recode=list(`0`=1) recode 1 0 numeric vector. See also 'Examples' 'Details'. default Defines default value values match recode-pairs. Note , preserve_na=FALSE, missing values (NA) also captured default argument, thus also recoded specified value. See 'Examples' 'Details'. preserve_na Logical, TRUE, NA (missing values) preserved. overrides arguments, including default. Hence, preserve_na=TRUE, default longer convert NA specified default value. verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode old values of variables into new values — recode_values","text":"x, old values replaced new values.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Recode old values of variables into new values — recode_values","text":"section describes pattern recode arguments, also provides shortcuts, particular recoding numeric values. Single values Single values either need wrapped backticks (case numeric values) \"\" (character factor levels). Example: recode=list(`0`=1,`1`=2) recode 1 0, 2 1. factors character vectors, example : recode=list(x=\"\",y=\"b\") (recode \"\" \"x\" \"b\" \"y\"). Multiple values Multiple values recoded new value can separated comma. Example: recode=list(`1`=c(1,4),`2`=c(2,3)) recode values 1 4 1, 2 3 2. also possible define  old values character string, like:  recode=list(`1`=\"1,4\",`2`=\"2,3\") factors character vectors, example : recode=list(x=c(\"\",\"b\"),y=c(\"c\",\"d\")). Value range Numeric value ranges can defined using :. Example: recode=list(`1`=1:3,`2`=4:6) recode values 1 3 1, 4 6 2. min max placeholder use minimum maximum value (numeric) variable. Useful, e.g., recoding ranges values. Example: recode=list(`1`=\"min:10\",`2`=\"11:max\"). default values default argument defines default value values match recode-pairs. example, recode=list(`1`=c(1,2),`2`=c(3,4)), default=9 recode values 1 2 1, 3 4 2, values 9. preserve_na set FALSE, NA (missing values) also recoded specified default value. Reversing rescaling See reverse() rescale().","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Recode old values of variables into new values — recode_values","text":"can use options(data_recode_pattern = \"old=new\") switch behaviour recode-argument, .e. recode-pairs now following pattern old values = new values, e.g. getOption(\"data_recode_pattern\") set \"old=new\", recode(`1`=0) recode 1 0. default recode(`1`=0) recode 0 1.","code":""},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Recode old values of variables into new values — recode_values","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/recode_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode old values of variables into new values — recode_values","text":"","code":"# numeric ---------- set.seed(123) x <- sample(c(1:4, NA), 15, TRUE) table(x, useNA = \"always\") #> x #>    1    2    3    4 <NA>  #>    2    3    6    2    2   out <- recode_values(x, list(`0` = 1, `1` = 2:3, `2` = 4)) out #>  [1]  1  1  1  1  1 NA  2  0  1  1 NA  1  1  0  2 table(out, useNA = \"always\") #> out #>    0    1    2 <NA>  #>    2    9    2    2   # to recode NA values, set preserve_na to FALSE out <- recode_values(   x,   list(`0` = 1, `1` = 2:3, `2` = 4, `9` = NA),   preserve_na = FALSE ) out #>  [1] 1 1 1 1 1 9 2 0 1 1 9 1 1 0 2 table(out, useNA = \"always\") #> out #>    0    1    2    9 <NA>  #>    2    9    2    2    0   # preserve na ---------- out <- recode_values(x, list(`0` = 1, `1` = 2:3), default = 77) out #>  [1]  1  1  1  1  1 NA 77  0  1  1 NA  1  1  0 77 table(out, useNA = \"always\") #> out #>    0    1   77 <NA>  #>    2    9    2    2   # recode na into default ---------- out <- recode_values(   x,   list(`0` = 1, `1` = 2:3),   default = 77,   preserve_na = FALSE ) out #>  [1]  1  1  1  1  1 77 77  0  1  1 77  1  1  0 77 table(out, useNA = \"always\") #> out #>    0    1   77 <NA>  #>    2    9    4    0    # factors (character vectors are similar) ---------- set.seed(123) x <- as.factor(sample(c(\"a\", \"b\", \"c\"), 15, TRUE)) table(x) #> x #> a b c  #> 2 7 6   out <- recode_values(x, list(x = \"a\", y = c(\"b\", \"c\"))) out #>  [1] y y y y y y y y y x y y x y y #> Levels: x y table(out) #> out #>  x  y  #>  2 13   out <- recode_values(x, list(x = \"a\", y = \"b\", z = \"c\")) out #>  [1] z z z y z y y y z x y y x y z #> Levels: x y z table(out) #> out #> x y z  #> 2 7 6   out <- recode_values(x, list(y = \"b,c\"), default = 77) # same as # recode_values(x, list(y = c(\"b\", \"c\")), default = 77) out #>  [1] y  y  y  y  y  y  y  y  y  77 y  y  77 y  y  #> Levels: 77 y table(out) #> out #> 77  y  #>  2 13    # data frames ---------- set.seed(123) d <- data.frame(   x = sample(c(1:4, NA), 12, TRUE),   y = as.factor(sample(c(\"a\", \"b\", \"c\"), 12, TRUE)),   stringsAsFactors = FALSE )  recode_values(   d,   recode = list(`0` = 1, `1` = 2:3, `2` = 4, x = \"a\", y = c(\"b\", \"c\")),   append = TRUE ) #>     x y x_r y_r #> 1   3 c   1   y #> 2   3 a   1   x #> 3   2 a   1   x #> 4   2 a   1   x #> 5   3 a   1   x #> 6  NA c  NA   y #> 7   4 b   2   y #> 8   1 c   0   y #> 9   2 b   1   y #> 10  3 a   1   x #> 11 NA b  NA   y #> 12  3 c   1   y   # switch recode pattern to \"old=new\" ---------- options(data_recode_pattern = \"old=new\")  # numeric set.seed(123) x <- sample(c(1:4, NA), 15, TRUE) table(x, useNA = \"always\") #> x #>    1    2    3    4 <NA>  #>    2    3    6    2    2   out <- recode_values(x, list(`1` = 0, `2:3` = 1, `4` = 2)) table(out, useNA = \"always\") #> out #>    0    1    2 <NA>  #>    2    9    2    2   # factors (character vectors are similar) set.seed(123) x <- as.factor(sample(c(\"a\", \"b\", \"c\"), 15, TRUE)) table(x) #> x #> a b c  #> 2 7 6   out <- recode_values(x, list(a = \"x\", `b, c` = \"y\")) table(out) #> out #>  x  y  #>  2 13   # reset options options(data_recode_pattern = NULL)"},{"path":"https://easystats.github.io/datawizard/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. insight compact_character, compact_list, is_empty_object, object_has_names, object_has_rownames, print_html, print_md","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":null,"dir":"Reference","previous_headings":"","what":"Return or remove variables or observations that are completely missing — remove_empty","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"functions check rows columns data frame completely contain missing values, .e. observations variables completely missing values, either (1) returns indices; (2) removes data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"","code":"empty_columns(x)  empty_rows(x)  remove_empty_columns(x)  remove_empty_rows(x)  remove_empty(x)"},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"x data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"empty_columns() empty_rows(), numeric (named) vector row column indices variables completely missing values. remove_empty_columns() remove_empty_rows(), data frame \"empty\" columns rows removed, respectively. remove_empty, empty rows columns removed.","code":""},{"path":"https://easystats.github.io/datawizard/reference/remove_empty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return or remove variables or observations that are completely missing — remove_empty","text":"","code":"tmp <- data.frame(   a = c(1, 2, 3, NA, 5),   b = c(1, NA, 3, NA, 5),   c = c(NA, NA, NA, NA, NA),   d = c(1, NA, 3, NA, 5) )  tmp #>    a  b  c  d #> 1  1  1 NA  1 #> 2  2 NA NA NA #> 3  3  3 NA  3 #> 4 NA NA NA NA #> 5  5  5 NA  5  # indices of empty columns or rows empty_columns(tmp) #> c  #> 3  empty_rows(tmp) #> [1] 4  # remove empty columns or rows remove_empty_columns(tmp) #>    a  b  d #> 1  1  1  1 #> 2  2 NA NA #> 3  3  3  3 #> 4 NA NA NA #> 5  5  5  5 remove_empty_rows(tmp) #>   a  b  c  d #> 1 1  1 NA  1 #> 2 2 NA NA NA #> 3 3  3 NA  3 #> 5 5  5 NA  5  # remove empty columns and rows remove_empty(tmp) #>   a  b  d #> 1 1  1  1 #> 2 2 NA NA #> 3 3  3  3 #> 5 5  5  5"},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert infinite or NaN values into NA — replace_nan_inf","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"Replaces infinite (Inf -Inf) NaN values NA.","code":""},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"","code":"replace_nan_inf(data)"},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"data vector data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"Data Inf, -Inf, NaN converted NA.","code":""},{"path":"https://easystats.github.io/datawizard/reference/replace_nan_inf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert infinite or NaN values into NA — replace_nan_inf","text":"","code":"# a vector x <- c(1, 2, NA, 3, NaN, 4, NA, 5, Inf, -Inf, 6, 7) replace_nan_inf(x) #>  [1]  1  2 NA  3 NA  4 NA  5 NA NA  6  7  # a data frame df <- data.frame(   x = c(1, NA, 5, Inf, 2, NA),   y = c(3, NaN, 4, -Inf, 6, 7),   stringsAsFactors = FALSE ) replace_nan_inf(df) #>    x  y #> 1  1  3 #> 2 NA NA #> 3  5  4 #> 4 NA NA #> 5  2  6 #> 6 NA  7"},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale Variables to a New Range — rescale","title":"Rescale Variables to a New Range — rescale","text":"Rescale variables new range. Can also used reverse-score variables (change keying/scoring direction).","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale Variables to a New Range — rescale","text":"","code":"rescale(x, ...)  change_scale(x, ...)  # S3 method for numeric rescale(x, to = c(0, 100), range = NULL, verbose = TRUE, ...)  # S3 method for data.frame rescale(   x,   select = NULL,   exclude = NULL,   to = c(0, 100),   range = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale Variables to a New Range — rescale","text":"x (grouped) data frame, numeric vector factor. ... Arguments passed methods. Numeric vector length 2 giving new range variable rescaling. reverse-score variable, range given maximum value first. See examples. range Initial (old) range values. NULL, take range input vector (range(x)). verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale Variables to a New Range — rescale","text":"rescaled object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Rescale Variables to a New Range — rescale","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/rescale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale Variables to a New Range — rescale","text":"","code":"rescale(c(0, 1, 5, -5, -2)) #>   t.t.scale.x.....sd...mean. #> 1                  100.81051 #> 2                  104.86309 #> 3                  121.07339 #> 4                   80.54764 #> 5                   92.70537 rescale(c(0, 1, 5, -5, -2), to = c(-5, 5)) #> Error in rescale(c(0, 1, 5, -5, -2), to = c(-5, 5)): unused argument (to = c(-5, 5)) rescale(c(1, 2, 3, 4, 5), to = c(-2, 2)) #> Error in rescale(c(1, 2, 3, 4, 5), to = c(-2, 2)): unused argument (to = c(-2, 2))  # Specify the \"theoretical\" range of the input vector rescale(c(1, 3, 4), to = c(0, 40), range = c(0, 4)) #> Error in rescale(c(1, 3, 4), to = c(0, 40), range = c(0, 4)): unused arguments (to = c(0, 40), range = c(0, 4))  # Reverse-score a variable rescale(c(1, 2, 3, 4, 5), to = c(5, 1)) #> Error in rescale(c(1, 2, 3, 4, 5), to = c(5, 1)): unused argument (to = c(5, 1)) rescale(c(1, 2, 3, 4, 5), to = c(2, -2)) #> Error in rescale(c(1, 2, 3, 4, 5), to = c(2, -2)): unused argument (to = c(2, -2))  # Data frames head(rescale(iris, to = c(0, 1))) #> Error in rescale(iris, to = c(0, 1)): unused argument (to = c(0, 1)) head(rescale(iris, to = c(0, 1), select = \"Sepal.Length\")) #> Error in rescale(iris, to = c(0, 1), select = \"Sepal.Length\"): unused arguments (to = c(0, 1), select = \"Sepal.Length\")  # One can specify a list of ranges head(rescale(iris, to = list(   \"Sepal.Length\" = c(0, 1),   \"Petal.Length\" = c(-1, 0) ))) #> Error in rescale(iris, to = list(Sepal.Length = c(0, 1), Petal.Length = c(-1,     0))): unused argument (to = list(Sepal.Length = c(0, 1), Petal.Length = c(-1, 0)))"},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale design weights for multilevel analysis — rescale_weights","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"functions fit multilevel mixed effects models allow specify frequency weights, design (.e. sampling probability) weights, used analyzing complex samples survey data. rescale_weights() implements algorithm proposed Asparouhov (2006) Carle (2009) rescale design weights survey data account grouping structure multilevel models, can used multilevel modelling.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"","code":"rescale_weights(data, group, probability_weights, nest = FALSE)"},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"data data frame. group Variable names (character vector, formula), indicating grouping structure (strata) survey data (level-2-cluster variable). also possible create weights multiple group variables; cases, created weighting variable suffixed name group variable. probability_weights Variable indicating probability (design sampling) weights survey data (level-1-weight). nest Logical, TRUE group indicates least two group variables, groups \"nested\", .e. groups now combination group level variables group.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"data, including new weighting variables: pweights_a pweights_b, represent rescaled design weights use multilevel models (use variables weights argument).","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"Rescaling based two methods: pweights_a, sample weights probability_weights adjusted factor represents proportion group size divided sum sampling weights within group. adjustment factor pweights_b sum sample weights within group divided sum squared sample weights within group (see Carle (2009), Appendix B). words, pweights_a \"scales weights new weights sum cluster sample size\" pweights_b \"scales weights new weights sum effective cluster size\". Regarding choice scaling methods B, Carle suggests \"analysts wish discuss point estimates report results based weighting method . analysts interested residual -group variance, method B may generally provide least biased estimates\". general, recommended fit non-weighted model weighted models scaling methods comparing models, see whether \"inferential decisions converge\", gain confidence results. Though bias scaled weights decreases increasing group size, method preferred insufficient low group size concern. group ID probably PSU may used random effects (e.g. nested design, group PSU varying intercepts), depending survey design mimicked.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"Carle .C. (2009). Fitting multilevel models complex survey data design weights: Recommendations. BMC Medical Research Methodology 9(49): 1-13 Asparouhov T. (2006). General Multi-Level Modeling Sampling Weights. Communications Statistics - Theory Methods 35: 439-460","code":""},{"path":"https://easystats.github.io/datawizard/reference/rescale_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale design weights for multilevel analysis — rescale_weights","text":"","code":"if (require(\"lme4\")) {   data(nhanes_sample)   head(rescale_weights(nhanes_sample, \"SDMVSTRA\", \"WTINT2YR\"))    # also works with multiple group-variables   head(rescale_weights(nhanes_sample, c(\"SDMVSTRA\", \"SDMVPSU\"), \"WTINT2YR\"))    # or nested structures.   x <- rescale_weights(     data = nhanes_sample,     group = c(\"SDMVSTRA\", \"SDMVPSU\"),     probability_weights = \"WTINT2YR\",     nest = TRUE   )   head(x)    nhanes_sample <- rescale_weights(nhanes_sample, \"SDMVSTRA\", \"WTINT2YR\")    glmer(     total ~ factor(RIAGENDR) * (log(age) + factor(RIDRETH1)) + (1 | SDMVPSU),     family = poisson(),     data = nhanes_sample,     weights = pweights_a   ) } #> Loading required package: lme4 #> Loading required package: Matrix #>  #> Attaching package: ‘Matrix’ #> The following objects are masked from ‘package:tidyr’: #>  #>     expand, pack, unpack #> Generalized linear mixed model fit by maximum likelihood (Laplace #>   Approximation) [glmerMod] #>  Family: poisson  ( log ) #> Formula: total ~ factor(RIAGENDR) * (log(age) + factor(RIDRETH1)) + (1 |   #>     SDMVPSU) #>    Data: nhanes_sample #> Weights: pweights_a #>       AIC       BIC    logLik  deviance  df.resid  #>  78844.27  78920.47 -39409.14  78818.27      2582  #> Random effects: #>  Groups  Name        Std.Dev. #>  SDMVPSU (Intercept) 0.1018   #> Number of obs: 2595, groups:  SDMVPSU, 2 #> Fixed Effects: #>                         (Intercept)                    factor(RIAGENDR)2   #>                            2.491801                            -1.021308   #>                            log(age)                    factor(RIDRETH1)2   #>                            0.838726                            -0.088627   #>                   factor(RIDRETH1)3                    factor(RIDRETH1)4   #>                           -0.013333                             0.722511   #>                   factor(RIDRETH1)5           factor(RIAGENDR)2:log(age)   #>                           -0.106521                            -1.012695   #> factor(RIAGENDR)2:factor(RIDRETH1)2  factor(RIAGENDR)2:factor(RIDRETH1)3   #>                           -0.009086                             0.732985   #> factor(RIAGENDR)2:factor(RIDRETH1)4  factor(RIAGENDR)2:factor(RIDRETH1)5   #>                            0.275967                             0.542074"},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape CI between wide/long formats — reshape_ci","title":"Reshape CI between wide/long formats — reshape_ci","text":"Reshape CI wide/long formats.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape CI between wide/long formats — reshape_ci","text":"","code":"reshape_ci(x, ci_type = \"CI\")"},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape CI between wide/long formats — reshape_ci","text":"x data frame containing columns named CI_low CI_high (similar, see ci_type). ci_type String indicating \"type\" (.e. prefix) interval columns. Per easystats convention, confidence credible intervals named CI_low CI_high, related ci_type \"CI\". column names intervals differ, ci_type can used indicate name, e.g. ci_type = \"SI\" can used support intervals, column names data frame SI_low SI_high.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape CI between wide/long formats — reshape_ci","text":"data frame columns corresponding confidence intervals reshaped either wide long format.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reshape_ci.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape CI between wide/long formats — reshape_ci","text":"","code":"x <- data.frame(   Parameter = c(\"Term 1\", \"Term 2\", \"Term 1\", \"Term 2\"),   CI = c(.8, .8, .9, .9),   CI_low = c(.2, .3, .1, .15),   CI_high = c(.5, .6, .8, .85),   stringsAsFactors = FALSE )  reshape_ci(x) #>   Parameter CI_low_0.8 CI_high_0.8 CI_low_0.9 CI_high_0.9 #> 1    Term 1        0.2         0.5       0.10        0.80 #> 2    Term 2        0.3         0.6       0.15        0.85 reshape_ci(reshape_ci(x)) #>   Parameter  CI CI_low CI_high #> 1    Term 1 0.8   0.20    0.50 #> 2    Term 1 0.9   0.10    0.80 #> 3    Term 2 0.8   0.30    0.60 #> 4    Term 2 0.9   0.15    0.85"},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse-Score Variables — reverse","title":"Reverse-Score Variables — reverse","text":"Reverse-score variables (change keying/scoring direction).","code":""},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse-Score Variables — reverse","text":"","code":"reverse(x, ...)  reverse_scale(x, ...)  # S3 method for numeric reverse(x, range = NULL, verbose = TRUE, ...)  # S3 method for data.frame reverse(   x,   select = NULL,   exclude = NULL,   range = NULL,   ignore_case = FALSE,   regex = FALSE,   verbose = FALSE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse-Score Variables — reverse","text":"x (grouped) data frame, numeric vector factor. ... Arguments passed methods. range Initial (old) range values. NULL, take range input vector (range(x)). verbose Toggle warnings. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse-Score Variables — reverse","text":"reverse-scored object.","code":""},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Reverse-Score Variables — reverse","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/reverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reverse-Score Variables — reverse","text":"","code":"reverse(c(1, 2, 3, 4, 5)) #> [1] 5 4 3 2 1 reverse(c(-2, -1, 0, 2, 1)) #> [1]  2  1  0 -2 -1  # Specify the \"theoretical\" range of the input vector reverse(c(1, 3, 4), range = c(0, 4)) #> [1] 3 1 0  # Factor variables reverse(factor(c(1, 2, 3, 4, 5))) #> [1] 5 4 3 2 1 #> Levels: 1 2 3 4 5 reverse(factor(c(1, 2, 3, 4, 5)), range = 0:10) #> [1] 9 8 7 6 5 #> Levels: 0 1 2 3 4 5 6 7 8 9 10  # Data frames head(reverse(iris)) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species #> 1          7.1         2.9          6.5         2.4 virginica #> 2          7.3         3.4          6.5         2.4 virginica #> 3          7.5         3.2          6.6         2.4 virginica #> 4          7.6         3.3          6.4         2.4 virginica #> 5          7.2         2.8          6.5         2.4 virginica #> 6          6.8         2.5          6.2         2.2 virginica head(reverse(iris, select = \"Sepal.Length\")) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          7.1         3.5          1.4         0.2  setosa #> 2          7.3         3.0          1.4         0.2  setosa #> 3          7.5         3.2          1.3         0.2  setosa #> 4          7.6         3.1          1.5         0.2  setosa #> 5          7.2         3.6          1.4         0.2  setosa #> 6          6.8         3.9          1.7         0.4  setosa"},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for working with row names — rownames_as_column","title":"Tools for working with row names — rownames_as_column","text":"Tools working row names","code":""},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for working with row names — rownames_as_column","text":"","code":"rownames_as_column(x, var = \"rowname\")  column_as_rownames(x, var = \"rowname\")"},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for working with row names — rownames_as_column","text":"x data frame. var Name column use rownames. column_as_rownames(), argument can variable name column number.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for working with row names — rownames_as_column","text":"rownames_as_column() column_as_rownames() return data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/rownames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools for working with row names — rownames_as_column","text":"","code":"# Convert between row names and column -------------------------------- test <- rownames_as_column(mtcars, var = \"car\") test #>                    car  mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> 1            Mazda RX4 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> 2        Mazda RX4 Wag 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> 3           Datsun 710 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> 4       Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> 5    Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> 6              Valiant 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> 7           Duster 360 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> 8            Merc 240D 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> 9             Merc 230 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> 10            Merc 280 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> 11           Merc 280C 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> 12          Merc 450SE 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> 13          Merc 450SL 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> 14         Merc 450SLC 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> 15  Cadillac Fleetwood 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> 16 Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> 17   Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> 18            Fiat 128 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> 19         Honda Civic 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> 20      Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> 21       Toyota Corona 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> 22    Dodge Challenger 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> 23         AMC Javelin 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> 24          Camaro Z28 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> 25    Pontiac Firebird 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> 26           Fiat X1-9 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> 27       Porsche 914-2 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> 28        Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> 29      Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> 30        Ferrari Dino 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> 31       Maserati Bora 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> 32          Volvo 142E 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 head(column_as_rownames(test, var = \"car\")) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Skewness and (Excess) Kurtosis — skewness","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"Compute Skewness (Excess) Kurtosis","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"","code":"skewness(x, na.rm = TRUE, type = \"2\", iterations = NULL, verbose = TRUE, ...)  kurtosis(x, na.rm = TRUE, type = \"2\", iterations = NULL, verbose = TRUE, ...)  # S3 method for parameters_kurtosis print(x, digits = 3, test = FALSE, ...)  # S3 method for parameters_skewness print(x, digits = 3, test = FALSE, ...)  # S3 method for parameters_skewness summary(object, test = FALSE, ...)  # S3 method for parameters_kurtosis summary(object, test = FALSE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"x numeric vector data.frame. na.rm Remove missing values. type Type algorithm computing skewness. May one 1 (\"1\", \"\" \"classic\"), 2 (\"2\", \"II\" \"SPSS\" \"SAS\") 3 ( \"3\", \"III\" \"Minitab\"). See 'Details'. iterations number bootstrap replicates computing standard errors. NULL (default), parametric standard errors computed. verbose Toggle warnings messages. ... Arguments passed methods. digits Number decimal places. test Logical, TRUE, tests skewness kurtosis significantly different zero. object object returned skewness() kurtosis().","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"Values skewness kurtosis.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"skewness","dir":"Reference","previous_headings":"","what":"Skewness","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"Symmetric distributions skewness around zero, negative skewness values indicates \"left-skewed\" distribution, positive skewness values indicates \"right-skewed\" distribution. Examples relationship skewness distributions : Normal distribution (symmetric distribution) skewness 0 Half-normal distribution skewness just 1 Exponential distribution skewness 2 Lognormal distribution can skewness positive value, depending parameters (https://en.wikipedia.org/wiki/Skewness)","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"types-of-skewness","dir":"Reference","previous_headings":"","what":"Types of Skewness","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"skewness() supports three different methods estimating skewness, discussed Joanes Gill (1988): Type \"1\" \"classical\" method, g1 = (sum((x - mean(x))^3) / n) / (sum((x - mean(x))^2) / n)^1.5 Type \"2\" first calculates type-1 skewness, adjusts result: G1 = g1 * sqrt(n * (n - 1)) / (n - 2). SAS SPSS usually return Type \"3\" first calculates type-1 skewness, adjusts result: b1 = g1 * ((1 - 1 / n))^1.5. Minitab usually returns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"kurtosis","dir":"Reference","previous_headings":"","what":"Kurtosis","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"kurtosis measure \"tailedness\" distribution. distribution kurtosis values zero called \"mesokurtic\". kurtosis value larger zero indicates \"leptokurtic\" distribution fatter tails. kurtosis value zero indicates \"platykurtic\" distribution thinner tails (https://en.wikipedia.org/wiki/Kurtosis).","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"types-of-kurtosis","dir":"Reference","previous_headings":"","what":"Types of Kurtosis","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"kurtosis() supports three different methods estimating kurtosis, discussed Joanes Gill (1988): Type \"1\" \"classical\" method, g2 = n * sum((x - mean(x))^4) / (sum((x - mean(x))^2)^2) - 3. Type \"2\" first calculates type-1 kurtosis, adjusts result: G2 = ((n + 1) * g2 + 6) * (n - 1)/((n - 2) * (n - 3)). SAS SPSS usually return Type \"3\" first calculates type-1 kurtosis, adjusts result: b2 = (g2 + 3) * (1 - 1 / n)^2 - 3. Minitab usually returns.","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"standard-errors","dir":"Reference","previous_headings":"","what":"Standard Errors","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"recommended compute empirical (bootstrapped) standard errors (via iterations argument) relying analytic standard errors (Wright & Herrington, 2011).","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"D. N. Joanes C. . Gill (1998). Comparing measures sample skewness kurtosis. Statistician, 47, 183–189. Wright, D. B., & Herrington, J. . (2011). Problematic standard errors confidence intervals skewness kurtosis. Behavior research methods, 43(1), 8-17.","code":""},{"path":"https://easystats.github.io/datawizard/reference/skewness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Skewness and (Excess) Kurtosis — skewness","text":"","code":"skewness(rnorm(1000)) #> Skewness |    SE #> ---------------- #>    0.063 | 0.077 kurtosis(rnorm(1000)) #> Kurtosis |    SE #> ---------------- #>   -0.071 | 0.154"},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":null,"dir":"Reference","previous_headings":"","what":"Shift numeric value range — slide","title":"Shift numeric value range — slide","text":"functions shifts value range numeric variable, new range starts given value.","code":""},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shift numeric value range — slide","text":"","code":"slide(x, ...)  # S3 method for numeric slide(x, lowest = 0, ...)  # S3 method for data.frame slide(   x,   select = NULL,   exclude = NULL,   lowest = 0,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shift numeric value range — slide","text":"x data frame numeric vector. ... used. lowest Numeric, indicating lowest (minimum) value converting factors character vectors numeric values. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shift numeric value range — slide","text":"x, range numeric variables starts new value.","code":""},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Shift numeric value range — slide","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/slide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shift numeric value range — slide","text":"","code":"# numeric head(mtcars$gear) #> [1] 4 4 4 3 3 3 head(slide(mtcars$gear)) #> [1] 1 1 1 0 0 0 head(slide(mtcars$gear, lowest = 10)) #> [1] 11 11 11 10 10 10  # data frame sapply(slide(mtcars, lowest = 1), min) #>  mpg  cyl disp   hp drat   wt qsec   vs   am gear carb  #>    1    1    1    1    1    1    1    1    1    1    1  sapply(mtcars, min) #>    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb  #> 10.400  4.000 71.100 52.000  2.760  1.513 14.500  0.000  0.000  3.000  1.000"},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantify the smoothness of a vector — smoothness","title":"Quantify the smoothness of a vector — smoothness","text":"Quantify smoothness vector","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantify the smoothness of a vector — smoothness","text":"","code":"smoothness(x, method = \"cor\", lag = 1, iterations = NULL, ...)"},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantify the smoothness of a vector — smoothness","text":"x Numeric vector (similar time series). method Can \"diff\" (standard deviation standardized differences) \"cor\" (default, lag-one autocorrelation). lag integer indicating lag use. less 1, interpreted expressed percentage length vector. iterations number bootstrap replicates computing standard errors. NULL (default), parametric standard errors computed. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantify the smoothness of a vector — smoothness","text":"Value smoothness.","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantify the smoothness of a vector — smoothness","text":"https://stats.stackexchange.com/questions/24607/--measure-smoothness---time-series--r","code":""},{"path":"https://easystats.github.io/datawizard/reference/smoothness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantify the smoothness of a vector — smoothness","text":"","code":"x <- (-10:10)^3 + rnorm(21, 0, 100) plot(x)  smoothness(x, method = \"cor\") #> [1] 0.9291692 #> attr(,\"class\") #> [1] \"parameters_smoothness\" \"numeric\"               smoothness(x, method = \"diff\") #> [1] 1.584401 #> attr(,\"class\") #> [1] \"parameters_smoothness\" \"numeric\""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-fit a model with standardized data — standardize.default","title":"Re-fit a model with standardized data — standardize.default","text":"Performs standardization data (z-scoring) using standardize() re-fits model standardized data.  Standardization done completely refitting model standardized data. Hence, approach equal standardizing variables fitting model return new model object. method particularly recommended complex models include interactions transformations (e.g., polynomial spline terms). robust (default FALSE) argument enables robust standardization data, based median MAD instead mean SD.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Re-fit a model with standardized data — standardize.default","text":"","code":"# S3 method for default standardize(   x,   robust = FALSE,   two_sd = FALSE,   weights = TRUE,   verbose = TRUE,   include_response = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-fit a model with standardized data — standardize.default","text":"x statistical model. robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). weights TRUE (default), weighted-standardization carried . verbose Toggle warnings messages . include_response TRUE (default), response value also standardized. FALSE, predictors standardized. Note GLMs models non-linear link functions, response value standardized, make re-fitting model work. model contains stats::offset(), offset variable(s) standardized response standardized. two_sd = TRUE, offsets standardized one-sd (similar response). (mediate models, include_response refers outcome y model; m model's response always standardized possible). ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Re-fit a model with standardized data — standardize.default","text":"statistical model fitted standardized data","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"generalized-linear-models","dir":"Reference","previous_headings":"","what":"Generalized Linear Models","title":"Re-fit a model with standardized data — standardize.default","text":"Standardization generalized linear models (GLM, GLMM, etc) done respect predictors (outcome remains -, unstandardized) - maintaining interpretability coefficients (e.g., binomial model: exponent standardized parameter change 1 SD predictor, etc.)","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"dealing-with-factors","dir":"Reference","previous_headings":"","what":"Dealing with Factors","title":"Re-fit a model with standardized data — standardize.default","text":"standardize(model) standardize_parameters(model, method = \"refit\") standardize categorical predictors (.e. factors) / dummy-variables, may different behaviour compared R packages (lm.beta) software packages (like SPSS). mimic behaviours, either use standardize_parameters(model, method = \"basic\") obtain post-hoc standardized parameters, standardize data standardize(data, force = TRUE) fitting model.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"transformed-variables","dir":"Reference","previous_headings":"","what":"Transformed Variables","title":"Re-fit a model with standardized data — standardize.default","text":"model's formula contains transformations (e.g. y ~ exp(X)) transformation effectively takes place standardization (e.g., exp(scale(X))). Since transformations undefined none positive values, log() sqrt(), relevel variables shifted (post standardization) Z - min(Z) + 1 Z - min(Z) (respectively).","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/standardize.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Re-fit a model with standardized data — standardize.default","text":"","code":"model <- lm(Infant.Mortality ~ Education * Fertility, data = swiss) coef(standardize(model)) #>         (Intercept)           Education           Fertility Education:Fertility  #>          0.06386069          0.47482848          0.63270919          0.09829777"},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardization (Z-scoring) — standardize","title":"Standardization (Z-scoring) — standardize","text":"Performs standardization data (z-scoring), .e., centering scaling, data expressed terms standard deviation (.e., mean = 0, SD = 1) Median Absolute Deviance (median = 0, MAD = 1). applied statistical model, function extracts dataset, standardizes , refits model standardized version dataset. normalize() function can also used scale numeric variables within 0 - 1 range.  model standardization, see standardize.default().","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardization (Z-scoring) — standardize","text":"","code":"standardize(x, ...)  standardise(x, ...)  # S3 method for numeric standardize(   x,   robust = FALSE,   two_sd = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   scale = NULL,   verbose = TRUE,   ... )  # S3 method for factor standardize(   x,   robust = FALSE,   two_sd = FALSE,   weights = NULL,   force = FALSE,   verbose = TRUE,   ... )  # S3 method for data.frame standardize(   x,   select = NULL,   exclude = NULL,   robust = FALSE,   two_sd = FALSE,   weights = NULL,   reference = NULL,   center = NULL,   scale = NULL,   remove_na = c(\"none\", \"selected\", \"all\"),   force = FALSE,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )  unstandardize(x, ...)  unstandardise(x, ...)  # S3 method for numeric unstandardize(   x,   center = NULL,   scale = NULL,   reference = NULL,   robust = FALSE,   two_sd = FALSE,   ... )  # S3 method for data.frame unstandardize(   x,   center = NULL,   scale = NULL,   reference = NULL,   robust = FALSE,   two_sd = FALSE,   select = NULL,   exclude = NULL,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardization (Z-scoring) — standardize","text":"x (grouped) data frame, vector statistical model (unstandardize() model). ... Arguments passed methods. robust Logical, TRUE, centering done subtracting median variables dividing median absolute deviation (MAD). FALSE, variables standardized subtracting mean dividing standard deviation (SD). two_sd TRUE, variables scaled two times deviation (SD MAD depending robust). method can useful obtain model coefficients continuous parameters comparable coefficients related binary predictors, applied predictors (outcome) (Gelman, 2008). weights Can NULL (weighting), : model: TRUE (default), weighted-standardization carried . data.frames: numeric vector weights, character name column data.frame contains weights. numeric vectors: numeric vector weights. reference data frame variable centrality deviation computed instead input variable. Useful standardizing subset new data according another data frame. center, scale standardize():  Numeric values, can used alternative reference define reference centrality deviation. scale center length 1, recycled match length selected variables standardization. Else, center scale must length number selected variables. Values center scale matched selected variables provided order, unless named vector given. case, names matched names selected variables. unstandardize(): center scale correspond center (mean / median) scale (SD / MAD) original non-standardized data (data frames, named, column order correspond numeric column). However, one can also directly provide original data reference, center scale computed (according robust two_sd). Alternatively, input contains attributes center scale (output standardize()), take rest arguments absent. verbose Toggle warnings messages . force Logical, TRUE, forces recoding factors character vectors well. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. remove_na missing values (NA) treated: \"none\" (default): column's standardization done separately, ignoring NAs. Else, rows NA columns selected select / exclude (\"selected\") columns (\"\") dropped standardization, resulting data frame include cases. append Logical string. TRUE, standardized variables get new column names (suffix \"_z\") appended (column bind) x, thus returning original standardized variables. FALSE, original variables x overwritten standardized versions. character value, standardized variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardization (Z-scoring) — standardize","text":"standardized object (either standardize data frame statistical model fitted standardized data).","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Standardization (Z-scoring) — standardize","text":"x vector data frame remove_na = \"none\"), missing values preserved, return value length / number rows original input.","code":""},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Standardization (Z-scoring) — standardize","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/standardize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardization (Z-scoring) — standardize","text":"","code":"d <- iris[1:4, ]  # vectors standardise(d$Petal.Length) #> [1]  0.000000  0.000000 -1.224745  1.224745 #> attr(,\"center\") #> [1] 1.4 #> attr(,\"scale\") #> [1] 0.08164966 #> attr(,\"robust\") #> [1] FALSE  # Data frames # overwrite standardise(d, select = c(\"Sepal.Length\", \"Sepal.Width\")) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1    1.2402159   1.3887301          1.4         0.2  setosa #> 2    0.3382407  -0.9258201          1.4         0.2  setosa #> 3   -0.5637345   0.0000000          1.3         0.2  setosa #> 4   -1.0147221  -0.4629100          1.5         0.2  setosa  # append standardise(d, select = c(\"Sepal.Length\", \"Sepal.Width\"), append = TRUE) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Length_z #> 1          5.1         3.5          1.4         0.2  setosa      1.2402159 #> 2          4.9         3.0          1.4         0.2  setosa      0.3382407 #> 3          4.7         3.2          1.3         0.2  setosa     -0.5637345 #> 4          4.6         3.1          1.5         0.2  setosa     -1.0147221 #>   Sepal.Width_z #> 1     1.3887301 #> 2    -0.9258201 #> 3     0.0000000 #> 4    -0.4629100  # append, suffix standardise(d, select = c(\"Sepal.Length\", \"Sepal.Width\"), append = \"_std\") #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Length_std #> 1          5.1         3.5          1.4         0.2  setosa        1.2402159 #> 2          4.9         3.0          1.4         0.2  setosa        0.3382407 #> 3          4.7         3.2          1.3         0.2  setosa       -0.5637345 #> 4          4.6         3.1          1.5         0.2  setosa       -1.0147221 #>   Sepal.Width_std #> 1       1.3887301 #> 2      -0.9258201 #> 3       0.0000000 #> 4      -0.4629100  # standardizing with reference center and scale d <- data.frame(   a = c(-2, -1, 0, 1, 2),   b = c(3, 4, 5, 6, 7) )  # default standardization, based on mean and sd of each variable standardize(d) # means are 0 and 5, sd ~ 1.581139 #>            a          b #> 1 -1.2649111 -1.2649111 #> 2 -0.6324555 -0.6324555 #> 3  0.0000000  0.0000000 #> 4  0.6324555  0.6324555 #> 5  1.2649111  1.2649111  # standardization, based on mean and sd set to the same values standardize(d, center = c(0, 5), scale = c(1.581, 1.581)) #>            a          b #> 1 -1.2650221 -1.2650221 #> 2 -0.6325111 -0.6325111 #> 3  0.0000000  0.0000000 #> 4  0.6325111  0.6325111 #> 5  1.2650221  1.2650221  # standardization, mean and sd for each variable newly defined standardize(d, center = c(3, 4), scale = c(2, 4)) #>      a     b #> 1 -2.5 -0.25 #> 2 -2.0  0.00 #> 3 -1.5  0.25 #> 4 -1.0  0.50 #> 5 -0.5  0.75  # standardization, taking same mean and sd for each variable standardize(d, center = 1, scale = 3) #>            a         b #> 1 -1.0000000 0.6666667 #> 2 -0.6666667 1.0000000 #> 3 -0.3333333 1.3333333 #> 4  0.0000000 1.6666667 #> 5  0.3333333 2.0000000"},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenient text formatting functionalities — text_format","title":"Convenient text formatting functionalities — text_format","text":"Convenience functions manipulate format text.","code":""},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenient text formatting functionalities — text_format","text":"","code":"text_format(   text,   sep = \", \",   last = \" and \",   width = NULL,   enclose = NULL,   ... )  format_text(   text,   sep = \", \",   last = \" and \",   width = NULL,   enclose = NULL,   ... )  text_fullstop(text)  text_lastchar(text, n = 1)  text_concatenate(text, sep = \", \", last = \" and \", enclose = NULL)  text_paste(text, text2 = NULL, sep = \", \", enclose = NULL, ...)  text_remove(text, pattern = \"\", ...)  text_wrap(text, width = NULL, ...)"},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenient text formatting functionalities — text_format","text":"text, text2 character string. sep Separator. last Last separator. width Positive integer giving target column width wrapping lines output. Can \"auto\", case select 90\\ default width. enclose Character used wrap elements text, can , e.g., enclosed quotes backticks. NULL (default), text elements enclosed. ... arguments passed functions. n number characters find. pattern Character vector. data_rename(), indicates columns selected renaming. Can NULL (case columns selected). data_addprefix() data_addsuffix(), character string, added prefix suffix column names.","code":""},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenient text formatting functionalities — text_format","text":"character string.","code":""},{"path":"https://easystats.github.io/datawizard/reference/text_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenient text formatting functionalities — text_format","text":"","code":"# Add full stop if missing text_fullstop(c(\"something\", \"something else.\")) #> [1] \"something.\"      \"something else.\"  # Find last characters text_lastchar(c(\"ABC\", \"DEF\"), n = 2) #>  ABC  DEF  #> \"BC\" \"EF\"   # Smart concatenation text_concatenate(c(\"First\", \"Second\", \"Last\")) #> [1] \"First, Second and Last\" text_concatenate(c(\"First\", \"Second\", \"Last\"), last = \" or \", enclose = \"`\") #> [1] \"`First`, `Second` or `Last`\"  # Remove parts of string text_remove(c(\"one!\", \"two\", \"three!\"), \"!\") #> [1] \"one\"   \"two\"   \"three\"  # Wrap text long_text <- paste(rep(\"abc \", 100), collapse = \"\") cat(text_wrap(long_text, width = 50)) #>  abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc abc abc abc abc abc abc abc abc #> abc abc abc abc  # Paste with optional separator text_paste(c(\"A\", \"\", \"B\"), c(\"42\", \"42\", \"42\")) #> [1] \"A, 42\" \"42\"    \"B, 42\""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data to factors — to_factor","title":"Convert data to factors — to_factor","text":"Convert data factors","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data to factors — to_factor","text":"","code":"to_factor(x, ...)  # S3 method for data.frame to_factor(   x,   select = NULL,   exclude = NULL,   ignore_case = FALSE,   append = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data to factors — to_factor","text":"x data frame vector. ... Arguments passed methods. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data to factors — to_factor","text":"factor, data frame factors.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert data to factors — to_factor","text":"Convert data numeric converting characters factors factors either numeric levels dummy variables. \"counterpart\" convert variables numeric to_numeric().","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"selection-of-variables-the-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - the select argument","title":"Convert data to factors — to_factor","text":"functions select argument (including function), complete input data frame returned, even select selects range variables. , function applied variables match select, variables remain unchanged. words: function, select omit non-included variables, returned data frame include variables input data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_factor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data to factors — to_factor","text":"","code":"str(to_factor(iris)) #> 'data.frame':\t150 obs. of  5 variables: #>  $ Sepal.Length: Factor w/ 35 levels \"4.3\",\"4.4\",\"4.5\",..: 9 7 5 4 8 12 4 8 2 7 ... #>  $ Sepal.Width : Factor w/ 23 levels \"2\",\"2.2\",\"2.3\",..: 15 10 12 11 16 19 14 14 9 11 ... #>  $ Petal.Length: Factor w/ 43 levels \"1\",\"1.1\",\"1.2\",..: 5 5 4 6 5 8 5 6 5 6 ... #>  $ Petal.Width : Factor w/ 22 levels \"0.1\",\"0.2\",\"0.3\",..: 2 2 2 2 2 4 3 2 2 1 ... #>  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...  # use labels as levels data(efc) str(efc$c172code) #>  num [1:100] 2 2 1 2 2 2 2 2 NA 2 ... #>  - attr(*, \"label\")= chr \"carer's level of education\" #>  - attr(*, \"labels\")= Named num [1:3] 1 2 3 #>   ..- attr(*, \"names\")= chr [1:3] \"low level of education\" \"intermediate level of education\" \"high level of education\" head(to_factor(efc$c172code)) #> [1] intermediate level of education intermediate level of education #> [3] low level of education          intermediate level of education #> [5] intermediate level of education intermediate level of education #> 3 Levels: low level of education ... high level of education"},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data to numeric — to_numeric","title":"Convert data to numeric — to_numeric","text":"Convert data numeric converting characters factors factors either numeric levels dummy variables. \"counterpart\" convert variables factors to_factor().","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data to numeric — to_numeric","text":"","code":"to_numeric(x, ...)  # S3 method for data.frame to_numeric(   x,   select = NULL,   exclude = NULL,   dummy_factors = TRUE,   preserve_levels = FALSE,   lowest = NULL,   append = FALSE,   ignore_case = FALSE,   regex = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data to numeric — to_numeric","text":"x data frame, factor vector. ... Arguments passed methods. select Variables included performing required tasks. Can either variable specified literal variable name (e.g., column_name), string variable name (e.g., \"column_name\"), character vector variable names (e.g., c(\"col1\", \"col2\", \"col3\")), formula variable names (e.g., ~column_1 + column_2), vector positive integers, giving positions counting left (e.g. 1 c(1, 3, 5)), vector negative integers, giving positions counting right (e.g., -1 -1:-3), one following select-helpers: starts_with(\"\"), ends_with(\"\"), contains(\"\"), range using : regex(\"\"), function testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3), ranges specified via literal variable names, select-helpers (except regex()) (user-defined) functions can negated, .e. return non-matching elements, prefixed -, e.g. -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Note: Negation means matches excluded, thus, exclude argument can used alternatively. instance, select=-ends_with(\"Length\") (-) equivalent exclude=ends_with(\"Length\") (-). case negation work expected, use exclude argument instead. NULL, selects columns. Patterns found matches silently ignored, e.g. find_columns(iris, select = c(\"Species\", \"Test\")) just return \"Species\". exclude See select, however, column names matched pattern exclude excluded instead selected. NULL (default), excludes columns. dummy_factors Transform factors dummy factors (factor levels different columns filled binary 0-1 value). preserve_levels Logical, applies x factor. TRUE, x numeric factor levels, converted related numeric values. possible, converted numeric values start 1 number levels. lowest Numeric, indicating lowest (minimum) value converting factors character vectors numeric values. append Logical string. TRUE, recoded converted variables get new column names appended (column bind) x, thus returning original recoded variables. new columns get suffix, based calling function: \"_r\" recode functions, \"_n\" to_numeric(), \"_f\" to_factor(), \"_s\" slide(). append=FALSE, original variables x overwritten recoded versions. character value, recoded variables appended new column names (using defined suffix) original data frame. ignore_case Logical, TRUE one select-helpers regular expression used select, ignores lower/upper case search pattern matching variable names. regex Logical, TRUE, search pattern select treated regular expression. regex = TRUE, select must character string (variable containing character string) allowed one supported select-helpers character vector length > 1. regex = TRUE comparable using one two select-helpers, select = contains(\"\") select = regex(\"\"), however, since select-helpers may work called inside functions (see 'Details'), argument may used workaround. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data to numeric — to_numeric","text":"data frame numeric variables.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"selection-of-variables-select-argument","dir":"Reference","previous_headings":"","what":"Selection of variables - select argument","title":"Convert data to numeric — to_numeric","text":"functions select argument complete input data frame returned, even select selects range variables. However, to_numeric(), factors might converted dummies, thus, number variables returned data frame longer match input data frame. Hence, select used, variables (dummies) specified select returned. Use append=TRUE also include original variables returned data frame.","code":""},{"path":"https://easystats.github.io/datawizard/reference/to_numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data to numeric — to_numeric","text":"","code":"to_numeric(head(ToothGrowth)) #>    len supp.OJ supp.VC dose #> 1  4.2       0       1  0.5 #> 2 11.5       0       1  0.5 #> 3  7.3       0       1  0.5 #> 4  5.8       0       1  0.5 #> 5  6.4       0       1  0.5 #> 6 10.0       0       1  0.5 to_numeric(head(ToothGrowth), dummy_factors = FALSE) #>    len supp dose #> 1  4.2    2  0.5 #> 2 11.5    2  0.5 #> 3  7.3    2  0.5 #> 4  5.8    2  0.5 #> 5  6.4    2  0.5 #> 6 10.0    2  0.5  # factors x <- as.factor(mtcars$gear) to_numeric(x, dummy_factors = FALSE) #>  [1] 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 3 3 3 3 3 2 to_numeric(x, dummy_factors = FALSE, preserve_levels = TRUE) #>  [1] 4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 5 5 4"},{"path":"https://easystats.github.io/datawizard/reference/visualisation_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare objects for visualisation — visualisation_recipe","title":"Prepare objects for visualisation — visualisation_recipe","text":"function prepares objects visualisation returning list layers data geoms can easily plotted using instance ggplot2. see package installed, call visualization_recipe() can replaced plot(), internally call former plot using ggplot. resulting plot can customized ad-hoc (adding ggplot's geoms, theme specifications), via arguments visualisation_recipe() control aesthetic parameters. See specific documentation page object's class: modelbased: https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html correlation: https://easystats.github.io/correlation/reference/visualisation_recipe.easycormatrix.html","code":""},{"path":"https://easystats.github.io/datawizard/reference/visualisation_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare objects for visualisation — visualisation_recipe","text":"","code":"visualisation_recipe(x, ...)"},{"path":"https://easystats.github.io/datawizard/reference/visualisation_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare objects for visualisation — visualisation_recipe","text":"x easystats object. ... arguments passed functions.","code":""},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted Mean, Median, SD, and MAD — weighted_mean","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"Weighted Mean, Median, SD, MAD","code":""},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"","code":"weighted_mean(x, weights = NULL, verbose = TRUE, ...)  weighted_median(x, weights = NULL, verbose = TRUE, ...)  weighted_sd(x, weights = NULL, verbose = TRUE, ...)  weighted_mad(x, weights = NULL, constant = 1.4826, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"x object containing values whose weighted mean     computed. weights numerical vector weights length x giving weights use elements x. verbose Show warning weights negative? weights = NULL, x passed non-weighted function. ... arguments passed methods. constant scale factor.","code":""},{"path":"https://easystats.github.io/datawizard/reference/weighted_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted Mean, Median, SD, and MAD — weighted_mean","text":"","code":"## GPA from Siegel 1994 x <- c(3.7, 3.3, 3.5, 2.8) wt <- c(5, 5, 4, 1) / 15  weighted_mean(x, wt) #> [1] 3.453333 weighted_median(x, wt) #> [1] 3.5  weighted_sd(x, wt) #> [1] 0.2852935 weighted_mad(x, wt) #> [1] 0.29652"},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Winsorize data — winsorize","title":"Winsorize data — winsorize","text":"Winsorize data","code":""},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Winsorize data — winsorize","text":"","code":"winsorize(data, ...)  # S3 method for numeric winsorize(   data,   threshold = 0.2,   method = \"percentile\",   robust = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Winsorize data — winsorize","text":"data data frame vector. ... Currently used. threshold amount winsorization, depends value method: method = \"percentile\": amount winsorize tail. method = \"zscore\": number SD/MAD-deviations mean/median (see robust) method = \"raw\": vector length 2 lower upper bound winsorization. method One \"percentile\" (default), \"zscore\", \"raw\". robust Logical, TRUE, winsorizing \"zscore\" method done via median median absolute deviation (MAD); FALSE, via mean standard deviation. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Winsorize data — winsorize","text":"data frame winsorized columns winsorized vector.","code":""},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Winsorize data — winsorize","text":"Winsorizing winsorization transformation statistics limiting extreme values statistical data reduce effect possibly spurious outliers. distribution many statistics can heavily influenced outliers. typical strategy set outliers (values beyond certain threshold) specified percentile data; example, 90\\ 5th percentile, data 95th percentile set 95th percentile. Winsorized estimators usually robust outliers standard forms.","code":""},{"path":[]},{"path":"https://easystats.github.io/datawizard/reference/winsorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Winsorize data — winsorize","text":"","code":"hist(iris$Sepal.Length, main = \"Original data\")   hist(winsorize(iris$Sepal.Length, threshold = 0.2),   xlim = c(4, 8), main = \"Percentile Winsorization\" )   hist(winsorize(iris$Sepal.Length, threshold = 1.5, method = \"zscore\"),   xlim = c(4, 8), main = \"Mean (+/- SD) Winsorization\" )   hist(winsorize(iris$Sepal.Length, threshold = 1.5, method = \"zscore\", robust = TRUE),   xlim = c(4, 8), main = \"Median (+/- MAD) Winsorization\" )   hist(winsorize(iris$Sepal.Length, threshold = c(5, 7.5), method = \"raw\"),   xlim = c(4, 8), main = \"Raw Thresholds\" )   # Also works on a data frame: winsorize(iris, threshold = 0.2) #>     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species #> 1            5.1         3.4          1.5         0.2     setosa #> 2            5.0         3.0          1.5         0.2     setosa #> 3            5.0         3.2          1.5         0.2     setosa #> 4            5.0         3.1          1.5         0.2     setosa #> 5            5.0         3.4          1.5         0.2     setosa #> 6            5.4         3.4          1.7         0.4     setosa #> 7            5.0         3.4          1.5         0.3     setosa #> 8            5.0         3.4          1.5         0.2     setosa #> 9            5.0         2.9          1.5         0.2     setosa #> 10           5.0         3.1          1.5         0.2     setosa #> 11           5.4         3.4          1.5         0.2     setosa #> 12           5.0         3.4          1.6         0.2     setosa #> 13           5.0         3.0          1.5         0.2     setosa #> 14           5.0         3.0          1.5         0.2     setosa #> 15           5.8         3.4          1.5         0.2     setosa #> 16           5.7         3.4          1.5         0.4     setosa #> 17           5.4         3.4          1.5         0.4     setosa #> 18           5.1         3.4          1.5         0.3     setosa #> 19           5.7         3.4          1.7         0.3     setosa #> 20           5.1         3.4          1.5         0.3     setosa #> 21           5.4         3.4          1.7         0.2     setosa #> 22           5.1         3.4          1.5         0.4     setosa #> 23           5.0         3.4          1.5         0.2     setosa #> 24           5.1         3.3          1.7         0.5     setosa #> 25           5.0         3.4          1.9         0.2     setosa #> 26           5.0         3.0          1.6         0.2     setosa #> 27           5.0         3.4          1.6         0.4     setosa #> 28           5.2         3.4          1.5         0.2     setosa #> 29           5.2         3.4          1.5         0.2     setosa #> 30           5.0         3.2          1.6         0.2     setosa #> 31           5.0         3.1          1.6         0.2     setosa #> 32           5.4         3.4          1.5         0.4     setosa #> 33           5.2         3.4          1.5         0.2     setosa #> 34           5.5         3.4          1.5         0.2     setosa #> 35           5.0         3.1          1.5         0.2     setosa #> 36           5.0         3.2          1.5         0.2     setosa #> 37           5.5         3.4          1.5         0.2     setosa #> 38           5.0         3.4          1.5         0.2     setosa #> 39           5.0         3.0          1.5         0.2     setosa #> 40           5.1         3.4          1.5         0.2     setosa #> 41           5.0         3.4          1.5         0.3     setosa #> 42           5.0         2.7          1.5         0.3     setosa #> 43           5.0         3.2          1.5         0.2     setosa #> 44           5.0         3.4          1.6         0.6     setosa #> 45           5.1         3.4          1.9         0.4     setosa #> 46           5.0         3.0          1.5         0.3     setosa #> 47           5.1         3.4          1.6         0.2     setosa #> 48           5.0         3.2          1.5         0.2     setosa #> 49           5.3         3.4          1.5         0.2     setosa #> 50           5.0         3.3          1.5         0.2     setosa #> 51           6.5         3.2          4.7         1.4 versicolor #> 52           6.4         3.2          4.5         1.5 versicolor #> 53           6.5         3.1          4.9         1.5 versicolor #> 54           5.5         2.7          4.0         1.3 versicolor #> 55           6.5         2.8          4.6         1.5 versicolor #> 56           5.7         2.8          4.5         1.3 versicolor #> 57           6.3         3.3          4.7         1.6 versicolor #> 58           5.0         2.7          3.3         1.0 versicolor #> 59           6.5         2.9          4.6         1.3 versicolor #> 60           5.2         2.7          3.9         1.4 versicolor #> 61           5.0         2.7          3.5         1.0 versicolor #> 62           5.9         3.0          4.2         1.5 versicolor #> 63           6.0         2.7          4.0         1.0 versicolor #> 64           6.1         2.9          4.7         1.4 versicolor #> 65           5.6         2.9          3.6         1.3 versicolor #> 66           6.5         3.1          4.4         1.4 versicolor #> 67           5.6         3.0          4.5         1.5 versicolor #> 68           5.8         2.7          4.1         1.0 versicolor #> 69           6.2         2.7          4.5         1.5 versicolor #> 70           5.6         2.7          3.9         1.1 versicolor #> 71           5.9         3.2          4.8         1.8 versicolor #> 72           6.1         2.8          4.0         1.3 versicolor #> 73           6.3         2.7          4.9         1.5 versicolor #> 74           6.1         2.8          4.7         1.2 versicolor #> 75           6.4         2.9          4.3         1.3 versicolor #> 76           6.5         3.0          4.4         1.4 versicolor #> 77           6.5         2.8          4.8         1.4 versicolor #> 78           6.5         3.0          5.0         1.7 versicolor #> 79           6.0         2.9          4.5         1.5 versicolor #> 80           5.7         2.7          3.5         1.0 versicolor #> 81           5.5         2.7          3.8         1.1 versicolor #> 82           5.5         2.7          3.7         1.0 versicolor #> 83           5.8         2.7          3.9         1.2 versicolor #> 84           6.0         2.7          5.1         1.6 versicolor #> 85           5.4         3.0          4.5         1.5 versicolor #> 86           6.0         3.4          4.5         1.6 versicolor #> 87           6.5         3.1          4.7         1.5 versicolor #> 88           6.3         2.7          4.4         1.3 versicolor #> 89           5.6         3.0          4.1         1.3 versicolor #> 90           5.5         2.7          4.0         1.3 versicolor #> 91           5.5         2.7          4.4         1.2 versicolor #> 92           6.1         3.0          4.6         1.4 versicolor #> 93           5.8         2.7          4.0         1.2 versicolor #> 94           5.0         2.7          3.3         1.0 versicolor #> 95           5.6         2.7          4.2         1.3 versicolor #> 96           5.7         3.0          4.2         1.2 versicolor #> 97           5.7         2.9          4.2         1.3 versicolor #> 98           6.2         2.9          4.3         1.3 versicolor #> 99           5.1         2.7          3.0         1.1 versicolor #> 100          5.7         2.8          4.1         1.3 versicolor #> 101          6.3         3.3          5.3         1.9  virginica #> 102          5.8         2.7          5.1         1.9  virginica #> 103          6.5         3.0          5.3         1.9  virginica #> 104          6.3         2.9          5.3         1.8  virginica #> 105          6.5         3.0          5.3         1.9  virginica #> 106          6.5         3.0          5.3         1.9  virginica #> 107          5.0         2.7          4.5         1.7  virginica #> 108          6.5         2.9          5.3         1.8  virginica #> 109          6.5         2.7          5.3         1.8  virginica #> 110          6.5         3.4          5.3         1.9  virginica #> 111          6.5         3.2          5.1         1.9  virginica #> 112          6.4         2.7          5.3         1.9  virginica #> 113          6.5         3.0          5.3         1.9  virginica #> 114          5.7         2.7          5.0         1.9  virginica #> 115          5.8         2.8          5.1         1.9  virginica #> 116          6.4         3.2          5.3         1.9  virginica #> 117          6.5         3.0          5.3         1.8  virginica #> 118          6.5         3.4          5.3         1.9  virginica #> 119          6.5         2.7          5.3         1.9  virginica #> 120          6.0         2.7          5.0         1.5  virginica #> 121          6.5         3.2          5.3         1.9  virginica #> 122          5.6         2.8          4.9         1.9  virginica #> 123          6.5         2.8          5.3         1.9  virginica #> 124          6.3         2.7          4.9         1.8  virginica #> 125          6.5         3.3          5.3         1.9  virginica #> 126          6.5         3.2          5.3         1.8  virginica #> 127          6.2         2.8          4.8         1.8  virginica #> 128          6.1         3.0          4.9         1.8  virginica #> 129          6.4         2.8          5.3         1.9  virginica #> 130          6.5         3.0          5.3         1.6  virginica #> 131          6.5         2.8          5.3         1.9  virginica #> 132          6.5         3.4          5.3         1.9  virginica #> 133          6.4         2.8          5.3         1.9  virginica #> 134          6.3         2.8          5.1         1.5  virginica #> 135          6.1         2.7          5.3         1.4  virginica #> 136          6.5         3.0          5.3         1.9  virginica #> 137          6.3         3.4          5.3         1.9  virginica #> 138          6.4         3.1          5.3         1.8  virginica #> 139          6.0         3.0          4.8         1.8  virginica #> 140          6.5         3.1          5.3         1.9  virginica #> 141          6.5         3.1          5.3         1.9  virginica #> 142          6.5         3.1          5.1         1.9  virginica #> 143          5.8         2.7          5.1         1.9  virginica #> 144          6.5         3.2          5.3         1.9  virginica #> 145          6.5         3.3          5.3         1.9  virginica #> 146          6.5         3.0          5.2         1.9  virginica #> 147          6.3         2.7          5.0         1.9  virginica #> 148          6.5         3.0          5.2         1.9  virginica #> 149          6.2         3.4          5.3         1.9  virginica #> 150          5.9         3.0          5.1         1.8  virginica"},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-060","dir":"Changelog","previous_headings":"","what":"datawizard 0.6.0","title":"datawizard 0.6.0","text":"BREAKING CHANGES Following deprecated functions removed: data_cut(), data_recode(), data_shift(), data_reverse(), data_rescale(), data_to_factor(), data_to_numeric() New text_format() alias introduced format_text(), latter removed next release. New recode_values() alias introduced change_code(), latter removed next release. NEW FUNCTIONS data_peek(), peek values type variables data frame. CHANGES data_filter() give informative messages malformed syntax filter argument. now possible use curly brackets pass variable names data_filter(), like following example. See examples section documentation data_filter(). regex argument added functions use select-helpers already argument.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-051","dir":"Changelog","previous_headings":"","what":"datawizard 0.5.1","title":"datawizard 0.5.1","text":"CRAN release: 2022-08-17 Fixes failing tests due poorman update.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-050","dir":"Changelog","previous_headings":"","what":"datawizard 0.5.0","title":"datawizard 0.5.0","text":"CRAN release: 2022-08-07 MAJOR CHANGES Following statistical transformation functions renamed data_*() prefix, since work exclusively data frames, typically first used vectors, therefore misleading names: data_cut() -> categorize() data_recode() -> change_code() data_shift() -> slide() data_reverse() -> reverse() data_rescale() -> rescale() data_to_factor() -> to_factor() data_to_numeric() -> to_numeric() Note functions also .data.frame() methods still work data frames well. Former function names still available aliases, deprecated removed future release. Bumps needed minimum R version 3.5. Removed deprecated function data_findcols(). Please use replacement, data_find(). Removed alias extract() data_extract() function since collided tidyr::extract(). Argument training_proportion data_partition() deprecated. Please use proportion now. Given continued significant contributions package, Etienne Bacher (@etiennebacher) now included author. unstandardise() now works center(x) unnormalize() now works change_scale(x) reshape_wider() now follows consistently tidyr::pivot_wider() syntax. Arguments colnames_from, sep, rows_from deprecated replaced names_from, names_sep, id_cols respectively. reshape_wider() also gains argument names_glue (#182, #198). Similarly, reshape_longer() now follows consistently tidyr::pivot_longer() syntax. Argument colnames_to deprecated replaced names_to. reshape_longer() also gains new arguments: names_prefix, names_sep, names_pattern, values_drop_na (#189). CHANGES text formatting helpers (like text_concatenate()) gain enclose argument, wrap text elements surrounding characters. winsorize now accepts “raw” “zscore” methods (addition “percentile”). Additionally, robust set TRUE together method = \"zscore\", winsorizes via median median absolute deviation (MAD); else via mean standard deviation. (@rempsyc, #177, #49, #47). convert_na_to now accepts numeric replacements character vectors single replacement multiple vector classes. (@rempsyc, #214). data_partition() now allows create multiple partitions data, returning multiple training remaining test set. Functions like center(), normalize() standardize() longer fail data contains infinite values (Inf). NEW FUNCTIONS row_to_colnames() colnames_to_row() move row column names, column names row (@etiennebacher, #169). data_arrange() sort rows dataframe according values selected columns. BUG FIXES Fixed wrong column names data_to_wide() (#173).","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-041","dir":"Changelog","previous_headings":"","what":"datawizard 0.4.1","title":"datawizard 0.4.1","text":"CRAN release: 2022-05-16 BREAKING Added standardize.default() method (moved package effectsize), consistent default-method now package generic. standardize.default() behaves exactly like effectsize particularly works regression model objects. effectsize now re-exports standardize() datawizard. NEW FUNCTIONS data_shift() shift value range numeric variables. data_recode() recode old new values. data_to_factor() counterpart data_to_numeric(). data_tabulate() create frequency tables variables. data_read() read (import) data files (text, foreign statistical packages). unnormalize() counterpart normalize(). function works variables normalized normalize(). data_group() data_ungroup() create grouped data frames, remove grouping information grouped data frames. CHANGES data_find() added alias find_colums(), consistent name patterns datawizard functions. data_findcols() removed future update usage discouraged. select argument (thus, also exclude argument) now also accepts functions testing logical conditions, e.g. .numeric() (.numeric), user-defined function selects variables function returns TRUE (like: foo <- function(x) mean(x) > 3). Arguments select exclude now allow negation select-helpers, like -ends_with(\"\"), -.numeric -Sepal.Width:Petal.Length. Many functions now get .default method, capture unsupported classes. now yields message returns original input, hence, .data.frame methods won’t stop due error. filter argument data_filter() can also numeric vector, indicate row indices rows returned. convert_to_na() gets methods variables class logical Date. convert_to_na() factors (data frames) gains drop_levels argument, drop unused levels replaced NA. data_to_numeric() gains two arguments, preserve_levels lowest, give better control conversion factors. BUG FIXES logicals passed center() standardize() force = TRUE, properly converted numeric variables.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-040","dir":"Changelog","previous_headings":"","what":"datawizard 0.4.0","title":"datawizard 0.4.0","text":"CRAN release: 2022-03-30 MAJOR CHANGES data_match() now returns filtered data default. Old behavior (returning rows indices) can set setting return_indices = TRUE. following functions now re-exported insight package: object_has_names(), object_has_rownames(), is_empty_object(), compact_list(), compact_character() data_findcols() become deprecated future updates. Please use new replacements find_columns() get_columns(). vignette Analysing Longitudinal Panel Data now moved parameters package. NEW FUNCTIONS convert rownames column, vice versa: rownames_as_column() column_as_rownames() (@etiennebacher, #80). find_columns() get_columns() find column names retrieve subsets data frames, based various select-methods (including select-helpers). function supersede data_findcols() future. data_filter() complement data_match(), works logical expressions filtering rows data frames. computing weighted centrality measures dispersion: weighted_mean(), weighted_median(), weighted_sd() weighted_mad(). replace NA vectors dataframes: convert_na_to() (@etiennebacher, #111). MINOR CHANGES select argument several functions (like data_remove(), reshape_longer(), data_extract()) now allows use select-helpers selecting variables based specific patterns. data_extract() gains new arguments allow type-safe return values, .e. always return vector data frame. Thus, data_extract() can now used select multiple variables pull single variable data frames. data_match() gains match argument, indicate logical operation matching results combined. Improved support labelled data many functions, .e. returned data frame preserve value variable label attributes, possible applicable. describe_distribution() now works lists (@etiennebacher, #105). data_rename() doesn’t use pattern anymore rename columns replacement provided (@etiennebacher, #103). data_rename() now adds suffix duplicated names replacement (@etiennebacher, #103). BUG FIXES data_to_numeric() produced wrong results factors dummy_factors =   TRUE factor contained missing values. data_match() produced wrong results data contained missing values. Fixed CRAN check issues data_extract() one variable extracted data frame.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-030","dir":"Changelog","previous_headings":"","what":"datawizard 0.3.0","title":"datawizard 0.3.0","text":"CRAN release: 2022-03-02 NEW FUNCTIONS find remove empty rows columns data frame: empty_rows(), empty_columns(), remove_empty_rows(), remove_empty_columns(), remove_empty. check names: object_has_names() object_has_rownames(). rotate data frames: data_rotate(). reverse score variables: data_reverse(). merge/join multiple data frames: data_merge() (alias data_join()). cut (recode) data groups: data_cut(). replace specific values NAs: convert_to_na(). replace Inf NaN values NAs: replace_nan_inf(). Arguments cols, data_relocate() can now also numeric values, indicating position destination column.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-023","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.3","title":"datawizard 0.2.3","text":"CRAN release: 2022-01-26 New functions: work lists: is_empty_object() compact_list() work strings: compact_character()","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-022","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.2","title":"datawizard 0.2.2","text":"CRAN release: 2022-01-04 New function data_extract() (alias extract()) pull single variables data frame, possibly naming value row names data frame. reshape_ci() gains ci_type argument, reshape data frames CI-columns prefixes \"CI\". standardize() center() gain arguments center scale, define references centrality deviation used centering standardizing variables. center() gains arguments force reference, similar standardize(). functionality append argument center() standardize() revised. made suffix argument redundant, thus removed. Fixed issue standardize(). Fixed issue data_findcols().","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-021","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.1","title":"datawizard 0.2.1","text":"CRAN release: 2021-10-04 Exports plot method visualisation_recipe() objects see package. centre(), standardise(), unstandardise() exported aliases center(), standardize(), unstandardize(), respectively.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-0201","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.0.1","title":"datawizard 0.2.0.1","text":"CRAN release: 2021-09-02 mainly maintenance release addresses issues conflicting namespaces.","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-020","dir":"Changelog","previous_headings":"","what":"datawizard 0.2.0","title":"datawizard 0.2.0","text":"CRAN release: 2021-08-17 New function: visualisation_recipe(). following function now moved performance package: check_multimodal(). Minor updates documentation, including new vignette demean().","code":""},{"path":"https://easystats.github.io/datawizard/news/index.html","id":"datawizard-010","dir":"Changelog","previous_headings":"","what":"datawizard 0.1.0","title":"datawizard 0.1.0","text":"CRAN release: 2021-06-18 First release.","code":""}]
