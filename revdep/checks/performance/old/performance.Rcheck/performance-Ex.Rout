
R version 4.2.2 (2022-10-31 ucrt) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "performance"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> options(pager = "console")
> library('performance')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("binned_residuals")
> ### * binned_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: binned_residuals
> ### Title: Binned residuals for binomial logistic regression
> ### Aliases: binned_residuals
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> result <- binned_residuals(model)
> result
[31mWarning: Probably bad model fit. Only about 50% of the residuals are inside the error bounds.
[39m> 
> # look at the data frame
> as.data.frame(result)
        xbar        ybar n       x.lo       x.hi         se   ci_range
1 0.03786483 -0.03786483 5 0.01744776 0.06917366 0.01899089 0.00968941
2 0.09514191 -0.09514191 5 0.07087498 0.15160143 0.02816391 0.01436960
3 0.25910531  0.07422802 6 0.17159955 0.35374001 0.42499664 0.21683901
4 0.47954643 -0.07954643 5 0.38363314 0.54063600 0.49728294 0.25372045
5 0.71108931  0.28891069 5 0.57299903 0.89141359 0.10975381 0.05599787
6 0.97119262 -0.13785929 6 0.91147360 0.99815623 0.30361062 0.15490623
       CI_low     CI_high group
1 -0.05685572 -0.01887394    no
2 -0.12330581 -0.06697800    no
3 -0.35076862  0.49922466   yes
4 -0.57682937  0.41773650   yes
5  0.17915688  0.39866451    no
6 -0.44146992  0.16575133   yes
> 
> # plot
> if (require("see")) {
+   plot(result)
+ }
Loading required package: see
Warning: Computation failed in `stat_smooth()`
Caused by error in `smooth.construct.tp.smooth.spec()`:
! A term has fewer unique covariate combinations than specified maximum degrees of freedom
> 
> 
> 
> cleanEx()

detaching 'package:see'

> nameEx("check_autocorrelation")
> ### * check_autocorrelation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_autocorrelation
> ### Title: Check model for independence of residuals.
> ### Aliases: check_autocorrelation check_autocorrelation.default
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_autocorrelation(m)
[32mOK: Residuals appear to be independent and not autocorrelated (p = 0.324).[39m> 
> 
> 
> cleanEx()
> nameEx("check_clusterstructure")
> ### * check_clusterstructure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_clusterstructure
> ### Title: Check suitability of data for clustering
> ### Aliases: check_clusterstructure
> 
> ### ** Examples
> 
> 
> 
> 
> cleanEx()
> nameEx("check_collinearity")
> ### * check_collinearity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_collinearity
> ### Title: Check for multicollinearity of model terms
> ### Aliases: check_collinearity multicollinearity
> ###   check_collinearity.default check_collinearity.glmmTMB
> ###   check_concurvity
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_collinearity(m)
[34m# Check for Multicollinearity
[39m
[32mLow Correlation

[39m Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI
  cyl 5.41 [3.42,  9.04]         2.33      0.18     [0.11, 0.29]

[33mModerate Correlation

[39m Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI
 gear 1.53  [1.19, 2.51]         1.24      0.65     [0.40, 0.84]
   wt 5.05 [3.21,  8.41]         2.25      0.20     [0.12, 0.31]
 disp 9.97 [6.08, 16.85]         3.16      0.10     [0.06, 0.16]
> 
> # plot results
> if (require("see")) {
+   x <- check_collinearity(m)
+   plot(x)
+ }
Loading required package: see
Variable `Component` is not in your data frame :/
> 
> 
> 
> cleanEx()

detaching 'package:see'

> nameEx("check_convergence")
> ### * check_convergence
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_convergence
> ### Title: Convergence test for mixed effects models
> ### Aliases: check_convergence
> 
> ### ** Examples
> 
> if (require("lme4")) {
+   data(cbpp)
+   set.seed(1)
+   cbpp$x <- rnorm(nrow(cbpp))
+   cbpp$x2 <- runif(nrow(cbpp))
+ 
+   model <- glmer(
+     cbind(incidence, size - incidence) ~ period + x + x2 + (1 + x | herd),
+     data = cbpp,
+     family = binomial()
+   )
+ 
+   check_convergence(model)
+ }
Loading required package: lme4
Loading required package: Matrix
[1] TRUE
attr(,"gradient")
[1] 0.0002803075
> 
> ## Not run: 
> ##D if (require("glmmTMB")) {
> ##D   model <- glmmTMB(
> ##D     Sepal.Length ~ poly(Petal.Width, 4) * poly(Petal.Length, 4) +
> ##D       (1 + poly(Petal.Width, 4) | Species),
> ##D     data = iris
> ##D   )
> ##D   check_convergence(model)
> ##D }
> ## End(Not run)
> 
> 
> 
> cleanEx()

detaching 'package:lme4', 'package:Matrix'

> nameEx("check_distribution")
> ### * check_distribution
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_distribution
> ### Title: Classify the distribution of a model-family using machine
> ###   learning
> ### Aliases: check_distribution
> 
> ### ** Examples
> 
> if (require("lme4") && require("parameters") &&
+   require("see") && require("patchwork") && require("randomForest")) {
+   data(sleepstudy)
+ 
+   model <<- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
+   check_distribution(model)
+   plot(check_distribution(model))
+ }
Loading required package: lme4
Loading required package: Matrix
Loading required package: parameters
Loading required package: see
Loading required package: patchwork
Loading required package: randomForest
randomForest 4.7-1.1
Type rfNews() to see new features/changes/bug fixes.
Warning: Removed 6 rows containing missing values (`geom_segment()`).
Warning: Removed 6 rows containing missing values (`geom_point()`).
> 
> 
> 
> cleanEx()

detaching 'package:randomForest', 'package:patchwork', 'package:see',
  'package:parameters', 'package:lme4', 'package:Matrix'

> nameEx("check_factorstructure")
> ### * check_factorstructure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_factorstructure
> ### Title: Check suitability of data for Factor Analysis (FA)
> ### Aliases: check_factorstructure
> 
> ### ** Examples
> 
> library(performance)
> check_factorstructure(mtcars)
[34m# Is the data suitable for Factor Analysis?

[39m[32m  - KMO: The Kaiser, Meyer, Olkin (KMO) measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83).
  - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001).[39m> 
> 
> 
> cleanEx()
> nameEx("check_heterogeneity_bias")
> ### * check_heterogeneity_bias
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_heterogeneity_bias
> ### Title: Check model predictor for heterogeneity bias
> ### Aliases: check_heterogeneity_bias
> 
> ### ** Examples
> 
> data(iris)
> iris$ID <- sample(1:4, nrow(iris), replace = TRUE) # fake-ID
> check_heterogeneity_bias(iris, select = c("Sepal.Length", "Petal.Length"), group = "ID")
Possible heterogeneity bias due to following predictors: [31mSepal.Length, Petal.Length[39m
> 
> 
> 
> cleanEx()
> nameEx("check_heteroscedasticity")
> ### * check_heteroscedasticity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_heteroscedasticity
> ### Title: Check model for (non-)constant error variance
> ### Aliases: check_heteroscedasticity check_heteroskedasticity
> 
> ### ** Examples
> 
> m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_heteroscedasticity(m)
[31mWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.042).
[39m> 
> # plot results
> if (require("see")) {
+   x <- check_heteroscedasticity(m)
+   plot(x)
+ }
Loading required package: see
> 
> 
> 
> cleanEx()

detaching 'package:see'

> nameEx("check_homogeneity")
> ### * check_homogeneity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_homogeneity
> ### Title: Check model for homogeneity of variances
> ### Aliases: check_homogeneity check_homogeneity.afex_aov
> 
> ### ** Examples
> 
> model <<- lm(len ~ supp + dose, data = ToothGrowth)
> check_homogeneity(model)
[32mOK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.226).
[39m> 
> # plot results
> if (require("see")) {
+   result <- check_homogeneity(model)
+   plot(result)
+ }
Loading required package: see
> 
> 
> 
> cleanEx()

detaching 'package:see'

> nameEx("check_itemscale")
> ### * check_itemscale
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_itemscale
> ### Title: Describe Properties of Item Scales
> ### Aliases: check_itemscale
> 
> ### ** Examples
> 
> # data generation from '?prcomp', slightly modified
> C <- chol(S <- toeplitz(0.9^(0:15)))
> set.seed(17)
> X <- matrix(rnorm(1600), 100, 16)
> Z <- X %*% C
> if (require("parameters") && require("psych")) {
+   pca <- principal_components(as.data.frame(Z), rotation = "varimax", n = 3)
+   pca
+   check_itemscale(pca)
+ }
Loading required package: parameters
Loading required package: psych
[34m# Description of (Sub-)Scales[39m[31m
Component 1[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V1   |        0 | -0.02 | 1.06 |    -0.49 |      -0.01 |           0.80 |             0.96
V2   |        0 | -0.05 | 1.05 |    -0.29 |      -0.02 |           0.90 |             0.95
V3   |        0 |  0.00 | 1.10 |    -0.77 |       0.00 |           0.94 |             0.95
V4   |        0 |  0.00 | 1.10 |    -0.82 |       0.00 |           0.92 |             0.95
V5   |        0 | -0.07 | 1.09 |    -0.29 |      -0.02 |           0.90 |             0.95
V6   |        0 | -0.04 | 1.13 |    -0.27 |      -0.01 |           0.83 |             0.96
[33m
Mean inter-item-correlation = 0.813  Cronbach's alpha = 0.963[39m
[31m
Component 2[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V7   |        0 | -0.01 | 1.07 |     0.01 |       0.00 |           0.87 |             0.97
V8   |        0 |  0.02 | 0.96 |     0.23 |       0.01 |           0.89 |             0.96
V9   |        0 |  0.04 | 0.98 |     0.37 |       0.01 |           0.93 |             0.96
V10  |        0 |  0.08 | 1.00 |     0.18 |       0.02 |           0.93 |             0.96
V11  |        0 |  0.02 | 1.03 |     0.18 |       0.01 |           0.92 |             0.96
V12  |        0 |  0.00 | 1.04 |     0.27 |       0.00 |           0.84 |             0.97
[33m
Mean inter-item-correlation = 0.840  Cronbach's alpha = 0.969[39m
[31m
Component 3[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V13  |        0 |  0.04 | 0.95 |     0.10 |       0.01 |           0.81 |             0.95
V14  |        0 | -0.02 | 0.96 |     0.24 |      -0.01 |           0.93 |             0.91
V15  |        0 | -0.03 | 0.94 |     0.41 |      -0.01 |           0.92 |             0.91
V16  |        0 |  0.03 | 0.96 |     0.28 |       0.01 |           0.82 |             0.94
[33m
Mean inter-item-correlation = 0.811  Cronbach's alpha = 0.945[39m> 
> 
> 
> cleanEx()

detaching 'package:psych', 'package:parameters'

> nameEx("check_kmo")
> ### * check_kmo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_kmo
> ### Title: Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA)
> ###   for Factor Analysis
> ### Aliases: check_kmo
> 
> ### ** Examples
> 
> library(performance)
> check_kmo(mtcars)
[34m# KMO Measure of Sampling Adequacy

[39m[32mThe Kaiser, Meyer, Olkin (KMO) measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83).[39m> 
> 
> 
> cleanEx()
> nameEx("check_model")
> ### * check_model
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_model
> ### Title: Visual check of model assumptions
> ### Aliases: check_model check_model.default
> 
> ### ** Examples
> 
> ## Not run: 
> ##D m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> ##D check_model(m)
> ##D 
> ##D if (require("lme4")) {
> ##D   m <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
> ##D   check_model(m, panel = FALSE)
> ##D }
> ##D 
> ##D if (require("rstanarm")) {
> ##D   m <- stan_glm(mpg ~ wt + gear, data = mtcars, chains = 2, iter = 200)
> ##D   check_model(m)
> ##D }
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("check_multimodal")
> ### * check_multimodal
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_multimodal
> ### Title: Check if a distribution is unimodal or multimodal
> ### Aliases: check_multimodal
> 
> ### ** Examples
> 
> ## Not run: 
> ##D if (require("multimode")) {
> ##D   # Univariate
> ##D   x <- rnorm(1000)
> ##D   check_multimodal(x)
> ##D }
> ##D 
> ##D if (require("multimode") && require("mclust")) {
> ##D   x <- c(rnorm(1000), rnorm(1000, 2))
> ##D   check_multimodal(x)
> ##D 
> ##D   # Multivariate
> ##D   m <- data.frame(
> ##D     x = rnorm(200),
> ##D     y = rbeta(200, 2, 1)
> ##D   )
> ##D   plot(m$x, m$y)
> ##D   check_multimodal(m)
> ##D 
> ##D   m <- data.frame(
> ##D     x = c(rnorm(100), rnorm(100, 4)),
> ##D     y = c(rbeta(100, 2, 1), rbeta(100, 1, 4))
> ##D   )
> ##D   plot(m$x, m$y)
> ##D   check_multimodal(m)
> ##D }
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("check_normality")
> ### * check_normality
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_normality
> ### Title: Check model for (non-)normality of residuals.
> ### Aliases: check_normality check_normality.merMod
> 
> ### ** Examples
> 
> m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_normality(m)
[32mOK: residuals appear as normally distributed (p = 0.230).
[39m> 
> # plot results
> if (require("see")) {
+   x <- check_normality(m)
+   plot(x)
+ }
Loading required package: see
> ## Not run: 
> ##D # QQ-plot
> ##D plot(check_normality(m), type = "qq")
> ##D 
> ##D # PP-plot
> ##D plot(check_normality(m), type = "pp")
> ## End(Not run)
> 
> 
> 
> cleanEx()

detaching 'package:see'

> nameEx("check_outliers")
> ### * check_outliers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_outliers
> ### Title: Outliers detection (check for influential observations)
> ### Aliases: check_outliers check_outliers.default check_outliers.numeric
> ###   check_outliers.data.frame
> 
> ### ** Examples
> 
> data <- mtcars # Size nrow(data) = 32
> 
> # For single variables ------------------------------------------------------
> outliers_list <- check_outliers(data$mpg) # Find outliers
> outliers_list # Show the row index of the outliers
[32mOK: No outliers detected.
- Based on the following method and threshold: zscore_robust (3.09).
- For variable: data$mpg

[39m> as.numeric(outliers_list) # The object is a binary vector...
 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> filtered_data <- data[!outliers_list, ] # And can be used to filter a dataframe
> nrow(filtered_data) # New size, 28 (4 outliers removed)
[1] 32
> 
> # Find all observations beyond +/- 2 SD
> check_outliers(data$mpg, method = "zscore", threshold = 2)
[33m2 outliers detected: cases 18, 20.
- Based on the following method and threshold: zscore (2).
- For variable: data$mpg.
[39m
-----------------------------------------------------------------------------
Outliers per variable (zscore): 

$`data$mpg`
   Row Distance_Zscore
18  18        2.042389
20  20        2.291272

> 
> # For dataframes ------------------------------------------------------
> check_outliers(data) # It works the same way on dataframes
[32mOK: No outliers detected.
- Based on the following method and threshold: mahalanobis (31.26).
- For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb

[39m> 
> # You can also use multiple methods at once
> outliers_list <- check_outliers(data, method = c(
+   "mahalanobis",
+   "iqr",
+   "zscore"
+ ))
> outliers_list
[33m1 outlier detected: case 31.
- Based on the following methods and thresholds: mahalanobis (3.09), iqr
  (1.7), zscore (31.26).
- For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb.[39m[33m
Note: Outliers were classified as such by[39m [33mat least half of the selected methods. 
[39m
-----------------------------------------------------------------------------
The following observations were considered outliers for two or more variables 
by at least one of the selected methods: 

  Row n_Zscore n_IQR
1  31        1     2
> 
> # Using `as.data.frame()`, we can access more details!
> outliers_info <- as.data.frame(outliers_list)
> head(outliers_info)
  Row Distance_Zscore Outlier_Zscore Distance_IQR Outlier_IQR
1   1        1.189901              0    0.4208483           0
2   2        1.189901              0    0.2941176           0
3   3        1.224858              0    0.5882353           0
4   4        1.122152              0    0.5882353           0
5   5        1.043081              0    0.3915954           0
6   6        1.564608              0    0.6809025           0
  Distance_Mahalanobis Outlier_Mahalanobis Outlier
1             8.946673                   0       0
2             8.287933                   0       0
3             8.937150                   0       0
4             6.096726                   0       0
5             5.429061                   0       0
6             8.877558                   0       0
> outliers_info$Outlier # Including the probability of being an outlier
 [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
 [8] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[15] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[22] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[29] 0.0000000 0.0000000 0.6666667 0.0000000
> 
> # And we can be more stringent in our outliers removal process
> filtered_data <- data[outliers_info$Outlier < 0.1, ]
> 
> # We can run the function stratified by groups using `{dplyr}` package:
> if (require("poorman")) {
+   iris %>%
+     group_by(Species) %>%
+     check_outliers()
+ }
Loading required package: poorman

  I'd seen my father. He was a poor man, and I watched him do astonishing things.
    - Sidney Poitier

Attaching package: 'poorman'

The following objects are masked from 'package:stats':

    filter, lag

[32mOK: No outliers detected.
- Based on the following method and threshold: mahalanobis (18.47).
- For variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width

[39m> ## Not run: 
> ##D # You can also run all the methods
> ##D check_outliers(data, method = "all")
> ##D 
> ##D # For statistical models ---------------------------------------------
> ##D # select only mpg and disp (continuous)
> ##D mt1 <- mtcars[, c(1, 3, 4)]
> ##D # create some fake outliers and attach outliers to main df
> ##D mt2 <- rbind(mt1, data.frame(
> ##D   mpg = c(37, 40), disp = c(300, 400),
> ##D   hp = c(110, 120)
> ##D ))
> ##D # fit model with outliers
> ##D model <- lm(disp ~ mpg + hp, data = mt2)
> ##D 
> ##D outliers_list <- check_outliers(model)
> ##D 
> ##D if (require("see")) {
> ##D   plot(outliers_list)
> ##D }
> ##D 
> ##D insight::get_data(model)[outliers_list, ] # Show outliers data
> ## End(Not run)
> 
> 
> 
> cleanEx()

detaching 'package:poorman'

> nameEx("check_overdispersion")
> ### * check_overdispersion
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_overdispersion
> ### Title: Check overdispersion of GL(M)M's
> ### Aliases: check_overdispersion
> 
> ### ** Examples
> 
> ## Don't show: 
> if (getRversion() >= "4.0.0" && require("glmmTMB", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ 
+ library(glmmTMB)
+ data(Salamanders)
+ m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
+ check_overdispersion(m)
+ 
+ m <- glmmTMB(
+   count ~ mined + spp + (1 | site),
+   family = poisson,
+   data = Salamanders
+ )
+ check_overdispersion(m)
+ ## Don't show: 
+ }) # examplesIf
> library(glmmTMB)
> data(Salamanders)
> m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
> check_overdispersion(m)
[34m# Overdispersion test

[39m       dispersion ratio =    2.946
  Pearson's Chi-Squared = 1873.710
                p-value =  < 0.001

Overdispersion detected.
> m <- glmmTMB(count ~ mined + spp + (1 | site), family = poisson, data = Salamanders)
> check_overdispersion(m)
[34m# Overdispersion test

[39m       dispersion ratio =    2.324
  Pearson's Chi-Squared = 1475.875
                p-value =  < 0.001

Overdispersion detected.
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching 'package:glmmTMB'

> nameEx("check_predictions")
> ### * check_predictions
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_predictions
> ### Title: Posterior predictive checks
> ### Aliases: check_predictions posterior_predictive_check
> ###   check_posterior_predictions
> 
> ### ** Examples
> 
> library(performance)
> model <- lm(mpg ~ disp, data = mtcars)
> if (require("see")) {
+   check_predictions(model)
+ }
Loading required package: see
> 
> 
> 
> cleanEx()

detaching 'package:see'

> nameEx("check_singularity")
> ### * check_singularity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_singularity
> ### Title: Check mixed models for boundary fits
> ### Aliases: check_singularity
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ library(lme4)
+ data(sleepstudy)
+ set.seed(123)
+ sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE)
+ sleepstudy$mysubgrp <- NA
+ for (i in 1:5) {
+   filter_group <- sleepstudy$mygrp == i
+   sleepstudy$mysubgrp[filter_group] <-
+     sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
+ 
+ model <- lmer(
+   Reaction ~ Days + (1 | mygrp / mysubgrp) + (1 | Subject),
+   data = sleepstudy
+ )
+ 
+ check_singularity(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> library(lme4)
> data(sleepstudy)
> set.seed(123)
> sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE)
> sleepstudy$mysubgrp <- NA
> for (i in 1:5) {
+     filter_group <- sleepstudy$mygrp == i
+     sleepstudy$mysubgrp[filter_group] <- sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
> model <- lmer(Reaction ~ Days + (1 | mygrp/mysubgrp) + (1 | Subject), 
+     data = sleepstudy)
boundary (singular) fit: see help('isSingular')
> check_singularity(model)
[1] TRUE
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching 'package:lme4', 'package:Matrix'

> nameEx("check_sphericity")
> ### * check_sphericity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_sphericity
> ### Title: Check model for violation of sphericity
> ### Aliases: check_sphericity
> 
> ### ** Examples
> 
> if (require("car")) {
+   soils.mod <- lm(
+     cbind(pH, N, Dens, P, Ca, Mg, K, Na, Conduc) ~ Block + Contour * Depth,
+     data = Soils
+   )
+ 
+   check_sphericity(Manova(soils.mod))
+ }
Loading required package: car
Loading required package: carData
[32mOK: Data seems to be spherical (p > .999).
[39m> 
> 
> 
> cleanEx()

detaching 'package:car', 'package:carData'

> nameEx("check_sphericity_bartlett")
> ### * check_sphericity_bartlett
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_sphericity_bartlett
> ### Title: Bartlett's Test of Sphericity
> ### Aliases: check_sphericity_bartlett
> 
> ### ** Examples
> 
> library(performance)
> check_sphericity_bartlett(mtcars)
[34m# Test of Sphericity

[39m[32mBartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001).[39m> 
> 
> 
> cleanEx()
> nameEx("check_symmetry")
> ### * check_symmetry
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_symmetry
> ### Title: Check distribution symmetry
> ### Aliases: check_symmetry
> 
> ### ** Examples
> 
> V <- wilcox.test(mtcars$mpg)
Warning in wilcox.test.default(mtcars$mpg) :
  cannot compute exact p-value with ties
> check_symmetry(V)
[32mOK: Data appears symmetrical (p = 0.119).
[39m> 
> 
> 
> 
> cleanEx()
> nameEx("check_zeroinflation")
> ### * check_zeroinflation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_zeroinflation
> ### Title: Check for zero-inflation in count models
> ### Aliases: check_zeroinflation
> 
> ### ** Examples
> 
> if (require("glmmTMB")) {
+   data(Salamanders)
+   m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
+   check_zeroinflation(m)
+ }
Loading required package: glmmTMB
[34m# Check for zero-inflation

[39m   Observed zeros: 387
  Predicted zeros: 298
            Ratio: 0.77

Model is underfitting zeros (probable zero-inflation).
> 
> 
> 
> cleanEx()

detaching 'package:glmmTMB'

> nameEx("compare_performance")
> ### * compare_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: compare_performance
> ### Title: Compare performance of different models
> ### Aliases: compare_performance
> 
> ### ** Examples
> 
> data(iris)
> lm1 <- lm(Sepal.Length ~ Species, data = iris)
> lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
> lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris)
> compare_performance(lm1, lm2, lm3)
[34m# Comparison of Model Performance Indices[39m

Name | Model | AIC (weights) | AICc (weights) | BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma
-------------------------------------------------------------------------------------------------
lm1  |    lm | 231.5 (<.001) |  231.7 (<.001) | 243.5 (<.001) | 0.619 |     0.614 | 0.510 | 0.515
lm2  |    lm | 106.2 (0.566) |  106.6 (0.611) | 121.3 (0.964) | 0.837 |     0.833 | 0.333 | 0.338
lm3  |    lm | 106.8 (0.434) |  107.6 (0.389) | 127.8 (0.036) | 0.840 |     0.835 | 0.330 | 0.336
> compare_performance(lm1, lm2, lm3, rank = TRUE)
[34m# Comparison of Model Performance Indices[39m

Name | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights | BIC weights | Performance-Score
---------------------------------------------------------------------------------------------------------------
lm2  |    lm | 0.837 |     0.833 | 0.333 | 0.338 |       0.566 |        0.611 |       0.964 |            99.23%
lm3  |    lm | 0.840 |     0.835 | 0.330 | 0.336 |       0.434 |        0.389 |       0.036 |            77.70%
lm1  |    lm | 0.619 |     0.614 | 0.510 | 0.515 |    3.65e-28 |     4.23e-28 |    2.80e-27 |             0.00%
> 
> if (require("lme4")) {
+   m1 <- lm(mpg ~ wt + cyl, data = mtcars)
+   m2 <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
+   m3 <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
+   compare_performance(m1, m2, m3)
+ }
Loading required package: lme4
Loading required package: Matrix
Warning: When comparing models, please note that probably not all models were fit
  from same data.
[34m# Comparison of Model Performance Indices[39m

Name |   Model | AIC (weights) | AICc (weights) | BIC (weights) |  RMSE | Sigma |    R2 | R2 (adj.) | Tjur's R2 | Log_loss | Score_log | Score_spherical |   PCP | R2 (cond.) | R2 (marg.) |   ICC
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m1   |      lm | 156.0 (<.001) |  157.5 (<.001) | 161.9 (<.001) | 2.444 | 2.568 | 0.830 |     0.819 |           |          |           |                 |       |            |            |      
m2   |     glm |  31.3 (>.999) |   32.2 (>.999) |  35.7 (>.999) | 0.359 | 0.934 |       |           |     0.478 |    0.395 |   -14.903 |           0.095 | 0.743 |            |            |      
m3   | lmerMod |  74.6 (<.001) |   74.9 (<.001) |  86.7 (<.001) | 0.279 | 0.283 |       |           |           |          |           |                 |       |      0.972 |      0.096 | 0.969
> 
> 
> 
> cleanEx()

detaching 'package:lme4', 'package:Matrix'

> nameEx("cronbachs_alpha")
> ### * cronbachs_alpha
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cronbachs_alpha
> ### Title: Cronbach's Alpha for Items or Scales
> ### Aliases: cronbachs_alpha
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> cronbachs_alpha(x)
[1] 0.09463206
> 
> 
> 
> cleanEx()
> nameEx("display.performance_model")
> ### * display.performance_model
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: display.performance_model
> ### Title: Print tables in different output formats
> ### Aliases: display.performance_model print_md.performance_model
> ###   print_md.compare_performance
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> mp <- model_performance(model)
> display(mp)
[1] "|AIC    |   AICc |    BIC |   R2 | R2 (adj.) | RMSE | Sigma |"
[2] "|:------|:------:|:------:|:----:|:---------:|:----:|:-----:|"
[3] "|156.01 | 157.49 | 161.87 | 0.83 |      0.82 | 2.44 |  2.57 |"
attr(,"format")
[1] "pipe"
attr(,"class")
[1] "knitr_kable" "character"  
> 
> 
> 
> cleanEx()
> nameEx("icc")
> ### * icc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: icc
> ### Title: Intraclass Correlation Coefficient (ICC)
> ### Aliases: icc variance_decomposition
> 
> ### ** Examples
> 
> if (require("lme4")) {
+   model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+   icc(model)
+ }
Loading required package: lme4
Loading required package: Matrix
[34m# Intraclass Correlation Coefficient

[39m    Adjusted ICC: 0.910
  Unadjusted ICC: 0.311
> 
> # ICC for specific group-levels
> if (require("lme4")) {
+   data(sleepstudy)
+   set.seed(12345)
+   sleepstudy$grp <- sample(1:5, size = 180, replace = TRUE)
+   sleepstudy$subgrp <- NA
+   for (i in 1:5) {
+     filter_group <- sleepstudy$grp == i
+     sleepstudy$subgrp[filter_group] <-
+       sample(1:30, size = sum(filter_group), replace = TRUE)
+   }
+   model <- lmer(
+     Reaction ~ Days + (1 | grp / subgrp) + (1 | Subject),
+     data = sleepstudy
+   )
+   icc(model, by_group = TRUE)
+ }
[34m# ICC by Group

[39mGroup      |   ICC
------------------
subgrp:grp | 0.017
Subject    | 0.589
grp        | 0.001
> 
> 
> 
> cleanEx()

detaching 'package:lme4', 'package:Matrix'

> nameEx("item_difficulty")
> ### * item_difficulty
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_difficulty
> ### Title: Difficulty of Questionnaire Items
> ### Aliases: item_difficulty
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_difficulty(x)
[34m# Item Difficulty

[39m[31m      difficulty  ideal
[39m   cyl      0.02   0.50
  gear      0.01   0.50
  carb      0.01   0.50
    hp      0.44   0.50
> 
> 
> 
> cleanEx()
> nameEx("item_intercor")
> ### * item_intercor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_intercor
> ### Title: Mean Inter-Item-Correlation
> ### Aliases: item_intercor
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_intercor(x)
[1] 0.294155
> 
> 
> 
> cleanEx()
> nameEx("item_reliability")
> ### * item_reliability
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_reliability
> ### Title: Reliability Test for Items or Scales
> ### Aliases: item_reliability
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_reliability(x)
  term alpha_if_deleted item_discrimination
1  cyl            0.048               0.826
2 gear            0.110              -0.127
3 carb            0.058               0.751
4   hp            0.411               0.881
> 
> 
> 
> cleanEx()
> nameEx("item_split_half")
> ### * item_split_half
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_split_half
> ### Title: Split-Half Reliability
> ### Aliases: item_split_half
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_split_half(x)
$splithalf
[1] 0.9070215

$spearmanbrown
[1] 0.9512441

> 
> 
> 
> cleanEx()
> nameEx("looic")
> ### * looic
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: looic
> ### Title: LOO-related Indices for Bayesian regressions.
> ### Aliases: looic
> 
> ### ** Examples
> 
> if (require("rstanarm")) {
+   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)
+   looic(model)
+ }
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.21.3
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Warning: The largest R-hat is 1.05, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
[34m# LOOIC and ELPD with Standard Error

[39m  LOOIC: 156.06 [9.54]
   ELPD: -78.03 [4.77]
> 
> 
> 
> cleanEx()

detaching 'package:rstanarm', 'package:Rcpp'

> nameEx("model_performance")
> ### * model_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance
> ### Title: Model Performance
> ### Aliases: model_performance performance
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> model_performance(model)
[34m# Indices of model performance[39m

AIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------------
156.010 | 157.492 | 161.873 | 0.830 |     0.819 | 2.444 | 2.568
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> model_performance(model)
[34m# Indices of model performance[39m

AIC    |   AICc |    BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP
-----------------------------------------------------------------------------------------------------
31.298 | 32.155 | 35.695 |     0.478 | 0.359 | 0.934 |    0.395 |   -14.903 |           0.095 | 0.743
> 
> 
> 
> cleanEx()
> nameEx("model_performance.kmeans")
> ### * model_performance.kmeans
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.kmeans
> ### Title: Model summary for k-means clustering
> ### Aliases: model_performance.kmeans
> 
> ### ** Examples
> 
> # a 2-dimensional example
> x <- rbind(
+   matrix(rnorm(100, sd = 0.3), ncol = 2),
+   matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2)
+ )
> colnames(x) <- c("x", "y")
> model <- kmeans(x, 2)
> model_performance(model)
[34m# Indices of model performance[39m

Sum_Squares_Total | Sum_Squares_Within | Sum_Squares_Between | Iterations
-------------------------------------------------------------------------
60.991            |             14.918 |              46.073 |      1.000
> 
> 
> 
> cleanEx()
> nameEx("model_performance.lavaan")
> ### * model_performance.lavaan
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.lavaan
> ### Title: Performance of lavaan SEM / CFA Models
> ### Aliases: model_performance.lavaan
> 
> ### ** Examples
> 
> # Confirmatory Factor Analysis (CFA) ---------
> if (require("lavaan")) {
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9 "
+   model <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+   model_performance(model)
+ }
Loading required package: lavaan
This is lavaan 0.6-13
lavaan is FREE software! Please report any bugs.
[34m# Indices of model performance[39m

Chi2(24) | p (Chi2) | Baseline(36) | p (Baseline) |   GFI |  AGFI |   NFI |  NNFI |   CFI | RMSEA |    RMSEA  CI | p (RMSEA) |   RMR |  SRMR |   RFI |  PNFI |   IFI |   RNI | Loglikelihood |      AIC |      BIC | BIC_adjusted
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
85.306   |   < .001 |      918.852 |       < .001 | 0.943 | 0.894 | 0.907 | 0.896 | 0.931 | 0.092 | [0.07, 0.11] |    < .001 | 0.082 | 0.065 | 0.861 | 0.605 | 0.931 | 0.931 |     -3737.745 | 7517.490 | 7595.339 |     7528.739
> 
> 
> 
> 
> cleanEx()

detaching 'package:lavaan'

> nameEx("model_performance.lm")
> ### * model_performance.lm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.lm
> ### Title: Performance of Regression Models
> ### Aliases: model_performance.lm
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> model_performance(model)
[34m# Indices of model performance[39m

AIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------------
156.010 | 157.492 | 161.873 | 0.830 |     0.819 | 2.444 | 2.568
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> model_performance(model)
[34m# Indices of model performance[39m

AIC    |   AICc |    BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP
-----------------------------------------------------------------------------------------------------
31.298 | 32.155 | 35.695 |     0.478 | 0.359 | 0.934 |    0.395 |   -14.903 |           0.095 | 0.743
> 
> 
> 
> cleanEx()
> nameEx("model_performance.merMod")
> ### * model_performance.merMod
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.merMod
> ### Title: Performance of Mixed Models
> ### Aliases: model_performance.merMod
> 
> ### ** Examples
> 
> if (require("lme4")) {
+   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
+   model_performance(model)
+ }
Loading required package: lme4
Loading required package: Matrix
[34m# Indices of model performance[39m

AIC    |   AICc |    BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma
--------------------------------------------------------------------------
77.320 | 77.595 | 89.362 |      0.972 |      0.096 | 0.969 | 0.279 | 0.283
> 
> 
> 
> cleanEx()

detaching 'package:lme4', 'package:Matrix'

> nameEx("model_performance.rma")
> ### * model_performance.rma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.rma
> ### Title: Performance of Meta-Analysis Models
> ### Aliases: model_performance.rma
> 
> ### ** Examples
> 
> if (require("metafor")) {
+   data(dat.bcg)
+   dat <- escalc(measure = "RR", ai = tpos, bi = tneg, ci = cpos, di = cneg, data = dat.bcg)
+   model <- rma(yi, vi, data = dat, method = "REML")
+   model_performance(model)
+ }
Loading required package: metafor
Loading required package: Matrix
Loading required package: metadat

Loading the 'metafor' package (version 3.8-1). For an
introduction to the package please type: help(metafor)

[34m# Indices of model performance[39m

AIC    |    BIC |    I2 |     H2 |  TAU2 | CochransQ | p (CochransQ) | df | Omnibus | p (Omnibus)
-------------------------------------------------------------------------------------------------
29.376 | 30.345 | 0.922 | 12.856 | 0.313 |   152.233 |        < .001 | 12 |  15.796 |      < .001
> 
> 
> 
> cleanEx()

detaching 'package:metafor', 'package:metadat', 'package:Matrix'

> nameEx("model_performance.stanreg")
> ### * model_performance.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.stanreg
> ### Title: Performance of Bayesian Models
> ### Aliases: model_performance.stanreg model_performance.BFBayesFactor
> 
> ### ** Examples
> 
> ## Not run: 
> ##D if (require("rstanarm") && require("rstantools")) {
> ##D   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)
> ##D   model_performance(model)
> ##D 
> ##D   model <- stan_glmer(
> ##D     mpg ~ wt + cyl + (1 | gear),
> ##D     data = mtcars,
> ##D     chains = 1,
> ##D     iter = 500,
> ##D     refresh = 0
> ##D   )
> ##D   model_performance(model)
> ##D }
> ##D 
> ##D if (require("BayesFactor") && require("rstantools")) {
> ##D   model <- generalTestBF(carb ~ am + mpg, mtcars)
> ##D 
> ##D   model_performance(model)
> ##D   model_performance(model[3])
> ##D 
> ##D   model_performance(model, average = TRUE)
> ##D }
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("performance_accuracy")
> ### * performance_accuracy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_accuracy
> ### Title: Accuracy of predictions from model fit
> ### Aliases: performance_accuracy
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> performance_accuracy(model)
[34m# Accuracy of Model Predictions

[39mAccuracy: 89.40%
      SE: 5.34%-points
  Method: Correlation between observed and predicted
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> performance_accuracy(model)
[34m# Accuracy of Model Predictions

[39mAccuracy: 91.67%
      SE: 14.43%-points
  Method: Area under Curve
> 
> 
> 
> cleanEx()
> nameEx("performance_aicc")
> ### * performance_aicc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_aicc
> ### Title: Compute the AIC or second-order AIC
> ### Aliases: performance_aicc performance_aic performance_aic.default
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> AIC(m)
[1] 159.1051
> performance_aicc(m)
[1] 162.4651
> 
> # correct AIC for models with transformed response variable
> data("mtcars")
> mtcars$mpg <- floor(mtcars$mpg)
> model <- lm(log(mpg) ~ factor(cyl), mtcars)
> 
> # wrong AIC, not corrected for log-transformation
> AIC(model)
[1] -19.67061
> 
> # performance_aic() correctly detects transformed response and
> # returns corrected AIC
> performance_aic(model)
[1] 168.2152
> 
> 
> 
> cleanEx()
> nameEx("performance_cv")
> ### * performance_cv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_cv
> ### Title: Cross-validated model performance
> ### Aliases: performance_cv
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> performance_cv(model)
[34m# Cross-validation performance (30% holdout method)[39m

MSE | RMSE |   R2
-----------------
5.5 |  2.4 | 0.83
> 
> 
> 
> 
> cleanEx()
> nameEx("performance_hosmer")
> ### * performance_hosmer
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_hosmer
> ### Title: Hosmer-Lemeshow goodness-of-fit test
> ### Aliases: performance_hosmer
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> performance_hosmer(model)
[34m# Hosmer-Lemeshow Goodness-of-Fit Test

[39m  Chi-squared: 5.137
           df: 8    
      p-value: 0.743

Summary: model seems to fit well.
> 
> 
> 
> cleanEx()
> nameEx("performance_logloss")
> ### * performance_logloss
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_logloss
> ### Title: Log Loss
> ### Aliases: performance_logloss
> 
> ### ** Examples
> 
> data(mtcars)
> m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars)
> performance_logloss(m)
[1] 0.2517054
> 
> 
> 
> cleanEx()
> nameEx("performance_mae")
> ### * performance_mae
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_mae
> ### Title: Mean Absolute Error of Models
> ### Aliases: performance_mae mae
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_mae(m)
[1] 2.545822
> 
> 
> 
> cleanEx()
> nameEx("performance_mse")
> ### * performance_mse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_mse
> ### Title: Mean Square Error of Linear Models
> ### Aliases: performance_mse mse
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_mse(m)
[1] 8.752858
> 
> 
> 
> cleanEx()
> nameEx("performance_pcp")
> ### * performance_pcp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_pcp
> ### Title: Percentage of Correct Predictions
> ### Aliases: performance_pcp
> 
> ### ** Examples
> 
> data(mtcars)
> m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars)
> performance_pcp(m)
[34m# Percentage of Correct Predictions from Logistic Regression Model

[39m  Full model: 83.75% [70.96% - 96.53%]
  Null model: 50.78% [33.46% - 68.10%]
[34m
# Likelihood-Ratio-Test

[39m  Chi-squared: 27.751
  df:  2.000
  p-value:  0.000

> performance_pcp(m, method = "Gelman-Hill")
[34m# Percentage of Correct Predictions from Logistic Regression Model

[39m  Full model: 87.50% [76.04% - 98.96%]
  Null model: 56.25% [39.06% - 73.44%]
[34m
# Likelihood-Ratio-Test

[39m  Chi-squared: 27.751
  df:  2.000
  p-value:  0.000

> 
> 
> 
> cleanEx()
> nameEx("performance_rmse")
> ### * performance_rmse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_rmse
> ### Title: Root Mean Squared Error
> ### Aliases: performance_rmse rmse
> 
> ### ** Examples
> 
> if (require("nlme")) {
+   m <- lme(distance ~ age, data = Orthodont)
+ 
+   # RMSE
+   performance_rmse(m, normalized = FALSE)
+ 
+   # normalized RMSE
+   performance_rmse(m, normalized = TRUE)
+ }
Loading required package: nlme
[1] 0.07242178
> 
> 
> 
> cleanEx()

detaching 'package:nlme'

> nameEx("performance_roc")
> ### * performance_roc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_roc
> ### Title: Simple ROC curve
> ### Aliases: performance_roc
> 
> ### ** Examples
> 
> library(bayestestR)
> data(iris)
> 
> set.seed(123)
> iris$y <- rbinom(nrow(iris), size = 1, .3)
> folds <- sample(nrow(iris), size = nrow(iris) / 8, replace = FALSE)
> test_data <- iris[folds, ]
> train_data <- iris[-folds, ]
> 
> model <- glm(y ~ Sepal.Length + Sepal.Width, data = train_data, family = "binomial")
> as.data.frame(performance_roc(model, new_data = test_data))
   Sensitivity Specificity   Model
1    0.0000000  0.00000000 Model 1
2    0.1428571  0.00000000 Model 1
3    0.1428571  0.09090909 Model 1
4    0.1428571  0.18181818 Model 1
5    0.1428571  0.27272727 Model 1
6    0.1428571  0.36363636 Model 1
7    0.2857143  0.36363636 Model 1
8    0.2857143  0.45454545 Model 1
9    0.2857143  0.54545455 Model 1
10   0.2857143  0.63636364 Model 1
11   0.2857143  0.72727273 Model 1
12   0.4285714  0.72727273 Model 1
13   0.5714286  0.72727273 Model 1
14   0.5714286  0.81818182 Model 1
15   0.7142857  0.81818182 Model 1
16   0.8571429  0.81818182 Model 1
17   0.8571429  0.90909091 Model 1
18   1.0000000  0.90909091 Model 1
19   1.0000000  1.00000000 Model 1
20   1.0000000  1.00000000 Model 1
> 
> roc <- performance_roc(model, new_data = test_data)
> area_under_curve(roc$Specificity, roc$Sensitivity)
[1] 0.3766234
> 
> if (interactive()) {
+   m1 <- glm(y ~ Sepal.Length + Sepal.Width, data = iris, family = "binomial")
+   m2 <- glm(y ~ Sepal.Length + Petal.Width, data = iris, family = "binomial")
+   m3 <- glm(y ~ Sepal.Length + Species, data = iris, family = "binomial")
+   performance_roc(m1, m2, m3)
+ 
+   # if you have `see` package installed, you can also plot comparison of
+   # ROC curves for different models
+   if (require("see")) plot(performance_roc(m1, m2, m3))
+ }
> 
> 
> 
> cleanEx()

detaching 'package:bayestestR'

> nameEx("performance_rse")
> ### * performance_rse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_rse
> ### Title: Residual Standard Error for Linear Models
> ### Aliases: performance_rse
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_rse(m)
[1] 3.107785
> 
> 
> 
> cleanEx()
> nameEx("performance_score")
> ### * performance_score
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_score
> ### Title: Proper Scoring Rules
> ### Aliases: performance_score
> 
> ### ** Examples
> 
> ## Dobson (1990) Page 93: Randomized Controlled Trial :
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> 
> performance_score(model)
[34m# Proper Scoring Rules

[39mlogarithmic: -2.5979
  quadratic:  0.2095
  spherical:  0.3238
> ## Not run: 
> ##D if (require("glmmTMB")) {
> ##D   data(Salamanders)
> ##D   model <- glmmTMB(
> ##D     count ~ spp + mined + (1 | site),
> ##D     zi = ~ spp + mined,
> ##D     family = nbinom2(),
> ##D     data = Salamanders
> ##D   )
> ##D 
> ##D   performance_score(model)
> ##D }
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("r2")
> ### * r2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2
> ### Title: Compute the model's R2
> ### Aliases: r2 r2.default r2.merMod
> 
> ### ** Examples
> 
> # Pseudo r-quared for GLM
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2(model)
[34m# R2 for Logistic Regression
[39m  Tjur's R2: 0.478
> 
> # r-squared including confidence intervals
> model <- lm(mpg ~ wt + hp, data = mtcars)
> r2(model, ci = 0.95)
       R2: 0.827 [0.654, 0.906]
  adj. R2: 0.815 [0.632, 0.899]
> 
> if (require("lme4")) {
+   model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+   r2(model)
+ }
Loading required package: lme4
Loading required package: Matrix
[34m# R2 for Mixed Models

[39m  Conditional R2: 0.969
     Marginal R2: 0.658
> 
> 
> 
> cleanEx()

detaching 'package:lme4', 'package:Matrix'

> nameEx("r2_bayes")
> ### * r2_bayes
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_bayes
> ### Title: Bayesian R2
> ### Aliases: r2_bayes r2_posterior r2_posterior.brmsfit
> ###   r2_posterior.stanreg r2_posterior.BFBayesFactor
> 
> ### ** Examples
> 
> library(performance)
> if (require("rstanarm") && require("rstantools")) {
+   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)
+   r2_bayes(model)
+ 
+   model <- stan_lmer(
+     Petal.Length ~ Petal.Width + (1 | Species),
+     data = iris,
+     chains = 1,
+     iter = 500,
+     refresh = 0
+   )
+   r2_bayes(model)
+ }
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.21.3
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Loading required package: rstantools
This is rstantools version 2.2.0
Warning: The largest R-hat is 1.05, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
[34m# Bayesian R2 with Compatibility Interval

[39m  Conditional R2: 0.954 (95% CI [0.943, 0.962])
     Marginal R2: 0.823 (95% CI [0.704, 0.894])
> 
> if (require("BayesFactor")) {
+   BFM <- generalTestBF(mpg ~ qsec + gear, data = mtcars, progress = FALSE)
+   FM <- lmBF(mpg ~ qsec + gear, data = mtcars)
+ 
+   r2_bayes(FM)
+   r2_bayes(BFM[3])
+   r2_bayes(BFM, average = TRUE) # across all models
+ 
+   # with random effects:
+   mtcars$gear <- factor(mtcars$gear)
+   model <- lmBF(
+     mpg ~ hp + cyl + gear + gear:wt,
+     mtcars,
+     progress = FALSE,
+     whichRandom = c("gear", "gear:wt")
+   )
+ 
+   r2_bayes(model)
+ }
Loading required package: BayesFactor
Loading required package: coda
Loading required package: Matrix
************
Welcome to BayesFactor 0.9.12-4.4. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).

Type BFManual() to open the manual.
************
[34m# Bayesian R2 with Compatibility Interval

[39m  Conditional R2: 0.368 (95% CI [0.260, 0.641])
     Marginal R2: 0.211 (95% CI [1.278e-04, 0.503])
> 
> ## Not run: 
> ##D if (require("brms")) {
> ##D   model <- brms::brm(mpg ~ wt + cyl, data = mtcars)
> ##D   r2_bayes(model)
> ##D 
> ##D   model <- brms::brm(Petal.Length ~ Petal.Width + (1 | Species), data = iris)
> ##D   r2_bayes(model)
> ##D }
> ## End(Not run)
> 
> 
> 
> cleanEx()

detaching 'package:BayesFactor', 'package:Matrix', 'package:coda',
  'package:rstantools', 'package:rstanarm', 'package:Rcpp'

> nameEx("r2_coxsnell")
> ### * r2_coxsnell
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_coxsnell
> ### Title: Cox & Snell's R2
> ### Aliases: r2_coxsnell
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_coxsnell(model)
Cox & Snell's R2 
       0.4401407 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_efron")
> ### * r2_efron
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_efron
> ### Title: Efron's R2
> ### Aliases: r2_efron
> 
> ### ** Examples
> 
> ## Dobson (1990) Page 93: Randomized Controlled Trial:
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) #
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> 
> r2_efron(model)
[1] 0.5265152
> 
> 
> 
> cleanEx()
> nameEx("r2_kullback")
> ### * r2_kullback
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_kullback
> ### Title: Kullback-Leibler R2
> ### Aliases: r2_kullback
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_kullback(model)
Kullback-Leibler R2 
          0.3834362 
> 
> 
> 
> cleanEx()
> nameEx("r2_loo")
> ### * r2_loo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_loo
> ### Title: LOO-adjusted R2
> ### Aliases: r2_loo r2_loo_posterior r2_loo_posterior.brmsfit
> ###   r2_loo_posterior.stanreg
> 
> ### ** Examples
> 
> if (require("rstanarm")) {
+   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)
+   r2_loo(model)
+ }
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.21.3
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Warning: The largest R-hat is 1.05, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
Warning: Some Pareto k diagnostic values are slightly high. See help('pareto-k-diagnostic') for details.

[34m# LOO-adjusted R2 with Compatibility Interval

[39m  Conditional R2: 0.802 (95% CI [0.706, 0.898])
> 
> 
> 
> cleanEx()

detaching 'package:rstanarm', 'package:Rcpp'

> nameEx("r2_mcfadden")
> ### * r2_mcfadden
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mcfadden
> ### Title: McFadden's R2
> ### Aliases: r2_mcfadden
> 
> ### ** Examples
> 
> if (require("mlogit")) {
+   data("Fishing", package = "mlogit")
+   Fish <- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode")
+ 
+   model <- mlogit(mode ~ price + catch, data = Fish)
+   r2_mcfadden(model)
+ }
Loading required package: mlogit
Loading required package: dfidx

Attaching package: 'dfidx'

The following object is masked from 'package:stats':

    filter

McFadden's R2 
      0.17823 
> 
> 
> 
> cleanEx()

detaching 'package:mlogit', 'package:dfidx'

> nameEx("r2_mckelvey")
> ### * r2_mckelvey
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mckelvey
> ### Title: McKelvey & Zavoinas R2
> ### Aliases: r2_mckelvey
> 
> ### ** Examples
> 
> ## Dobson (1990) Page 93: Randomized Controlled Trial:
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) #
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> 
> r2_mckelvey(model)
McKelvey's R2 
    0.3776292 
> 
> 
> 
> cleanEx()
> nameEx("r2_nagelkerke")
> ### * r2_nagelkerke
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_nagelkerke
> ### Title: Nagelkerke's R2
> ### Aliases: r2_nagelkerke
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_nagelkerke(model)
Nagelkerke's R2 
      0.5899593 
> 
> 
> 
> cleanEx()
> nameEx("r2_nakagawa")
> ### * r2_nakagawa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_nakagawa
> ### Title: Nakagawa's R2 for mixed models
> ### Aliases: r2_nakagawa
> 
> ### ** Examples
> 
> if (require("lme4")) {
+   model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+   r2_nakagawa(model)
+   r2_nakagawa(model, by_group = TRUE)
+ }
Loading required package: lme4
Loading required package: Matrix
[34m# Explained Variance by Level

[39mLevel   |     R2
----------------
Level 1 |  0.569
Species | -0.853

> 
> 
> 
> cleanEx()

detaching 'package:lme4', 'package:Matrix'

> nameEx("r2_somers")
> ### * r2_somers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_somers
> ### Title: Somers' Dxy rank correlation for binary outcomes
> ### Aliases: r2_somers
> 
> ### ** Examples
> 
> ## Not run: 
> ##D if (require("correlation") && require("Hmisc")) {
> ##D   model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> ##D   r2_somers(model)
> ##D }
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_tjur")
> ### * r2_tjur
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_tjur
> ### Title: Tjur's R2 - coefficient of determination (D)
> ### Aliases: r2_tjur
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_tjur(model)
Tjur's R2 
0.4776926 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_xu")
> ### * r2_xu
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_xu
> ### Title: Xu' R2 (Omega-squared)
> ### Aliases: r2_xu
> 
> ### ** Examples
> 
> model <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
> r2_xu(model)
  Xu's R2 
0.8367238 
> 
> 
> 
> cleanEx()
> nameEx("r2_zeroinflated")
> ### * r2_zeroinflated
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_zeroinflated
> ### Title: R2 for models with zero-inflation
> ### Aliases: r2_zeroinflated
> 
> ### ** Examples
> 
> 
> 
> 
> cleanEx()
> nameEx("test_performance")
> ### * test_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: test_bf
> ### Title: Test if models are different
> ### Aliases: test_bf test_bf.default test_likelihoodratio test_lrt
> ###   test_performance test_vuong test_wald
> 
> ### ** Examples
> 
> # Nested Models
> # -------------
> m1 <- lm(Sepal.Length ~ Petal.Width, data = iris)
> m2 <- lm(Sepal.Length ~ Petal.Width + Species, data = iris)
> m3 <- lm(Sepal.Length ~ Petal.Width * Species, data = iris)
> 
> test_performance(m1, m2, m3)
Name | Model |    BF |   Omega2 | p (Omega2) |   LR | p (LR)
------------------------------------------------------------
m1   |    lm |       |          |            |      |       
m2   |    lm | 0.007 | 9.54e-04 |      0.935 | 0.15 |  0.919
m3   |    lm | 0.037 |     0.02 |      0.081 | 3.41 |  0.099
Models were detected as nested and are compared in sequential order.
> 
> test_bf(m1, m2, m3)
[34mBayes Factors for Model Comparison[39m

     Model                       BF
[m2] Petal.Width + Species    0.007
[m3] Petal.Width * Species 2.64e-04

* Against Denominator: [36m[m1] Petal.Width[39m
*   Bayes Factor Type: [36mBIC approximation[39m> test_wald(m1, m2, m3) # Equivalent to anova(m1, m2, m3)
Name | Model |  df | df_diff |    F |     p
-------------------------------------------
m1   |    lm | 148 |         |      |      
m2   |    lm | 146 |    2.00 | 0.08 | 0.927
m3   |    lm | 144 |    2.00 | 1.66 | 0.195
Models were detected as nested and are compared in sequential order.
> 
> # Equivalent to lmtest::lrtest(m1, m2, m3)
> test_likelihoodratio(m1, m2, m3, estimator = "ML")
[34m# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)[39m

Name | Model | df | df_diff | Chi2 |     p
------------------------------------------
m1   |    lm |  3 |         |      |      
m2   |    lm |  5 |       2 | 0.15 | 0.926
m3   |    lm |  7 |       2 | 3.41 | 0.182
> 
> # Equivalent to anova(m1, m2, m3, test='LRT')
> test_likelihoodratio(m1, m2, m3, estimator = "OLS")
[34m# Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator)[39m

Name | Model | df | df_diff | Chi2 |     p
------------------------------------------
m1   |    lm |  3 |         |      |      
m2   |    lm |  5 |       2 | 0.15 | 0.927
m3   |    lm |  7 |       2 | 3.31 | 0.191
> 
> if (require("CompQuadForm")) {
+   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2, nested=TRUE)
+ 
+   # Non-nested Models
+   # -----------------
+   m1 <- lm(Sepal.Length ~ Petal.Width, data = iris)
+   m2 <- lm(Sepal.Length ~ Petal.Length, data = iris)
+   m3 <- lm(Sepal.Length ~ Species, data = iris)
+ 
+   test_performance(m1, m2, m3)
+   test_bf(m1, m2, m3)
+   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2)
+ }
Loading required package: CompQuadForm
Name | Model | Omega2 | p (Omega2) |    LR | p (LR)
---------------------------------------------------
m1   |    lm |        |            |       |       
m2   |    lm |   0.19 |     < .001 | -4.57 | < .001
m3   |    lm |   0.12 |     < .001 |  2.51 | 0.006 
Each model is compared to m1.
> 
> # Tweak the output
> # ----------------
> test_performance(m1, m2, m3, include_formula = TRUE)
Name |                           Model |       BF | Omega2 | p (Omega2) |    LR | p (LR)
----------------------------------------------------------------------------------------
m1   |  lm(Sepal.Length ~ Petal.Width) |          |        |            |       |       
m2   | lm(Sepal.Length ~ Petal.Length) | 2.90e+10 |   0.19 |     < .001 | -4.57 | < .001
m3   |      lm(Sepal.Length ~ Species) | 2.00e-06 |   0.12 |     < .001 |  2.51 | 0.006 
Each model is compared to m1.
> 
> 
> # SEM / CFA (lavaan objects)
> # --------------------------
> # Lavaan Models
> if (require("lavaan")) {
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ textual + speed "
+   m1 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ 0 * textual + speed "
+   m2 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ 0 * textual + 0 * speed "
+   m3 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   test_likelihoodratio(m1, m2, m3)
+ 
+   # Different Model Types
+   # ---------------------
+   if (require("lme4") && require("mgcv")) {
+     m1 <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
+     m2 <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+     m3 <- gam(Sepal.Length ~ s(Petal.Length, by = Species) + Species, data = iris)
+ 
+     test_performance(m1, m2, m3)
+   }
+ }
Loading required package: lavaan
This is lavaan 0.6-13
lavaan is FREE software! Please report any bugs.
Loading required package: lme4
Loading required package: Matrix
Loading required package: mgcv
Loading required package: nlme

Attaching package: 'nlme'

The following object is masked from 'package:lme4':

    lmList

This is mgcv 1.8-41. For overview type 'help("mgcv-package")'.
Name |   Model |       BF
-------------------------
m1   |      lm |         
m2   | lmerMod | 3.78e-04
m3   |     gam |    0.012
Each model is compared to m1.
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()

detaching 'package:mgcv', 'package:nlme', 'package:lme4',
  'package:Matrix', 'package:lavaan', 'package:CompQuadForm'

> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  26.73 1.95 31.38 NA NA 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
